-- ============================================================================
-- Trino Performance Tuning & Analysis Scripts Collection
-- ============================================================================
-- è¿™ä¸ªSQLè„šæœ¬é›†åˆæä¾›äº†ä¸€å¥—å®Œæ•´çš„Trinoæ€§èƒ½åˆ†æå’Œè°ƒä¼˜å·¥å…·
-- ä½¿ç”¨æ–¹æ³•ï¼šæ ¹æ®éœ€è¦å¤åˆ¶ç›¸åº”çš„SQLè¯­å¥åˆ°Trinoå®¢æˆ·ç«¯æ‰§è¡Œ

-- ============================================================================
-- 1. æŸ¥è¯¢æ€§èƒ½åˆ†æ
-- ============================================================================

-- 1.1 æŸ¥çœ‹å½“å‰è¿è¡Œçš„æŸ¥è¯¢
SELECT 
    query_id,
    state,
    user_name,
    source,
    query,
    date_diff('second', created, now()) as runtime_seconds,
    queued_time.seconds as queued_seconds,
    analysis_time.seconds as analysis_seconds,  
    planning_time.seconds as planning_seconds,
    total_bytes,
    total_rows,
    peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0 as peak_memory_gb
FROM system.runtime.queries
WHERE state = 'RUNNING'
ORDER BY created DESC;

-- 1.2 æŸ¥çœ‹æœ€è¿‘å®Œæˆçš„æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
SELECT 
    query_id,
    state,
    user_name,
    left(query, 100) as query_preview,
    elapsed_time.seconds as total_seconds,
    queued_time.seconds as queued_seconds,
    planning_time.seconds as planning_seconds,
    analysis_time.seconds as analysis_seconds,
    execution_time.seconds as execution_seconds,
    total_bytes / 1024.0 / 1024.0 / 1024.0 as total_gb,
    total_rows / 1000000.0 as total_million_rows,
    peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0 as peak_memory_gb,
    peak_total_memory_bytes / 1024.0 / 1024.0 / 1024.0 as peak_total_memory_gb,
    cumulative_user_memory / 1024.0 / 1024.0 / 1024.0 as cumulative_memory_gb
FROM system.runtime.queries
WHERE created >= current_timestamp - INTERVAL '1' HOUR
  AND state IN ('FINISHED', 'FAILED')
ORDER BY elapsed_time.seconds DESC
LIMIT 20;

-- 1.3 æŸ¥çœ‹æŸ¥è¯¢å¤±è´¥ç»Ÿè®¡  
SELECT 
    error_type,
    COUNT(*) as failure_count,
    array_agg(DISTINCT user_name) as affected_users,
    min(created) as first_occurrence,
    max(created) as last_occurrence
FROM system.runtime.queries
WHERE state = 'FAILED'
  AND created >= current_timestamp - INTERVAL '24' HOUR
GROUP BY error_type
ORDER BY failure_count DESC;

-- 1.4 åˆ†æé•¿æ—¶é—´æ’é˜Ÿçš„æŸ¥è¯¢
SELECT 
    query_id,
    user_name,
    left(query, 150) as query_preview,
    queued_time.seconds as queued_seconds,
    elapsed_time.seconds as total_seconds,
    resource_group_name,
    state
FROM system.runtime.queries
WHERE queued_time.seconds > 30
  AND created >= current_timestamp - INTERVAL '6' HOUR
ORDER BY queued_time.seconds DESC;

-- ============================================================================
-- 2. ç»Ÿè®¡ä¿¡æ¯åˆ†æä¸ç»´æŠ¤
-- ============================================================================

-- 2.1 æ£€æŸ¥è¡¨ç»Ÿè®¡ä¿¡æ¯çš„å®Œæ•´æ€§å’Œæ–°é²œåº¦
SELECT 
    table_catalog,
    table_schema,
    table_name,
    row_count,
    data_size / 1024.0 / 1024.0 / 1024.0 as data_size_gb,
    CASE 
        WHEN row_count IS NULL THEN 'âŒ Missing'
        WHEN row_count = 0 THEN 'âš ï¸ Empty or Stale'
        ELSE 'âœ… Available'
    END as stats_status
FROM system.metadata.table_statistics
WHERE table_schema NOT IN ('information_schema', 'system')
ORDER BY 
    CASE WHEN row_count IS NULL THEN 0 ELSE 1 END,
    data_size DESC;

-- 2.2 æ£€æŸ¥åˆ—ç»Ÿè®¡ä¿¡æ¯è´¨é‡
SELECT 
    table_schema,
    table_name,
    column_name,
    data_type,
    distinct_values_count,
    nulls_fraction,
    data_size / 1024.0 / 1024.0 as data_size_mb,
    CASE 
        WHEN distinct_values_count IS NULL THEN 'âŒ Missing NDV'
        WHEN distinct_values_count = 0 THEN 'âš ï¸ Zero NDV'
        WHEN nulls_fraction IS NULL THEN 'âš ï¸ Missing Null Info'
        ELSE 'âœ… Complete'
    END as stats_quality
FROM system.metadata.column_statistics
WHERE table_schema NOT IN ('information_schema', 'system')
  AND (distinct_values_count IS NULL OR distinct_values_count = 0 OR nulls_fraction IS NULL)
ORDER BY table_schema, table_name, column_name;

-- 2.3 ç”ŸæˆANALYZEè¯­å¥è„šæœ¬
SELECT 
    'ANALYZE TABLE ' || table_catalog || '.' || table_schema || '.' || table_name || ';' as analyze_command
FROM system.metadata.table_statistics
WHERE table_schema NOT IN ('information_schema', 'system')
  AND (row_count IS NULL OR row_count = 0)
ORDER BY table_schema, table_name;

-- 2.4 è¯†åˆ«éœ€è¦é‡æ–°æ”¶é›†ç»Ÿè®¡çš„å¤§è¡¨
SELECT 
    table_catalog || '.' || table_schema || '.' || table_name as full_table_name,
    row_count,
    data_size / 1024.0 / 1024.0 / 1024.0 as data_size_gb,
    'ANALYZE TABLE ' || table_catalog || '.' || table_schema || '.' || table_name || 
    ' WITH (sample_percentage = ' || 
    CASE 
        WHEN data_size > 100 * 1024 * 1024 * 1024 THEN '1.0'  -- 100GB+ : 1%é‡‡æ ·
        WHEN data_size > 10 * 1024 * 1024 * 1024 THEN '5.0'   -- 10GB+ : 5%é‡‡æ ·  
        ELSE '10.0'  -- 10GB- : 10%é‡‡æ ·
    END || ');' as recommended_analyze
FROM system.metadata.table_statistics  
WHERE table_schema NOT IN ('information_schema', 'system')
  AND data_size > 1024 * 1024 * 1024  -- åªåˆ†æ1GBä»¥ä¸Šçš„è¡¨
  AND (row_count IS NULL OR row_count = 0)
ORDER BY data_size DESC;

-- ============================================================================
-- 3. Joinæ€§èƒ½ä¼˜åŒ–åˆ†æ
-- ============================================================================

-- 3.1 è¯†åˆ«å¯èƒ½éœ€è¦å¹¿æ’­Joinä¼˜åŒ–çš„æŸ¥è¯¢æ¨¡å¼
-- æ³¨æ„ï¼šè¿™éœ€è¦åœ¨å®é™…æ‰§è¡Œè®¡åˆ’ä¸­æŸ¥çœ‹ï¼Œè¿™é‡Œæä¾›åˆ†ææ€è·¯
WITH frequent_joins AS (
  SELECT 
    user_name,
    regexp_extract(lower(query), '(from\s+\w+\.\w+\.\w+).*?(join\s+\w+\.\w+\.\w+)', 2) as joined_table,
    COUNT(*) as join_frequency,
    AVG(elapsed_time.seconds) as avg_seconds,
    AVG(total_bytes) as avg_bytes
  FROM system.runtime.queries
  WHERE query LIKE '%JOIN%'
    AND state = 'FINISHED' 
    AND created >= current_timestamp - INTERVAL '7' DAY
  GROUP BY 1, 2
)
SELECT 
  user_name,
  joined_table,
  join_frequency,
  avg_seconds,
  avg_bytes / 1024.0 / 1024.0 / 1024.0 as avg_gb,
  CASE 
    WHEN avg_seconds > 60 AND avg_gb < 1 THEN 'ğŸ¯ Consider Broadcast Join'
    WHEN avg_seconds > 300 THEN 'âš¡ Needs Optimization'
    ELSE 'âœ… Performance OK'
  END as optimization_hint
FROM frequent_joins
WHERE join_frequency >= 5
ORDER BY avg_seconds DESC, join_frequency DESC;

-- 3.2 åˆ†æJoinå€¾æ–œé—®é¢˜çš„æŸ¥è¯¢
-- æŸ¥çœ‹æ‰§è¡Œæ—¶é—´æ–¹å·®è¾ƒå¤§çš„é‡å¤æŸ¥è¯¢æ¨¡å¼
WITH query_patterns AS (
  SELECT 
    regexp_replace(
      regexp_replace(query, '\d+', 'N'),  -- æ•°å­—æ›¿æ¢ä¸ºN
      '''[^'']*''', '''X'''               -- å­—ç¬¦ä¸²æ›¿æ¢ä¸ºX
    ) as query_pattern,
    elapsed_time.seconds as seconds,
    total_bytes,
    user_name
  FROM system.runtime.queries
  WHERE state = 'FINISHED'
    AND created >= current_timestamp - INTERVAL '3' DAY
    AND query LIKE '%JOIN%'
),
pattern_stats AS (
  SELECT 
    query_pattern,
    COUNT(*) as execution_count,
    AVG(seconds) as avg_seconds,
    STDDEV(seconds) as stddev_seconds,
    MIN(seconds) as min_seconds,
    MAX(seconds) as max_seconds
  FROM query_patterns
  GROUP BY query_pattern
  HAVING COUNT(*) >= 3
)
SELECT 
  left(query_pattern, 200) as pattern_preview,
  execution_count,
  avg_seconds,
  stddev_seconds,
  min_seconds,
  max_seconds,
  max_seconds / NULLIF(min_seconds, 0) as performance_ratio,
  CASE 
    WHEN stddev_seconds > avg_seconds * 0.5 THEN 'âš ï¸ High Variance - Check for Skew'
    WHEN max_seconds / NULLIF(min_seconds, 0) > 5 THEN 'ğŸ” Investigate Data Skew'
    ELSE 'âœ… Consistent Performance'
  END as skew_indicator
FROM pattern_stats
WHERE stddev_seconds IS NOT NULL
ORDER BY stddev_seconds / NULLIF(avg_seconds, 0) DESC;

-- ============================================================================
-- 4. èµ„æºä½¿ç”¨åˆ†æ
-- ============================================================================

-- 4.1 å†…å­˜ä½¿ç”¨åˆ†æ
SELECT 
    date_trunc('hour', created) as hour,
    COUNT(*) as query_count,
    AVG(peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0) as avg_memory_gb,
    PERCENTILE(peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0, 0.95) as p95_memory_gb,
    MAX(peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0) as max_memory_gb,
    COUNT(CASE WHEN error_code = 'EXCEEDED_MEMORY_LIMIT' THEN 1 END) as oom_failures
FROM system.runtime.queries
WHERE created >= current_timestamp - INTERVAL '24' HOUR
GROUP BY 1
ORDER BY 1 DESC;

-- 4.2 æŒ‰ç”¨æˆ·åˆ†æèµ„æºä½¿ç”¨æ¨¡å¼
SELECT 
    user_name,
    COUNT(*) as total_queries,
    COUNT(CASE WHEN state = 'FINISHED' THEN 1 END) as successful_queries,
    COUNT(CASE WHEN state = 'FAILED' THEN 1 END) as failed_queries,
    AVG(elapsed_time.seconds) as avg_runtime_seconds,
    SUM(total_bytes) / 1024.0 / 1024.0 / 1024.0 / 1024.0 as total_processed_tb,
    AVG(peak_user_memory_bytes) / 1024.0 / 1024.0 / 1024.0 as avg_memory_gb,
    MAX(peak_user_memory_bytes) / 1024.0 / 1024.0 / 1024.0 as max_memory_gb
FROM system.runtime.queries
WHERE created >= current_timestamp - INTERVAL '7' DAY
GROUP BY user_name
HAVING COUNT(*) >= 10
ORDER BY total_processed_tb DESC;

-- 4.3 é›†ç¾¤è´Ÿè½½è¶‹åŠ¿åˆ†æ
SELECT 
    date_trunc('hour', created) as hour,
    COUNT(*) as total_queries,
    COUNT(CASE WHEN state = 'RUNNING' THEN 1 END) as running_queries,
    COUNT(CASE WHEN state = 'QUEUED' THEN 1 END) as queued_queries,
    AVG(queued_time.seconds) as avg_queue_time,
    PERCENTILE(queued_time.seconds, 0.95) as p95_queue_time,
    SUM(total_bytes) / 1024.0 / 1024.0 / 1024.0 / 1024.0 as total_data_tb
FROM system.runtime.queries  
WHERE created >= current_timestamp - INTERVAL '48' HOUR
GROUP BY 1
ORDER BY 1 DESC;

-- ============================================================================
-- 5. æ…¢æŸ¥è¯¢è¯Šæ–­
-- ============================================================================

-- 5.1 è¯†åˆ«æ…¢æŸ¥è¯¢æ¨¡å¼
WITH slow_queries AS (
  SELECT 
    query_id,
    user_name,
    query,
    elapsed_time.seconds as total_seconds,
    queued_time.seconds as queued_seconds,
    planning_time.seconds as planning_seconds,
    analysis_time.seconds as analysis_seconds,
    execution_time.seconds as execution_seconds,
    total_bytes / 1024.0 / 1024.0 / 1024.0 as processed_gb,
    total_rows / 1000000.0 as processed_million_rows,
    peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0 as peak_memory_gb
  FROM system.runtime.queries
  WHERE state = 'FINISHED'
    AND elapsed_time.seconds > 60  -- è¶…è¿‡1åˆ†é’Ÿçš„æŸ¥è¯¢
    AND created >= current_timestamp - INTERVAL '24' HOUR
)
SELECT 
  query_id,
  user_name,
  left(query, 100) as query_preview,
  total_seconds,
  planning_seconds / total_seconds * 100 as planning_pct,
  execution_seconds / total_seconds * 100 as execution_pct,
  processed_gb,
  processed_million_rows,
  processed_gb / NULLIF(total_seconds, 0) as throughput_gb_per_sec,
  peak_memory_gb,
  CASE 
    WHEN planning_seconds / total_seconds > 0.5 THEN 'ğŸ§  Planning Bottleneck'
    WHEN processed_gb / NULLIF(total_seconds, 0) < 0.1 THEN 'ğŸ’¿ IO Bottleneck'  
    WHEN peak_memory_gb > 50 THEN 'ğŸ’¾ Memory Intensive'
    ELSE 'âš¡ CPU Intensive'
  END as bottleneck_type
FROM slow_queries
ORDER BY total_seconds DESC;

-- 5.2 æŸ¥çœ‹å…·ä½“æ…¢æŸ¥è¯¢çš„Stageåˆ†æ
-- æ³¨æ„ï¼šéœ€è¦æ›¿æ¢å…·ä½“çš„query_id
SELECT 
    stage_id,
    state,
    total_tasks,
    running_tasks, 
    completed_tasks,
    total_splits,
    queued_splits,
    running_splits,
    wall_time.seconds as wall_seconds,
    total_cpu_time.seconds as cpu_seconds,
    raw_input_data_size / 1024.0 / 1024.0 as input_mb,
    processed_input_data_size / 1024.0 / 1024.0 as processed_mb,
    output_data_size / 1024.0 / 1024.0 as output_mb
FROM system.runtime.stages
WHERE query_id = '<YOUR_QUERY_ID_HERE>'  -- æ›¿æ¢ä¸ºå®é™…çš„query_id
ORDER BY stage_id;

-- ============================================================================  
-- 6. ä¼šè¯å‚æ•°ä¼˜åŒ–å»ºè®®
-- ============================================================================

-- 6.1 ç”Ÿæˆé’ˆå¯¹ä¸åŒworkloadçš„å‚æ•°è°ƒä¼˜å»ºè®®
WITH workload_analysis AS (
  SELECT 
    user_name,
    COUNT(*) as query_count,
    AVG(elapsed_time.seconds) as avg_runtime,
    AVG(total_bytes / 1024.0 / 1024.0 / 1024.0) as avg_data_gb,
    AVG(peak_user_memory_bytes / 1024.0 / 1024.0 / 1024.0) as avg_memory_gb,
    COUNT(CASE WHEN query LIKE '%JOIN%' THEN 1 END) as join_queries,
    COUNT(CASE WHEN query LIKE '%GROUP BY%' THEN 1 END) as agg_queries,
    COUNT(CASE WHEN query LIKE '%ORDER BY%' THEN 1 END) as sort_queries
  FROM system.runtime.queries
  WHERE created >= current_timestamp - INTERVAL '7' DAY
    AND state = 'FINISHED'
  GROUP BY user_name
  HAVING COUNT(*) >= 20
)
SELECT 
  user_name,
  query_count,
  avg_runtime,
  avg_data_gb,
  avg_memory_gb,
  join_queries,
  CASE 
    WHEN avg_data_gb < 1 AND join_queries > query_count * 0.5 THEN
      'SET SESSION broadcast_join_threshold = ''200MB''; -- é€‚åˆå°æ•°æ®Join'
    WHEN avg_memory_gb > 20 THEN
      'SET SESSION query_max_memory_per_node = ''8GB''; -- æ§åˆ¶å†…å­˜ä½¿ç”¨'
    WHEN avg_runtime > 300 THEN  
      'SET SESSION enable_dynamic_filtering = true; -- å¯ç”¨åŠ¨æ€è¿‡æ»¤'
    ELSE 'Current settings likely optimal'
  END as tuning_recommendation
FROM workload_analysis
ORDER BY avg_runtime DESC;

-- ============================================================================
-- 7. åŠ¨æ€è¿‡æ»¤æ•ˆæœåˆ†æ  
-- ============================================================================

-- 7.1 æŸ¥çœ‹åŠ¨æ€è¿‡æ»¤çš„ä½¿ç”¨æƒ…å†µ (éœ€è¦å¯ç”¨event listener)
-- æ³¨æ„ï¼šè¿™ä¸ªæŸ¥è¯¢å¯èƒ½éœ€è¦æ ¹æ®ä½ çš„ç›‘æ§ç³»ç»Ÿè°ƒæ•´
SELECT 
    date_trunc('day', created) as day,
    COUNT(*) as total_queries,
    COUNT(CASE WHEN query LIKE '%DynamicFilter%' THEN 1 END) as dynamic_filter_queries,
    AVG(CASE WHEN query LIKE '%DynamicFilter%' THEN elapsed_time.seconds END) as avg_df_runtime,
    AVG(CASE WHEN query NOT LIKE '%DynamicFilter%' THEN elapsed_time.seconds END) as avg_regular_runtime
FROM system.runtime.queries
WHERE created >= current_timestamp - INTERVAL '30' DAY
  AND state = 'FINISHED'
  AND query LIKE '%JOIN%'
GROUP BY 1
ORDER BY 1 DESC;

-- ============================================================================
-- 8. è¡¨è®¾è®¡ä¼˜åŒ–å»ºè®®
-- ============================================================================

-- 8.1 è¯†åˆ«ç»å¸¸å…¨è¡¨æ‰«æçš„å¤§è¡¨
WITH table_access_patterns AS (
  SELECT 
    regexp_extract(query, 'FROM\s+(\w+\.\w+\.\w+)', 1) as table_name,
    COUNT(*) as scan_frequency,
    AVG(elapsed_time.seconds) as avg_scan_time,
    AVG(total_bytes / 1024.0 / 1024.0 / 1024.0) as avg_scanned_gb,
    COUNT(CASE WHEN query NOT LIKE '%WHERE%' THEN 1 END) as full_scans
  FROM system.runtime.queries
  WHERE query LIKE '%SELECT%'
    AND query LIKE '%FROM%'
    AND created >= current_timestamp - INTERVAL '7' DAY
    AND state = 'FINISHED'
  GROUP BY 1
  HAVING table_name IS NOT NULL
),
table_stats AS (
  SELECT 
    table_catalog || '.' || table_schema || '.' || table_name as full_name,
    data_size / 1024.0 / 1024.0 / 1024.0 as table_size_gb
  FROM system.metadata.table_statistics
)
SELECT 
  tap.table_name,
  ts.table_size_gb,
  tap.scan_frequency,
  tap.avg_scan_time,
  tap.avg_scanned_gb,
  tap.full_scans,
  tap.full_scans * 100.0 / tap.scan_frequency as full_scan_ratio,
  CASE 
    WHEN ts.table_size_gb > 10 AND tap.full_scans > tap.scan_frequency * 0.3 THEN
      'ğŸ“Š Consider partitioning by frequently filtered columns'
    WHEN tap.avg_scan_time > 300 AND ts.table_size_gb > 50 THEN
      'ğŸ—‚ï¸ Consider columnar format (Parquet/ORC) and compression'
    WHEN tap.scan_frequency > 100 AND tap.avg_scan_time > 60 THEN
      'ğŸš€ Consider pre-aggregation or materialized views'
    ELSE 'âœ… Table access pattern looks reasonable'
  END as optimization_suggestion  
FROM table_access_patterns tap
LEFT JOIN table_stats ts ON tap.table_name = ts.full_name
WHERE ts.table_size_gb IS NOT NULL
ORDER BY tap.full_scans DESC, ts.table_size_gb DESC;

-- ============================================================================
-- 9. é›†ç¾¤å¥åº·åº¦ç›‘æ§
-- ============================================================================

-- 9.1 èŠ‚ç‚¹å¥åº·çŠ¶æ€æ£€æŸ¥
-- æ³¨æ„ï¼šè¿™ä¸ªæŸ¥è¯¢éœ€è¦æœ‰é€‚å½“çš„æƒé™è®¿é—®system.runtime.nodes
SELECT 
    node_id,
    http_uri,
    node_version,
    coordinator,
    state,
    age(now(), last_request_time) as last_seen,
    recent_failures,
    recent_successes  
FROM system.runtime.nodes
ORDER BY coordinator DESC, state, node_id;

-- 9.2 èµ„æºç»„ä½¿ç”¨ç»Ÿè®¡  
SELECT 
    name as resource_group,
    state,
    queued_queries,
    running_queries, 
    total_queued_time.seconds / 3600.0 as total_queued_hours,
    cpu_usage_millis / 1000.0 / 3600.0 as cpu_hours
FROM system.runtime.resource_groups
WHERE queued_queries > 0 OR running_queries > 0
ORDER BY queued_queries DESC, running_queries DESC;

-- ============================================================================
-- ä½¿ç”¨è¯´æ˜å’Œæœ€ä½³å®è·µ
-- ============================================================================

/*
ä½¿ç”¨å»ºè®®ï¼š

1. æ—¥å¸¸ç›‘æ§ï¼ˆæ¯æ—¥æ‰§è¡Œï¼‰ï¼š
   - è¿è¡Œ 1.2 æŸ¥çœ‹å½“å¤©æŸ¥è¯¢æ€§èƒ½æ¦‚å†µ
   - è¿è¡Œ 4.1 æ£€æŸ¥å†…å­˜ä½¿ç”¨è¶‹åŠ¿
   - è¿è¡Œ 2.1 æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯å®Œæ•´æ€§

2. å‘¨åº¦åˆ†æï¼ˆæ¯å‘¨æ‰§è¡Œï¼‰ï¼š
   - è¿è¡Œ 3.2 åˆ†æJoinæ€§èƒ½æ¨¡å¼
   - è¿è¡Œ 5.1 è¯†åˆ«æ…¢æŸ¥è¯¢æ¨¡å¼  
   - è¿è¡Œ 8.1 åˆ†æè¡¨è®¿é—®æ¨¡å¼

3. æŒ‰éœ€è¯Šæ–­ï¼ˆé—®é¢˜å‡ºç°æ—¶ï¼‰ï¼š
   - è¿è¡Œ 1.1 æŸ¥çœ‹å½“å‰è¿è¡ŒçŠ¶æ€
   - è¿è¡Œ 5.2 åˆ†æå…·ä½“æ…¢æŸ¥è¯¢çš„Stage
   - è¿è¡Œ 1.3 æŸ¥çœ‹å¤±è´¥åŸå› åˆ†å¸ƒ

4. ä¼˜åŒ–å»ºè®®åº”ç”¨ï¼š
   - æ ¹æ® 2.3/2.4 çš„è¾“å‡ºæ‰§è¡ŒANALYZEè¯­å¥
   - å‚è€ƒ 6.1 è°ƒæ•´ä¼šè¯å‚æ•°  
   - æ ¹æ® 8.1 è€ƒè™‘è¡¨è®¾è®¡ä¼˜åŒ–

æ³¨æ„äº‹é¡¹ï¼š
- æŸäº›æŸ¥è¯¢éœ€è¦æ›¿æ¢å…·ä½“çš„å‚æ•°ï¼ˆå¦‚query_idï¼‰
- ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢å¯èƒ½éœ€è¦ç›¸åº”çš„æƒé™
- å»ºè®®åœ¨ä½å³°æ—¶æœŸè¿è¡Œèµ„æºå¯†é›†å‹çš„åˆ†ææŸ¥è¯¢
- å¯ä»¥æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´æ—¶é—´é—´éš”å’Œé˜ˆå€¼
*/
