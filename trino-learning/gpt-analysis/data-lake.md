# 09/05 17:53 æ•°æ®æ¹–è¡¨è§£è¯»

> Trino æ•°æ®æ¹–è¡¨æ ¼å¼æ·±åº¦è§£æ
> è§£é‡Šä¸‹é¢
> ## 1. æ•°æ®æ¹–è¡¨æ ¼å¼æ¼”è¿›å†ç¨‹
>
> ### 1.1 ä¼ ç»Ÿæ•°æ®æ¹–çš„å±€é™æ€§
>
> ```
> ä¼ ç»ŸHiveè¡¨æ ¼å¼çš„é—®é¢˜:
> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
> â”‚ æ–‡ä»¶çº§æ“ä½œ â†’ ç›®å½•ç»“æ„ â†’ å…ƒæ•°æ®å­˜å‚¨                            â”‚
> â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
> â”‚ é—®é¢˜1: ç¼ºä¹ACIDäº‹åŠ¡æ”¯æŒ                                     â”‚
> â”‚ â””â”€â”€ å¹¶å‘å†™å…¥å†²çªï¼Œæ•°æ®ä¸ä¸€è‡´                                â”‚
> â”‚                                                           â”‚
> â”‚ é—®é¢˜2: Schemaæ¼”è¿›å›°éš¾                                       â”‚
> â”‚ â””â”€â”€ åˆ—æ·»åŠ /åˆ é™¤éœ€è¦é‡å†™å…¨é‡æ•°æ®                              â”‚
> â”‚                                                           â”‚
> â”‚ é—®é¢˜3: å°æ–‡ä»¶é—®é¢˜ä¸¥é‡                                       â”‚
> â”‚ â””â”€â”€ é¢‘ç¹å†™å…¥äº§ç”Ÿå¤§é‡å°æ–‡ä»¶ï¼Œå½±å“æŸ¥è¯¢æ€§èƒ½                      â”‚
> â”‚                                                           â”‚
> â”‚ é—®é¢˜4: ç¼ºä¹æ—¶é—´æ—…è¡Œèƒ½åŠ›                                     â”‚
> â”‚ â””â”€â”€ æ— æ³•æŸ¥è¯¢å†å²ç‰ˆæœ¬æ•°æ®                                    â”‚
> â”‚                                                           â”‚
> â”‚ é—®é¢˜5: å…ƒæ•°æ®ç®¡ç†ä½æ•ˆ                                       â”‚
> â”‚ â””â”€â”€ åˆ†åŒºå‘ç°æ…¢ï¼Œç»Ÿè®¡ä¿¡æ¯ç»´æŠ¤æˆæœ¬é«˜                          â”‚
> â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
> ```
>
> ### 1.2 ç°ä»£è¡¨æ ¼å¼çš„æ ¸å¿ƒåˆ›æ–°
>
> ```java
> // ç°ä»£æ•°æ®æ¹–è¡¨æ ¼å¼çš„è®¾è®¡ç†å¿µ
> public abstract class ModernTableFormat {
>
>     // æ ¸å¿ƒè®¾è®¡åŸåˆ™
>     enum DesignPrinciple {
>         VERSIONED_METADATA,      // ç‰ˆæœ¬åŒ–å…ƒæ•°æ®
>         TRANSACTION_LOG,         // äº‹åŠ¡æ—¥å¿—
>         SCHEMA_EVOLUTION,        // æ¨¡å¼æ¼”è¿›
>         PARTITION_EVOLUTION,     // åˆ†åŒºæ¼”è¿›
>         TIME_TRAVEL,             // æ—¶é—´æ—…è¡Œ
>         INCREMENTAL_PROCESSING,  // å¢é‡å¤„ç†
>         COMPACTION_OPTIMIZATION, // å‹ç¼©ä¼˜åŒ–
>         MULTI_ENGINE_SUPPORT     // å¤šå¼•æ“æ”¯æŒ
>     }
>
>     // è¡¨æ ¼å¼å¿…é¡»æä¾›çš„æ ¸å¿ƒèƒ½åŠ›
>     public interface TableFormatCapabilities {
>         // äº‹åŠ¡èƒ½åŠ›
>         Transaction beginTransaction();
>         void commitTransaction(Transaction tx);
>         void rollbackTransaction(Transaction tx);
>
>         // ç‰ˆæœ¬ç®¡ç†
>         List<Snapshot> getSnapshots();
>         Snapshot getSnapshotAsOf(long timestampMs);
>         Snapshot getSnapshotById(long snapshotId);
>
>         // æ¨¡å¼ç®¡ç†
>         Schema getCurrentSchema();
>         Schema getSchemaAsOf(long timestampMs);
>         void evolveSchema(SchemaUpdate update);
>
>         // åˆ†åŒºç®¡ç†
>         PartitionSpec getCurrentPartitionSpec();
>         void evolvePartitionSpec(PartitionSpecUpdate update);
>
>         // æ–‡ä»¶ç®¡ç†
>         List<DataFile> getDataFiles();
>         void addDataFiles(List<DataFile> files);
>         void deleteDataFiles(List<DataFile> files);
>
>         // ä¼˜åŒ–æ“ä½œ
>         void compact(CompactionStrategy strategy);
>         void expire(ExpireStrategy strategy);
>
>         // ç»Ÿè®¡ä¿¡æ¯
>         TableStatistics getStatistics();
>         void updateStatistics(TableStatistics stats);
>     }
> }
> ```
>
> ---

å¥½å˜ï¼Œè¿™æ®µå†…å®¹å…¶å®æ˜¯åœ¨å¯¹ **Trino æ•°æ®æ¹–è¡¨æ ¼å¼**çš„æ¼”è¿›å†ç¨‹åšä¸€ä¸ªæ·±åº¦æ¢³ç†ï¼Œä»ä¼ ç»Ÿ Hive è¡¨æ ¼å¼çš„ç—›ç‚¹ï¼Œåˆ°ç°ä»£æ•°æ®æ¹–è¡¨æ ¼å¼ï¼ˆæ¯”å¦‚ Icebergã€Delta Lakeã€Hudiï¼‰çš„æ ¸å¿ƒè®¾è®¡ç†å¿µä¸èƒ½åŠ›ã€‚æˆ‘ä»¬å¯ä»¥åˆ†æˆä¸¤ä¸ªå±‚æ¬¡å»ç†è§£ğŸ‘‡

---

## 1ï¸âƒ£ ä¼ ç»Ÿæ•°æ®æ¹–è¡¨æ ¼å¼çš„å±€é™æ€§

åœ¨æ—©æœŸæ•°æ®æ¹–ï¼ˆä¸»è¦æŒ‡ Hive on HDFS è¿™ç§æ¶æ„ï¼‰ä¸­ï¼Œè¡¨å…¶å®æœ¬è´¨ä¸Šå°±æ˜¯ **å…ƒæ•°æ® + å­˜å‚¨æ–‡ä»¶å¤¹**ï¼š

- å…ƒæ•°æ®å­˜åœ¨ **Hive Metastoreï¼ˆHMSï¼‰** é‡Œï¼Œè®°å½•è¡¨ schemaã€åˆ†åŒºè·¯å¾„ç­‰ä¿¡æ¯ã€‚
- æ•°æ®ä»¥ **æ–‡ä»¶**ï¼ˆORC / Parquet / Textï¼‰å½¢å¼å­˜æ”¾åœ¨ HDFS ç›®å½•ç»“æ„ä¸­ã€‚

è™½ç„¶ç®€å•æ˜“å®ç°ï¼Œä½†**ç¼ºç‚¹éå¸¸æ˜æ˜¾**ï¼š

| é—®é¢˜ | è¯´æ˜ | å½±å“ |
|------|------|------|
| âŒ ç¼ºä¹ ACID äº‹åŠ¡ | Hive è¡¨ä¸æ˜¯åŸç”Ÿäº‹åŠ¡è¡¨ï¼Œå¤šä¸ªå†™å…¥ä¼šå‘ç”Ÿå†²çªï¼›insert overwrite æ—¶å¦‚æœå¤±è´¥ï¼Œæ•°æ®å¯èƒ½ä¸ä¸€è‡´ | æ•°æ®è´¨é‡æ— æ³•ä¿è¯ï¼Œå°¤å…¶æ˜¯å¹¶å‘å†™å…¥åœºæ™¯ |
| âŒ Schema æ¼”è¿›å›°éš¾ | åˆ—å¢åˆ éœ€è¦ä¿®æ”¹å…ƒæ•°æ®ï¼Œä½†åº•å±‚æ•°æ®æ–‡ä»¶ä¸å…¼å®¹è¿˜å¾—å…¨é‡é‡å†™ | è¡¨ç»“æ„ç»´æŠ¤å›°éš¾ |
| âŒ å°æ–‡ä»¶ä¸¥é‡ | æ•°æ®å¯¼å…¥é¢‘ç¹çš„å°æ‰¹é‡äº§ç”Ÿå¤§é‡å°æ–‡ä»¶ | æŸ¥è¯¢æˆæœ¬é«˜ï¼ŒNameNode & I/O å‹åŠ›å¤§ |
| âŒ æ²¡æœ‰æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰ | æ— æ³•æŒ‰å†å²ç‰ˆæœ¬å›æº¯æŸ¥è¯¢ | æ•°æ®åˆ†æç¼ºä¹å¯æº¯æºæ€§ |
| âŒ å…ƒæ•°æ®ç®¡ç†ä½æ•ˆ | åˆ†åŒºè¿‡å¤šæ—¶å…ƒæ•°æ®å‘ç°æ…¢ï¼Œç»Ÿè®¡ä¿¡æ¯æˆæœ¬é«˜ | æŸ¥è¯¢ä¼˜åŒ–å™¨éš¾ä»¥ç”Ÿæˆé«˜æ•ˆè®¡åˆ’ |

ğŸ’¡ **ç›´è§‚ç±»æ¯”**
Hive è¡¨ = Excel æ–‡ä»¶å¤¹ + æ–‡ä»¶åä½œä¸ºåˆ†åŒºï¼Œç¼ºä¹ç‰ˆæœ¬æ§åˆ¶ & äº‹åŠ¡ç®¡ç†
ç°ä»£è¡¨æ ¼å¼ = å¸¦ Git ç‰ˆæœ¬ç®¡ç† + å…ƒæ•°æ®ç´¢å¼• + è‡ªåŠ¨åˆå¹¶ä¼˜åŒ–çš„æ•°æ®åº“

---

## 2ï¸âƒ£ ç°ä»£è¡¨æ ¼å¼çš„è®¾è®¡ç†å¿µ

åœ¨ Apache Iceberg / Delta Lake / Apache Hudi ç­‰æ–°ä¸€ä»£æ•°æ®æ¹–è¡¨æ ¼å¼é‡Œï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

ğŸ“Œ **ç”¨äº‹åŠ¡æ—¥å¿—ï¼ˆMetadata Logï¼‰ç®¡ç†æ•°æ®æ¹–æ–‡ä»¶å…ƒæ•°æ®å’Œå˜åŒ–å†å²**
ğŸ“Œ **å…ƒæ•°æ®ä¹Ÿç‰ˆæœ¬åŒ–ï¼ˆVersioned Metadataï¼‰**ï¼Œæ”¯æŒå›æº¯ & å¹¶å‘å†™å…¥
ğŸ“Œ **æ–‡ä»¶ç®¡ç†è‡ªåŠ¨åŒ–**ï¼Œè§£å†³å°æ–‡ä»¶ & åˆ†åŒºæ¼”è¿›é—®é¢˜
ğŸ“Œ **å¤šå¼•æ“æ”¯æŒ**ï¼ˆTrinoã€Sparkã€Flinkã€Hive ç­‰éƒ½èƒ½è®¿é—®åŒä¸€ä»½è¡¨æ•°æ®ï¼‰

åœ¨ä½ è´´çš„ Java ç¤ºæ„ä»£ç ä¸­ï¼š
```java
enum DesignPrinciple {
    VERSIONED_METADATA,      // å…ƒæ•°æ®æœ‰ç‰ˆæœ¬ï¼Œå¯è®°å½•å†å²å¿«ç…§
    TRANSACTION_LOG,         // äº‹åŠ¡æ—¥å¿—ï¼Œæ”¯æŒåŸå­æäº¤/å›æ»š
    SCHEMA_EVOLUTION,        // è¡¨ç»“æ„å¯æ¼”è¿›ï¼ˆåŠ åˆ—ã€æ”¹åˆ—åã€ç±»å‹è½¬æ¢ï¼‰
    PARTITION_EVOLUTION,     // åˆ†åŒºæ–¹å¼å¯å˜ï¼ˆæ— éœ€é‡å†™å…¨é‡æ•°æ®ï¼‰
    TIME_TRAVEL,             // æ”¯æŒæ—¶é—´æ—…è¡ŒæŸ¥è¯¢
    INCREMENTAL_PROCESSING,  // æ”¯æŒå¢é‡å¤„ç†ï¼ˆåªè¯»å˜åŒ–ï¼‰
    COMPACTION_OPTIMIZATION, // è‡ªåŠ¨å°æ–‡ä»¶åˆå¹¶å‹ç¼©
    MULTI_ENGINE_SUPPORT     // æ”¯æŒå¤šè®¡ç®—å¼•æ“è¯»å†™
}
```

---

### ä¾‹å­ï¼šäº‹åŠ¡æ—¥å¿—æœºåˆ¶
å‡è®¾å½“å‰è¡¨æ˜¯ `sales`
1. æ–°æ•°æ®å¯¼å…¥ä¼šå…ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶åŒºï¼ˆStagingï¼‰
2. ç”Ÿæˆä¸€ä¸ª **Snapshot**ï¼ˆæ¯”å¦‚ v123ï¼‰ï¼Œæ–‡ä»¶åˆ—è¡¨ã€Schemaã€åˆ†åŒºä¿¡æ¯éƒ½ä¼šå†™å…¥ `metadata.json`
3. **åŸå­æäº¤**ï¼šå°† v123 åŠ åˆ°äº‹åŠ¡æ—¥å¿—é‡Œ
4. å…¶ä»–æŸ¥è¯¢å¼•æ“è¯»å–è¡¨æ—¶å°±åŸºäºæœ€æ–°çš„ Snapshotï¼Œç¡®ä¿è¯»ä¸€è‡´æ€§

**æ•ˆæœ**ï¼š
- ä¸åŒå¼•æ“ï¼ˆTrinoã€Sparkï¼‰è¯»åˆ°çš„æ•°æ®æ˜¯ä¸€è‡´çš„
- å¦‚æœå†™å…¥å¤±è´¥å¯ä»¥ rollback åˆ°ä¸Šä¸€ä¸ª Snapshot

---

### Schema æ¼”è¿› & åˆ†åŒºæ¼”è¿›
è¿‡å» Hive å¦‚æœè¦è°ƒæ•´åˆ†åŒºåˆ—ï¼Œè¦ä¹ˆé‡æ–°å»ºè¡¨ï¼Œè¦ä¹ˆå¯¼å‡ºæ‰€æœ‰æ•°æ®é‡å†™
â˜‘ Iceberg/Deltalake ç›´æ¥ä¿®æ”¹åˆ†åŒºç­–ç•¥ï¼Œæœªæ¥æ–°æ•°æ®ç”¨æ–°åˆ†åŒºå­˜å‚¨ï¼Œæ—§æ•°æ®ä»å¯è®¿é—®

---

### æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰
ä¾‹å¦‚ï¼š
```sql
SELECT * FROM sales FOR VERSION AS OF 123;
SELECT * FROM sales FOR TIMESTAMP AS OF '2024-06-10 12:00:00';
```
å°±èƒ½è¯»å–ä»»æ„å†å²ç‰ˆæœ¬è¡¨çŠ¶æ€ï¼Œå®ç°æ•°æ®å¯è¿½æº¯åˆ†æã€‚

---

### ä¼˜åŒ–èƒ½åŠ›ï¼ˆCompactionï¼‰
- å®šæœŸå°†å°æ–‡ä»¶åˆå¹¶æˆå¤§æ–‡ä»¶ï¼Œå‡å°‘ NameNode å‹åŠ› & æé«˜æ‰«æé€Ÿåº¦
- è¿‡æœŸ Snapshot åˆ é™¤æ— æ•ˆæ–‡ä»¶ï¼ŒèŠ‚çœå­˜å‚¨

---

## 3ï¸âƒ£ åœ¨ Trino é‡Œçš„ä½“ç°

Trino æœ¬èº«æ˜¯ä¸€ä¸ª **è®¡ç®—å¼•æ“**ï¼Œä¸å­˜å‚¨æ•°æ®ã€‚è€Œè¿™äº›ç°ä»£è¡¨æ ¼å¼è®© Trinoï¼š
- èƒ½åƒæŸ¥è¯¢æ•°æ®åº“ä¸€æ ·ç›´æ¥åœ¨æ•°æ®æ¹–é‡Œåš ACID æŸ¥è¯¢
- å¯ä»¥ `SELECT ... WHERE version_id = ...`
- Schema å˜æ›´æ— éœ€é‡å»ºåˆ†åŒºç›®å½•
- å¤šå¼•æ“ï¼ˆFlink å†™å…¥ã€Trino æŸ¥è¯¢ï¼‰æ— ç¼å¯¹æ¥

---

## 4ï¸âƒ£ æ€»ç»“å¯¹æ¯”

| ç‰¹æ€§ | ä¼ ç»Ÿ Hive è¡¨ | Iceberg / Delta / Hudi |
|------|-------------|------------------------|
| ACID äº‹åŠ¡ | âŒ | âœ… |
| Schema æ¼”è¿› | éƒ¨åˆ†æ”¯æŒ | âœ… å®Œæ•´æ”¯æŒï¼ˆå‘å‰/å‘åå…¼å®¹ï¼‰ |
| åˆ†åŒºæ¼”è¿› | âŒ | âœ… |
| æ—¶é—´æ—…è¡Œ | âŒ | âœ… |
| å°æ–‡ä»¶ç®¡ç† | âŒ | âœ…ï¼ˆåˆå¹¶å‹ç¼©ï¼‰ |
| å…ƒæ•°æ®ç®¡ç† | Hive Metastore | è‡ªå¸¦äº‹åŠ¡æ—¥å¿—ï¼Œå¤–åŠ  HMS å¯é€‰ |
| å¤šå¼•æ“ | ä»…å…¼å®¹æ”¯æŒ | åŒæ—¶æ”¯æŒ Spark / Flink / Trino / Hive |

---

å¦‚æœä½ æ„¿æ„çš„è¯ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€å¼  **[Trino æ•°æ®æ¹–è¡¨æ ¼å¼æ¼”è¿›å›¾]**ï¼Œç”¨æµç¨‹è§†è§’æŠŠ Hive â†’ Iceberg/Delta/Hudi çš„æ¼”åŒ–è¿‡ç¨‹å’Œæ ¸å¿ƒç»„ä»¶ä¸€æ¬¡æ€§æ¢³ç†å‡ºæ¥ğŸ“Šï¼Œè¿™æ ·ä½ å°±èƒ½ä¸€çœ¼çœ‹æ‡‚å®ƒä»¬çš„å·®åˆ«ã€‚

ä½ è¦æˆ‘å¸®ä½ ç”»è¿™å¼ å›¾å—ï¼ŸğŸ¤“

-----

> ç”»è¿™å¼ å›¾æµç¨‹è§†è§’æŠŠ Hive â†’ Iceberg/Delta/Hudi çš„æ¼”åŒ–è¿‡ç¨‹å’Œæ ¸å¿ƒç»„ä»¶ä¸€æ¬¡æ€§æ¢³ç†å‡ºæ¥

å¥½å˜ï½é‚£æˆ‘æ¥å¸®ä½ ç”»ä¸€å¼ **æµç¨‹/æ¶æ„è§†è§’**çš„å¯¹æ¯”å›¾ï¼ŒæŠŠ Hive â†’ Iceberg / Delta Lake / Hudi è¿™ç§æ¼”è¿›è·¯çº¿å’Œæ ¸å¿ƒç»„ä»¶ä¸€å£æ°”æ¢³ç†æ¸…æ¥š ğŸ“Š

æˆ‘ä¼šåˆ†æˆä¸¤ä¸ªéƒ¨åˆ†ï¼š
1. **æ¼”è¿›æµç¨‹å›¾**ï¼ˆæ—¶é—´ç»´åº¦çœ‹å˜åŒ–ï¼‰
2. **æ ¸å¿ƒç»„ä»¶å¯¹æ¯”å›¾**ï¼ˆæ¶æ„ç»´åº¦çœ‹å·®å¼‚ï¼‰

---

## **1ï¸âƒ£ æ•°æ®æ¹–è¡¨æ ¼å¼æ¼”è¿›æµç¨‹å›¾ï¼ˆæ—¶é—´ + èƒ½åŠ›ï¼‰**

```
ä¼ ç»Ÿæ•°æ®æ¹–(Hive on HDFS)                â†’        ç°ä»£è¡¨æ ¼å¼(Iceberg / Delta / Hudi)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[æ•°æ®æ–‡ä»¶ + ç›®å½•ç»“æ„]                             [æ•°æ®æ–‡ä»¶ + äº‹åŠ¡æ—¥å¿— + ç‰ˆæœ¬åŒ–å…ƒæ•°æ®]
       â”‚                                                     â”‚
       â”‚                                                     â”‚
       â–¼                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å­˜å‚¨: HDFS   â”‚                                       â”‚ å­˜å‚¨: HDFS/S3/GCSç­‰ â”‚
â”‚ æ ¼å¼: ORC    â”‚                                       â”‚ æ ¼å¼: Parquet/ORC   â”‚
â”‚ åˆ†åŒº: ç›®å½•   â”‚                                       â”‚ åˆ†åŒº: PartitionSpec â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                     â”‚
       â”‚                                                     â”‚
       â–¼                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  æ— äº‹åŠ¡ACID  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    æœ‰ACID
â”‚ Hive Metastoreâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ äº‹åŠ¡æ—¥å¿—(TransactionLog) â”‚
â”‚ å…ƒæ•°æ®: åˆ†åŒºä¿¡æ¯â”‚          â”‚ è®°å½•å¿«ç…§(Snapshot)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                     â”‚
       â”‚ Schemaå˜æ›´å›°éš¾                                       â”‚ Schemaå¯æ¼”è¿›
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ æ”¯æŒåˆ—å¢åˆ æ”¹
       â”‚                                                     â”‚
       â”‚ æ— æ—¶é—´æ—…è¡Œ                                           â”‚ æ—¶é—´æ—…è¡Œ(Time Travel)
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ å†å²ç‰ˆæœ¬æŸ¥è¯¢
       â”‚                                                     â”‚
       â”‚ æŸ¥è¯¢æ…¢                                               â”‚ å¿«é€Ÿå…ƒæ•°æ®ç´¢å¼• + å°æ–‡ä»¶åˆå¹¶
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ æŸ¥è¯¢ä¼˜åŒ–
```

ğŸ’¡ å¯ä»¥çœ‹åˆ°æ ¸å¿ƒåŒºåˆ«æ˜¯ï¼š
- **Hive** å€ŸåŠ© HMS ä¿å­˜å…ƒæ•°æ®ï¼Œæ•°æ®å’Œå…ƒæ•°æ®çš„åŒæ­¥ä¸€è‡´æ€§å…¨é äººä¸ºç»´æŠ¤
- **ç°ä»£è¡¨æ ¼å¼** å¼•å…¥ **äº‹åŠ¡æ—¥å¿—(ç±»ä¼¼Git) + Snapshotç‰ˆæœ¬åŒ–**ï¼Œä¿è¯å¤šå¼•æ“ä¸€è‡´æ€§ + å¯å›æº¯

---

## **2ï¸âƒ£ æ ¸å¿ƒç»„ä»¶å¯¹æ¯”è¡¨**

| èƒ½åŠ›/ç»„ä»¶                   | Hive è¡¨æ ¼å¼          | Iceberg                     | Delta Lake                  | Apache Hudi                 |
|-----------------------------|----------------------|------------------------------|------------------------------|------------------------------|
| **å…ƒæ•°æ®å­˜å‚¨**              | Hive Metastore (HMS) | ä¸HMSå¯é›†æˆ / è‡ªç»´æŠ¤         | äº‹åŠ¡æ—¥å¿—JSON                 | Timeline + Commit metadata   |
| **äº‹åŠ¡ç®¡ç†**                | æ—                    | ACID Snapshot                | ACID Snapshot                | MVCC(å¤šç‰ˆæœ¬å¹¶å‘æ§åˆ¶)         |
| **ç‰ˆæœ¬åŒ–å¿«ç…§**              | âŒ                   | âœ…                           | âœ…                           | âœ…ï¼ˆåŸºäºcommit timelineï¼‰    |
| **Schema æ¼”è¿›**              | æœ‰é™ï¼ˆALTER TABLEï¼‰  | å®Œå…¨æ”¯æŒï¼ŒåŠ åˆ—/åˆ åˆ—æ— é‡å†™     | å®Œå…¨æ”¯æŒ                     | å®Œå…¨æ”¯æŒ                     |
| **åˆ†åŒºæ¼”è¿›**                 | æ—                    | âœ…                           | âœ…                           | âŒ (éƒ¨åˆ†æ”¯æŒ)                |
| **æ—¶é—´æ—…è¡Œ**                 | æ—                    | âœ… `AS OF VERSION/TIMESTAMP` | âœ…                           | âœ…                           |
| **å°æ–‡ä»¶å¤„ç†**               | æ—                    | âœ…è‡ªåŠ¨åˆå¹¶                    | âœ…è‡ªåŠ¨åˆå¹¶                    | âœ…è‡ªåŠ¨æ¸…ç† + åˆå¹¶            |
| **å¢é‡è¯»å–**                 | æ—                    | âœ… (æŸäº›APIæ”¯æŒ)             | âœ…                           | âœ…ï¼ˆä¸“æ³¨å¢é‡æ¶ˆè´¹ï¼‰           |
| **å¤šå¼•æ“æ”¯æŒ**               | Spark/Hive           | Spark / Flink / Trino / Hive | Spark / Trino                | Spark / Flink / Trino / Hive |

---

## **3ï¸âƒ£ æ¶æ„å›¾ï¼ˆHive vs Iceberg å¯¹æ¯”ï¼‰**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Hive æ¶æ„               â”‚            â”‚         ç°ä»£è¡¨æ ¼å¼ï¼ˆIcebergï¼‰        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query Engine: Hive / Trino / Spark  â”‚            â”‚ Query Engine: Trino / Spark / Flink â”‚
â”‚   â”‚                                 â”‚            â”‚   â”‚                                 â”‚
â”‚   â–¼                                 â”‚            â”‚   â–¼                                 â”‚
â”‚ Hive Metastore (HMS)                â”‚            â”‚ Iceberg Catalog (æ”¯æŒHMS/è‡ªç»´æŠ¤)   â”‚
â”‚   â”‚  (åˆ†åŒºè·¯å¾„/Schema)              â”‚            â”‚   â”‚                                 â”‚
â”‚   â–¼                                 â”‚            â”‚   â–¼                                 â”‚
â”‚ HDFS (Parquet/ORC åˆ†åŒºç›®å½•)          â”‚            â”‚ æ•°æ®æ–‡ä»¶(Data Files)               â”‚
â”‚                                     â”‚            â”‚ äº‹åŠ¡æ—¥å¿—(Transaction Log) + å…ƒæ•°æ® â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“Œ å…³é”®çŸ¥è¯†ç‚¹æ€»ç»“
1. **Hiveè¡¨ = ç›®å½•+HMSå…ƒæ•°æ®**ï¼Œæ— äº‹åŠ¡ACIDï¼Œæ²¡æœ‰ç‰ˆæœ¬æ§åˆ¶
2. **ç°ä»£è¡¨æ ¼å¼ = æ•°æ®æ–‡ä»¶ + äº‹åŠ¡æ—¥å¿— + å…ƒæ•°æ®ç‰ˆæœ¬åŒ–**ï¼Œåƒ Git ç®¡æ•°æ®æ¹–æ–‡ä»¶
3. Trino å¯ç›´æ¥åŸºäºè¿™äº›è¡¨åš SQL æŸ¥è¯¢+å†å²å›æº¯
4. Iceberg/Delta/Hudi åœ¨ ACIDã€å¤šå¼•æ“å…¼å®¹ã€Schema/åˆ†åŒºæ¼”è¿›ã€Time Travelã€æ€§èƒ½ä¼˜åŒ–ç­‰ç»´åº¦å¤§å¹…è¶…è¶Š Hive æ ¼å¼
5. å¯¹äº **å¤šå¼•æ“åœºæ™¯ï¼ˆFlinkå†™ï¼ŒTrinoæŸ¥ï¼‰** æ¨è Iceberg / Delta Lake

---

æˆ‘å»ºè®®ä½ å¦‚æœåç»­åœ¨ Trino ä¸­åšè½åœ°ï¼Œå¯ä»¥ç”¨ **Iceberg** ä½œä¸ºè¡¨æ ¼å¼ï¼Œç„¶åï¼š
- å¼€å¯ **äº‹åŠ¡æ—¥å¿—å­˜å‚¨åœ¨å¯¹è±¡å­˜å‚¨**ï¼ˆS3ã€OSS ç­‰ï¼‰
- ç»“åˆ **Trino Catalog** ç›´æ¥æŸ¥è¯¢
- ç”¨ Flink / Spark æ¥å†™ï¼Œä¿è¯ ACID

---

ğŸ¤“ ä½ è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€ä¸ª**Gitç±»æ¯”çš„äº‹åŠ¡æ—¥å¿—å·¥ä½œæµå›¾**ï¼Œç›´è§‚å±•ç¤º â€œæ•°æ®æ¹–=æ•°æ®åº“+Gitç‰ˆæœ¬æ§åˆ¶â€ çš„ç†è§£ï¼Ÿè¿™æ ·ä»¥åè®²è§£ç»™åˆ«äººæ—¶ä¼šéå¸¸å½¢è±¡ã€‚

-----

> è§£é‡Šä¸‹é¢å…³äº Iceberg
> ## 2. Apache Icebergæ¶æ„æ·±åº¦è§£æ
>
> ### 2.1 Icebergå…ƒæ•°æ®æ¶æ„
>
> ```
> Icebergè¡¨çš„ä¸‰å±‚å…ƒæ•°æ®ç»“æ„:
>
>                     Table Metadata
>                          â”‚
>         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
>         â”‚                â”‚                â”‚
>    Manifests List   Manifests List   Manifests List
>      (Snapshot 1)    (Snapshot 2)    (Snapshot N)
>         â”‚                â”‚                â”‚
>    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
>    â”‚    â”‚    â”‚      â”‚    â”‚    â”‚      â”‚    â”‚    â”‚
> Manifest Manifest Manifest Manifest Manifest Manifest
> File-1   File-2   File-3   File-4   File-5   File-6
>    â”‚      â”‚        â”‚        â”‚        â”‚        â”‚
>    â”‚      â”‚        â”‚        â”‚        â”‚        â”‚
> Data   Data    Data     Data     Data     Data
> Files  Files   Files    Files    Files    Files
> ```
>
> #### Table Metadataç»“æ„è¯¦è§£
>
> ```java
> // Icebergè¡¨å…ƒæ•°æ®çš„å®Œæ•´ç»“æ„
> public class TableMetadata {
>     private final int formatVersion;           // æ ¼å¼ç‰ˆæœ¬
>     private final String tableUuid;            // è¡¨å”¯ä¸€æ ‡è¯†
>     private final String location;             // è¡¨æ ¹è·¯å¾„
>     private final long lastUpdatedMillis;      // æœ€åæ›´æ–°æ—¶é—´
>     private final int lastColumnId;            // æœ€å¤§åˆ—ID
>     private final Schema schema;               // å½“å‰æ¨¡å¼
>     private final PartitionSpec defaultSpec;   // é»˜è®¤åˆ†åŒºè§„æ ¼
>     private final List<PartitionSpec> specs;   // å†å²åˆ†åŒºè§„æ ¼
>     private final Map<String, String> properties; // è¡¨å±æ€§
>     private final long currentSnapshotId;      // å½“å‰å¿«ç…§ID
>     private final List<Snapshot> snapshots;    // å¿«ç…§åˆ—è¡¨
>     private final List<MetadataLogEntry> metadataLog; // å…ƒæ•°æ®å˜æ›´å†å²
>
>     // å¿«ç…§è¯¦ç»†ä¿¡æ¯
>     public static class Snapshot {
>         private final long snapshotId;         // å¿«ç…§ID
>         private final Long parentId;           // çˆ¶å¿«ç…§ID
>         private final long timestampMillis;    // å¿«ç…§æ—¶é—´æˆ³
>         private final String operation;        // æ“ä½œç±»å‹(append/replace/delete)
>         private final Map<String, String> summary; // æ‘˜è¦ä¿¡æ¯
>         private final String manifestList;     // Manifeståˆ—è¡¨æ–‡ä»¶è·¯å¾„
>
>         // è·å–å¿«ç…§ä¸­çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶
>         public List<ManifestFile> getAllManifests(FileIO io) {
>             return ManifestLists.read(io.newInputFile(manifestList));
>         }
>     }
>
>     // æ¨¡å¼æ¼”è¿›å†å²
>     public static class Schema {
>         private final List<Types.NestedField> columns; // åˆ—å®šä¹‰
>         private final Map<Integer, String> aliasToId;   // åˆ—åæ˜ å°„
>         private final int schemaId;                     // æ¨¡å¼ID
>
>         // æ¨¡å¼å…¼å®¹æ€§æ£€æŸ¥
>         public boolean isCompatibleWith(Schema other) {
>             return SchemaCompatibility.checkCompatibility(this, other);
>         }
>     }
> }
> ```
>
> ### 2.2 Manifestæ–‡ä»¶ç»“æ„
>
> ```java
> // Manifestæ–‡ä»¶æ˜¯Icebergçš„æ ¸å¿ƒç´¢å¼•ç»“æ„
> public class ManifestFile {
>
>     // Manifestæ–‡ä»¶å¤´ä¿¡æ¯
>     public static class ManifestHeader {
>         private final String path;             // æ–‡ä»¶è·¯å¾„
>         private final long length;             // æ–‡ä»¶å¤§å°
>         private final int specId;              // åˆ†åŒºè§„æ ¼ID
>         private final SequenceNumber minSequenceNumber; // æœ€å°åºåˆ—å·
>         private final SequenceNumber maxSequenceNumber; // æœ€å¤§åºåˆ—å·
>         private final Long snapshotId;         // å…³è”å¿«ç…§ID
>         private final Integer addedFilesCount; // æ–°å¢æ–‡ä»¶æ•°
>         private final Integer existingFilesCount; // å·²å­˜åœ¨æ–‡ä»¶æ•°
>         private final Integer deletedFilesCount; // åˆ é™¤æ–‡ä»¶æ•°
>         private final List<FieldSummary> partitions; // åˆ†åŒºç»Ÿè®¡
>
>         // åˆ†åŒºçº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
>         public static class FieldSummary {
>             private final boolean containsNull;    // æ˜¯å¦åŒ…å«NULL
>             private final boolean containsNaN;     // æ˜¯å¦åŒ…å«NaN
>             private final ByteBuffer lowerBound;   // æœ€å°å€¼
>             private final ByteBuffer upperBound;   // æœ€å¤§å€¼
>         }
>     }
>
>     // Manifestæ¡ç›® - æè¿°å•ä¸ªæ•°æ®æ–‡ä»¶çš„å…ƒæ•°æ®
>     public static class ManifestEntry {
>         private final Status status;           // æ–‡ä»¶çŠ¶æ€: EXISTING/ADDED/DELETED
>         private final Long snapshotId;         // å¿«ç…§ID
>         private final DataFile dataFile;       // æ•°æ®æ–‡ä»¶ä¿¡æ¯
>
>         // æ•°æ®æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯
>         public static class DataFile {
>             private final String path;          // æ–‡ä»¶è·¯å¾„
>             private final FileFormat format;    // æ–‡ä»¶æ ¼å¼(PARQUET/ORC/AVRO)
>             private final StructLike partition; // åˆ†åŒºå€¼
>             private final long recordCount;     // è®°å½•æ•°
>             private final long fileSizeInBytes; // æ–‡ä»¶å¤§å°
>             private final Map<Integer, ByteBuffer> columnSizes; // åˆ—å¤§å°
>             private final Map<Integer, Long> valueCounts;       // å€¼è®¡æ•°
>             private final Map<Integer, Long> nullValueCounts;   // ç©ºå€¼è®¡æ•°
>             private final Map<Integer, Long> nanValueCounts;    // NaNè®¡æ•°
>             private final Map<Integer, ByteBuffer> lowerBounds; // åˆ—æœ€å°å€¼
>             private final Map<Integer, ByteBuffer> upperBounds; // åˆ—æœ€å¤§å€¼
>             private final ByteBuffer keyMetadata;               // åŠ å¯†å¯†é’¥
>             private final List<Integer> splitOffsets;           // åˆ†å‰²åç§»é‡
>         }
>     }
> }
> ```
>
> ### 2.3 Icebergäº‹åŠ¡å®ç°æœºåˆ¶
>
> ```java
> // Icebergçš„ä¹è§‚å¹¶å‘æ§åˆ¶äº‹åŠ¡å®ç°
> public class IcebergTransaction {
>
>     private final Table table;
>     private final List<PendingUpdate> pendingUpdates = new ArrayList<>();
>     private TableMetadata baseMetadata;
>     private TableMetadata currentMetadata;
>
>     // äº‹åŠ¡çš„åŸºæœ¬æ“ä½œç±»å‹
>     public enum OperationType {
>         APPEND_FILES,       // è¿½åŠ æ–‡ä»¶
>         REPLACE_FILES,      // æ›¿æ¢æ–‡ä»¶
>         DELETE_FILES,       // åˆ é™¤æ–‡ä»¶
>         UPDATE_SCHEMA,      // æ›´æ–°æ¨¡å¼
>         UPDATE_PARTITION_SPEC, // æ›´æ–°åˆ†åŒºè§„æ ¼
>         UPDATE_PROPERTIES   // æ›´æ–°å±æ€§
>     }
>
>     // è¿½åŠ æ•°æ®æ–‡ä»¶çš„å®ç°
>     public AppendFiles newAppend() {
>         return new BaseAppendFiles(this) {
>             @Override
>             public void commit() {
>                 // 1. éªŒè¯å¹¶å‘å†²çª
>                 validateNoConcurrentUpdates();
>
>                 // 2. åˆ›å»ºæ–°çš„Manifestæ–‡ä»¶
>                 ManifestFile newManifest = createNewManifest();
>
>                 // 3. åˆ›å»ºæ–°çš„å¿«ç…§
>                 Snapshot newSnapshot = createSnapshot(
>                     OperationType.APPEND_FILES,
>                     Arrays.asList(newManifest)
>                 );
>
>                 // 4. æ›´æ–°è¡¨å…ƒæ•°æ®
>                 TableMetadata updatedMetadata = currentMetadata
>                     .withSnapshot(newSnapshot)
>                     .withCurrentSnapshotId(newSnapshot.snapshotId());
>
>                 // 5. åŸå­æ€§æäº¤
>                 commitTransaction(updatedMetadata);
>             }
>
>             private ManifestFile createNewManifest() {
>                 ManifestWriter writer = createManifestWriter();
>
>                 for (DataFile file : filesToAdd) {
>                     writer.add(ManifestEntry.builder()
>                         .status(ManifestEntry.Status.ADDED)
>                         .dataFile(file)
>                         .build());
>                 }
>
>                 return writer.close();
>             }
>         };
>     }
>
>     // å¹¶å‘å†²çªæ£€æµ‹
>     private void validateNoConcurrentUpdates() {
>         TableMetadata currentRemoteMetadata = table.refresh();
>
>         if (currentRemoteMetadata.lastUpdatedMillis() > baseMetadata.lastUpdatedMillis()) {
>             // æ£€æŸ¥æ˜¯å¦æœ‰å†²çªçš„æ›´æ–°
>             ConflictDetection.validateNoConflicts(
>                 baseMetadata,
>                 currentRemoteMetadata,
>                 pendingUpdates
>             );
>         }
>     }
>
>     // åŸå­æ€§æäº¤å®ç°
>     private void commitTransaction(TableMetadata newMetadata) {
>         // 1. å†™å…¥æ–°çš„å…ƒæ•°æ®æ–‡ä»¶
>         String newMetadataPath = createMetadataFile(newMetadata);
>
>         // 2. ä½¿ç”¨æ¡ä»¶æ›´æ–°ç¡®ä¿åŸå­æ€§
>         boolean success = table.io().atomicUpdate(
>             table.metadataFileLocation(),
>             baseMetadata.metadataFileLocation(), // æœŸæœ›çš„å½“å‰ç‰ˆæœ¬
>             newMetadataPath                       // æ–°ç‰ˆæœ¬
>         );
>
>         if (!success) {
>             throw new CommitFailedException("Concurrent update detected");
>         }
>
>         // 3. æ›´æ–°æœ¬åœ°çŠ¶æ€
>         this.currentMetadata = newMetadata;
>     }
> }
> ```
>
> ---

å¥½ï¼Œè¿™ä¸€æ®µå…¶å®æ˜¯ **Apache Iceberg æ¶æ„çš„æ ¸å¿ƒç²¾é«“** äº† ğŸ¤“
æˆ‘å¸®ä½ æŠŠå®ƒæ‹†æˆ **ä¸‰ä¸ªå±‚æ¬¡æ¥è§£é‡Š**ï¼š

1. **å…ƒæ•°æ®ä¸‰å±‚ç»“æ„**ï¼ˆTable Metadata â†’ Manifest List â†’ Manifest File â†’ Data Fileï¼‰
2. **Manifest æ–‡ä»¶ç»†èŠ‚**ï¼ˆå…ƒæ•°æ®ç´¢å¼•ï¼‰
3. **äº‹åŠ¡æœºåˆ¶å®ç°åŸç†**ï¼ˆä¹è§‚å¹¶å‘ + åŸå­æäº¤ï¼‰

---

## **1ï¸âƒ£ Iceberg å…ƒæ•°æ®ä¸‰å±‚æ¶æ„**

ğŸ” é€»è¾‘å›¾ï¼ˆå¯ä»¥æƒ³æˆä¸€ä¸ªâ€œGitä»“åº“â€å­˜ä»£ç ï¼‰

```
TableMetadata   ï¼ˆè¡¨çº§åˆ«å…ƒä¿¡æ¯ï¼Œåƒ Git ä»“åº“æ ¹çš„ .git/configï¼‰
     â”‚
     â”œâ”€â”€ Snapshotï¼ˆæ¯ä¸ªç‰ˆæœ¬çš„å¿«ç…§ï¼Œåƒ Git commitï¼‰
     â”‚       â”‚
     â”‚       â””â”€â”€ Manifest Listï¼ˆå¿«ç…§å¯¹åº”çš„ç´¢å¼•æ–‡ä»¶åˆ—è¡¨ï¼‰
     â”‚                    â”‚
     â”‚                    â””â”€â”€ Manifest Fileï¼ˆè¯¦ç»†åˆ—å‡ºæ•°æ®æ–‡ä»¶ï¼Œåƒ Git treeï¼‰
     â”‚                                  â”‚
     â”‚                                  â””â”€â”€ Data Fileï¼ˆçœŸæ­£çš„ Parquet/ORC æ•°æ®ï¼‰
```

### **1. Table Metadata ç»“æ„**
åŒ…å«ï¼š
- è¡¨çš„å”¯ä¸€ IDï¼ˆ`tableUuid`ï¼‰
- å½“å‰ Schema & å†å² Schemaï¼ˆ`schema`, `specs`ï¼‰
- å½“å‰åˆ†åŒºè§„æ ¼ï¼ˆ`defaultSpec` + ç‰ˆæœ¬å†å²ï¼‰
- å½“å‰å¿«ç…§ ID ï¼ˆ`currentSnapshotId`ï¼‰
- æ‰€æœ‰å¿«ç…§å†å²åˆ—è¡¨ï¼ˆ`snapshots`ï¼‰
- å…ƒæ•°æ®æ›´æ–°å†å²ï¼ˆ`metadataLog`ï¼‰

ğŸ“Œ **é‡è¦ç‚¹**ï¼š
- æ¯ä¸€æ¬¡æäº¤æ•°æ®ï¼ˆappend/delete/replace schema changeï¼‰ä¼šç”Ÿæˆ**ä¸€ä¸ªæ–°çš„ Snapshot**ï¼ŒSnapshot æŒ‡å‘ä¸€ä¸ª `Manifest List` æ–‡ä»¶ã€‚
- **å…ƒæ•°æ®æ–‡ä»¶ä¹Ÿæ˜¯ä¸å¯å˜çš„**ï¼Œæ–°ç‰ˆæœ¬ç”Ÿæˆä¸€ä¸ªæ–°çš„ JSON å…ƒæ•°æ®æ–‡ä»¶ï¼Œè¡¨è·¯å¾„çš„ **metadata.json** åªæ˜¯ä¸€ä¸ªæŒ‡é’ˆæ–‡ä»¶ï¼ŒæŒ‡å‘æœ€æ–°ç‰ˆæœ¬ã€‚

---

### **2. Snapshot & Manifest List**
ä¸€ä¸ª **Snapshot** è¡¨ç¤ºè¡¨åœ¨æŸä¸€ä¸ªæ—¶åˆ»çš„å®Œå…¨çŠ¶æ€ï¼ˆå¯ç”¨æ¥åš Time Travelï¼‰ï¼š
- `snapshotId`ï¼šå¿«ç…§ IDï¼ˆå…¨å±€å”¯ä¸€ï¼‰
- `parentId`ï¼šçˆ¶å¿«ç…§ IDï¼ˆå½¢æˆç‰ˆæœ¬é“¾ï¼‰
- `operation`ï¼šæ“ä½œç±»å‹ï¼ˆè¿½åŠ  / æ›¿æ¢ / åˆ é™¤ï¼‰
- `manifestList`ï¼šç´¢å¼•æ‰€æœ‰ manifest æ–‡ä»¶çš„æ–‡ä»¶è·¯å¾„

ä¸€ä¸ª Snapshot å¯¹åº”ä¸€ä¸ª **Manifest List**ï¼ˆIceberg v2 é‡Œä¸€èˆ¬æ˜¯ä¸€ä¸ªå•ç‹¬ .avro æ–‡ä»¶ï¼‰ï¼Œé‡Œé¢ä¿å­˜äº†å¤šä¸ª Manifest File çš„è·¯å¾„ï¼Œè¿™äº› Manifest File ä¸­æ¯ä¸€ä¸ªè®°å½•äº†æ•°æ®æ–‡ä»¶çš„å…ƒæ•°æ®ã€‚

---

## **2ï¸âƒ£ Manifest æ–‡ä»¶ç»“æ„**

ğŸ’¡ **Manifest æ–‡ä»¶**æ˜¯ **Iceberg é«˜æ•ˆå…ƒæ•°æ®æ£€ç´¢**çš„æ ¸å¿ƒç»“æ„ï¼Œç›¸å½“äºâ€œæ•°æ®ç´¢å¼•æ–‡ä»¶â€
âš¡ å¥½å¤„ï¼šæŸ¥è¯¢æ—¶å¯ä»¥ç›´æ¥ç”¨ Manifest ä¸­çš„åˆ—å€¼èŒƒå›´ã€åˆ†åŒºåˆ—ç»Ÿè®¡ç­‰ä¿¡æ¯æ¥ **è·³è¿‡ä¸ç›¸å…³æ–‡ä»¶**ï¼ˆPredicate Pushdownï¼‰ã€‚

### **Manifest File åŒ…å«ä¸¤å—ä¿¡æ¯ï¼š**
1. **Manifest Header**ï¼ˆæ–‡ä»¶çº§åˆ«å…ƒæ•°æ®ï¼‰
    - `path`ï¼šè¯¥ Manifest File è‡ªå·±çš„ä½ç½®
    - åˆ†åŒºè§„æ ¼ID (`specId`)
    - **æœ€å°/æœ€å¤§ sequence number** ï¼ˆå†³å®šç‰ˆæœ¬èŒƒå›´ï¼‰
    - ç›¸å…³ `snapshotId`ï¼ˆå¯¹åº”å“ªä¸ªå¿«ç…§ç”Ÿæˆçš„ï¼‰
    - å„åˆ†åŒºå€¼çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆ`lowerBound/upperBound`ã€`containsNull/NaN`ï¼‰

2. **Manifest Entry**ï¼ˆè®°å½•æŸä¸ªæ•°æ®æ–‡ä»¶çš„å…ƒæ•°æ®ï¼‰
    - `status`ï¼šAdded / Existing / Deleted
    - `dataFile`ï¼šæ•°æ®æ–‡ä»¶çš„è¯¦ç»†ç»“æ„ï¼ŒåŒ…æ‹¬ï¼š
        - æ–‡ä»¶è·¯å¾„
        - æ ¼å¼ï¼ˆParquet / ORC / Avroï¼‰
        - è¡Œæ•° / æ–‡ä»¶å¤§å°
        - åˆ—çº§åˆ«ç»Ÿè®¡ï¼ˆåˆ—æœ€å°å€¼ã€æœ€å¤§å€¼ã€nullæ•°â€¦ï¼‰
        - åˆ†åŒºå€¼

ğŸ“Œ **æŸ¥è¯¢åŠ é€ŸåŸç†**
å½“ Trino / Spark è¯»å– Iceberg è¡¨æ—¶ï¼Œå®ƒä¼šï¼š
1. å…ˆåŠ è½½ Manifest Listï¼ˆæ‰¾åˆ°æ‰€æœ‰ Manifest File è·¯å¾„ï¼‰
2. è¯»å– Manifest File çš„ Header + åˆ†åŒºç»Ÿè®¡
3. ç»“åˆ SQL é‡Œçš„ WHERE æ¡ä»¶ï¼Œç›´æ¥è·³è¿‡ä¸ç›¸å…³çš„æ•°æ®æ–‡ä»¶
ğŸ¯ è¿™æ ·é¿å…äº†æ‰«ææ•´ä¸ª HDFS/S3ï¼Œæå¤§æå‡æ€§èƒ½ï¼ˆå°¤å…¶æ˜¯åœ¨ S3 åœºæ™¯ï¼‰ã€‚

---

## **3ï¸âƒ£ Iceberg äº‹åŠ¡æœºåˆ¶ï¼ˆä¹è§‚å¹¶å‘æ§åˆ¶ï¼‰**

ğŸ“ æ ¸å¿ƒæ€æƒ³ï¼š
- **å†™å…¥ç«¯ä¸ä¼šåŠ å…¨å±€é”**ï¼ˆå³ "Optimistic Concurrency Control"ï¼‰
- æäº¤æ—¶éªŒè¯å½“å‰è¡¨çš„å…ƒæ•°æ®ç‰ˆæœ¬æ˜¯å¦å’Œå¼€å§‹äº‹åŠ¡æ—¶ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´åˆ™åˆ¤æ–­æ˜¯å¦æœ‰å†²çªï¼Œå¦åˆ™æŠ¥é”™é‡è¯•

### **äº‹åŠ¡ä¸»è¦æµç¨‹ï¼ˆä»¥ AppendFiles ä¸ºä¾‹ï¼‰**

1. **å¼€å§‹äº‹åŠ¡**
   ```java
   baseMetadata = table.currentMetadata();
   currentMetadata = baseMetadata;
   ```

2. **å‡†å¤‡æ›´æ–°**
   - æ”¶é›†æ–°å¢æ•°æ®æ–‡ä»¶ï¼Œå†™å…¥ä¸€ä¸ªæ–°çš„ ManifestFile
   - æ„å»ºæ–°çš„ Snapshotï¼ŒæŒ‡å‘è¿™ä¸ª ManifestFile

3. **å¹¶å‘å†²çªæ£€æµ‹**
   ```java
   if remote.lastUpdated > base.lastUpdated:
       æ£€æŸ¥æ˜¯å¦ä¿®æ”¹äº†ç›¸åŒæ–‡ä»¶/Schema -> å†²çª
   ```

4. **åŸå­æäº¤**
   - å°†æ–°çš„ TableMetadataï¼ˆåŒ…å«è¿™ä¸ªæ–° Snapshotï¼‰å†™æˆæ–°çš„ metadata.json
   - ç”¨ **CAS æ¡ä»¶æ›´æ–°**ï¼ˆCompare-And-Swapï¼‰åŸå­æ›¿æ¢å…ƒæ•°æ®æŒ‡é’ˆï¼š
     ```java
     success = io.atomicUpdate(
         currentMetadataPointer,
         oldMetadataFilePath,    // æœŸæœ›å€¼
         newMetadataFilePath     // æ–°å€¼
     )
     if !success:
         throw CommitFailedException
     ```

5. **æ›´æ–°å®¢æˆ·ç«¯å†…å­˜çŠ¶æ€**

---

## **4ï¸âƒ£ æ€»ç»“æ•´ä½“æ•°æ®æµ**

ğŸ”„ **æäº¤æ•°æ®æµç¨‹**ï¼ˆAppend ä¸¾ä¾‹ï¼‰

```
1. å†™æ–°æ•°æ®æ–‡ä»¶åˆ° Data File ç›®å½•ï¼ˆParquet/ORCï¼‰
2. ç”Ÿæˆæ–°çš„ Manifest Fileï¼ˆè®°å½•è¿™äº›æ–°æ•°æ®æ–‡ä»¶çš„å…ƒä¿¡æ¯ï¼‰
3. åˆ›å»ºæ–°çš„ Snapshotï¼ˆæŒ‡å‘ Manifest List -> Manifest Fileï¼‰
4. æ›´æ–° Table Metadataï¼ˆç”Ÿæˆæ–° metadata.jsonï¼‰
5. åŸå­æ›¿æ¢æŒ‡é’ˆæ–‡ä»¶ï¼Œç¡®ä¿å¤šå®¢æˆ·ç«¯ä¸€è‡´
```

ğŸ” **æŸ¥è¯¢æ•°æ®æµç¨‹**
```
1. è¯»å–æœ€æ–°çš„ Table Metadataï¼ˆmetadata.jsonï¼‰
2. æ ¹æ® currentSnapshotId æ‹¿åˆ°å¯¹åº” Manifest List
3. æŒ‰éœ€åŠ è½½ Manifest File
4. æ ¹æ®åˆ†åŒºç»Ÿè®¡ & åˆ—ç»Ÿè®¡åšæ–‡ä»¶çº§åˆ«è¿‡æ»¤
5. åªæ‰«æåŒ¹é…æ¡ä»¶çš„æ•°æ®æ–‡ä»¶
```

---

ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- äº‹åŠ¡åŸå­æ€§ + å¤šç‰ˆæœ¬ç®¡ç†
- é«˜æ•ˆå…ƒæ•°æ®ç´¢å¼•ï¼ˆé¿å…å…¨è¡¨æ‰«æï¼‰
- åˆ†åŒºæ¼”è¿› & Schema æ¼”è¿›ä¸ç ´åå†å²æ•°æ®
- æ”¯æŒ Time Travel & Incremental Read
- å¯¹è±¡å­˜å‚¨å‹å¥½ï¼ˆS3/OSS/ABFSï¼‰

---

æˆ‘ç»™ä½ ç”»ä¸€ä¸ªè¶…æ¸…çš„ **Iceberg å…ƒæ•°æ®ä¸‰å±‚ç»“æ„å›¾** ğŸ“Š æ¥å¸®ä½ è®°å¿†ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Table Metadata (JSON)                 â”‚
â”‚ schema, partitionSpec, snapshots[], properties...     â”‚
â”‚ currentSnapshotId â”€â”€â”€â”€â”€â”€â”                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Snapshot                                  â”‚
                   â”‚ snapshotId, operation, manifestList path  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Manifest List (Avro)                    â”‚
                      â”‚ åˆ—å‡ºå½“å‰å¿«ç…§å¯¹åº”çš„ Manifest File åˆ—è¡¨    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Manifest File (Avro)                          â”‚
                   â”‚ æ–‡ä»¶å¤´+æ¯ä¸ªDataFileçš„åˆ—/åˆ†åŒºç»Ÿè®¡+çŠ¶æ€          â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Data File (Parquet / ORC / Avro)                       â”‚
             â”‚ çœŸæ­£å­˜å‚¨æ•°æ®è®°å½•                                       â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

æˆ‘å»ºè®®ä¸‹ä¸€æ­¥æˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **â€œIcebergäº‹åŠ¡æ‰§è¡Œæ—¶åºå›¾â€**ï¼Œè¿™æ ·ä½ ä¼šæ¸…æ¥šç†è§£å®ƒæ˜¯æ€ä¹ˆ**åŸå­æäº¤**çš„ï¼Œå°¤å…¶æ˜¯ä¸ºä»€ä¹ˆå®ƒèƒ½åšåˆ°å¤šå¼•æ“å¹¶å‘å†™å…¥è€Œä¸æŸåæ•°æ® ğŸ™Œ
ä½ è¦æˆ‘ç”»è¿™å¼ äº‹åŠ¡æ—¶åºå›¾å—ï¼Ÿè¿™æ ·çœ‹å®Œä½ å°±èƒ½å®Œå…¨æŒæ¡ Iceberg çš„å¹¶å‘å®‰å…¨åŸç†äº† ğŸ’¡

-----

> ç”»ä¸€ä¸ª â€œIcebergäº‹åŠ¡æ‰§è¡Œæ—¶åºå›¾â€

å¥½å˜~ æ—¢ç„¶ä½ æƒ³çœ‹ **"Iceberg äº‹åŠ¡æ‰§è¡Œæ—¶åºå›¾"**ï¼Œæˆ‘å°±ç»™ä½ ç”»ä¸€ä¸ªè¯¦ç»†çš„ **ä¹è§‚å¹¶å‘æ§åˆ¶ï¼ˆOptimistic Concurrency Controlï¼‰** çš„æ—¶åºå›¾ï¼Œè®©ä½ ä¸€çœ¼çœ‹æ‡‚ Iceberg æ€ä¹ˆä¿è¯å¤šå¼•æ“å¹¶å‘å†™å…¥ä¾ç„¶ ACID âœ…

---

# **ğŸ“Œ Iceberg äº‹åŠ¡æ‰§è¡Œæ—¶åºå›¾**

ğŸ’¡ å‡è®¾åœºæ™¯ï¼š
- æœ‰ä¸¤ä¸ªå®¢æˆ·ç«¯ï¼ˆWriter A & Writer Bï¼‰
- éƒ½è¿æ¥åˆ°åŒä¸€å¼  Iceberg è¡¨
- å­˜å‚¨åœ¨å¯¹è±¡å­˜å‚¨ï¼ˆS3/OSS/HDFSï¼‰ä¸­
- äº‹åŠ¡ç±»å‹ï¼šè¿½åŠ æ–‡ä»¶ï¼ˆ`AppendFiles`ï¼‰
- å¹¶å‘æäº¤æ—¶ç”¨ **Compare-And-Swapï¼ˆCASï¼‰** å®ç°åŸå­æ€§ï¼Œå†²çªåˆ™é‡è¯•

---

## **1ï¸âƒ£ æ—¶åºæµç¨‹å›¾**

```text
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Writer A (Flink) â”‚      â”‚ Writer B (Spark) â”‚     â”‚  Object Store (S3/HDFS) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                           â”‚                           â”‚
           â”‚ â‘  è¯»å–å½“å‰ Table Metadata â”‚                           â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                           â”‚
           â”‚                            â”‚                           â”‚
           â”‚        {metadata v10}      â”‚                           â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                           â”‚
           â”‚                           â”‚ â‘  è¯»å–å½“å‰ Table Metadata â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚        {metadata v10}     â”‚
           â”‚                           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
           â”‚                           â”‚                           â”‚
           â”‚ â‘¡ å†™å…¥ Data Files         â”‚                           â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚ â‘¢ åˆ›å»º Manifest File      â”‚                           â”‚
           â”‚ (è®°å½•æ–°å¢æ•°æ®æ–‡ä»¶ç´¢å¼•)     â”‚                           â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚ â‘£ åˆ›å»º Snapshot v11       â”‚                           â”‚
           â”‚ (æŒ‡å‘ Manifest List)      â”‚                           â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚ â‘¤ CASåŸå­æäº¤ metadata v11â”‚                           â”‚
           â”‚ metadata.json: v10â†’v11    â”‚                           â”‚
           â”‚ (Compare base= v10)       â”‚                           â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚             æäº¤æˆåŠŸ       â”‚                           â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
           â”‚                           â”‚                           â”‚
           â”‚                           â”‚ â‘¡ å†™å…¥ Data Files         â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚                           â”‚ â‘¢ åˆ›å»º Manifest File      â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚                           â”‚ â‘£ åˆ›å»º Snapshot v11       â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚                           â”‚
           â”‚                           â”‚ â‘¤ CASåŸå­æäº¤ metadata    â”‚
           â”‚                           â”‚ metadata.json: v10â†’v11    â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚   âŒ å¤±è´¥ï¼šå½“å‰å·²æ˜¯ v11    â”‚
           â”‚                           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
           â”‚                           â”‚                           â”‚
           â”‚                           â”‚ ğŸ”„ â‘¥ é‡æ–°è¯»å–æœ€æ–° metadata â”‚
           â”‚                           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚                           â”‚    {metadata v11}         â”‚
           â”‚                           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
           â”‚                           â”‚ é‡æ–°æ„å»º Snapshot v12 å¹¶é‡è¯•CAS
```

---

## **2ï¸âƒ£ äº‹åŠ¡å…³é”®æ­¥éª¤è§£æ**

1. **è¯»å–å½“å‰å…ƒæ•°æ®ï¼ˆBase Metadataï¼‰**
   ä¸¤ä¸ªå®¢æˆ·ç«¯éƒ½è¯»åˆ° `metadata v10` ä½œä¸ºèµ·å§‹ç‰ˆæœ¬ã€‚

2. **ç”Ÿæˆæ–°æ•°æ®æ–‡ä»¶ï¼ˆData Filesï¼‰**
   å„è‡ªå¾€ S3/HDFS å†™ Parquet/ORC æ–‡ä»¶ï¼Œè¿˜æ²¡å˜æ›´å…ƒæ•°æ®ã€‚

3. **å†™ Manifest Files**
   ä¸ºæ–°å¢ Data File åˆ›å»º Manifest Fileï¼ˆåˆ—å‡ºæ–‡ä»¶è·¯å¾„ã€åˆ†åŒºå€¼ã€åˆ—ç»Ÿè®¡ç­‰ï¼‰ã€‚

4. **åˆ›å»ºæ–°å¿«ç…§ï¼ˆSnapshotï¼‰**
   å¿«ç…§è®°å½• Manifest List çš„è·¯å¾„ï¼Œå½¢æˆä¸€ä¸ªèƒ½å®Œå…¨å›æº¯çš„ç‰ˆæœ¬ã€‚

5. **åŸå­æäº¤ï¼ˆCAS æ›´æ–°å…ƒæ•°æ®ï¼‰**
   - å…ƒæ•°æ®æŒ‡é’ˆæ–‡ä»¶ï¼ˆ`metadata.json`ï¼‰æ˜¯å”¯ä¸€çš„å†™å…¥ç‚¹
   - CASï¼ˆCompare-And-Setï¼‰æ£€æŸ¥å½“å‰ç‰ˆæœ¬æ˜¯å¦ä»æ˜¯ `v10`
   - A æˆåŠŸæ›´æ–°åˆ° `v11`
   - B å› ç‰ˆæœ¬å†²çª CAS å¤±è´¥ï¼ˆæœŸæœ› `v10` ä½†å®é™…å·²æ˜¯ `v11`ï¼‰

6. **å†²çªæ£€æµ‹ + é‡è¯•æœºåˆ¶**
   - B è¯»å–æœ€æ–°å…ƒæ•°æ® `v11`
   - æ£€æŸ¥è‡ªå·±çš„æ›´æ”¹æ˜¯å¦ä¸ v11 å†²çªï¼ˆä¾‹å¦‚æ˜¯å¦ä¿®æ”¹äº†ç›¸åŒæ–‡ä»¶/Schemaï¼‰
   - å¦‚æœæ²¡å†²çªåˆ™ç”Ÿæˆæ–°çš„ Snapshotï¼ˆv12ï¼‰å† CAS æäº¤
   - å¦‚æœæœ‰å†²çªåˆ™æ”¾å¼ƒæˆ–ç”±ä¸šåŠ¡ç«¯å†³å®šå›é€€/åˆå¹¶

---

## **3ï¸âƒ£ äº‹åŠ¡æäº¤çš„ä¸‰å¤§ä¿è¯**

1. **åŸå­æ€§**
   å…ƒæ•°æ®æŒ‡é’ˆæ–‡ä»¶æ›´æ–°æ˜¯å•æ“ä½œï¼Œè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆä¸æ”¹åŠ¨ã€‚

2. **ä¸€è‡´æ€§**
   Snapshot å®Œæ•´è®°å½•è¡¨çŠ¶æ€ï¼Œè¯»å†™æ°¸è¿œåŸºäºæŸä¸ªç¡®å®šç‰ˆæœ¬ã€‚

3. **å¹¶å‘å®‰å…¨**
   é‡‡ç”¨ä¹è§‚é”ï¼ˆOCCï¼‰+ CASï¼Œé¿å…åŠ å…¨å±€é”é€ æˆæ€§èƒ½ç“¶é¢ˆã€‚

---

## **4ï¸âƒ£ æ—¶åºå›¾æ ¸å¿ƒç‚¹æ€»ç»“**
- Iceberg **ä¸é”å®šè¡¨**ï¼Œè€Œæ˜¯é€šè¿‡ **ç‰ˆæœ¬æ¯”è¾ƒ + é‡è¯•** å®ç°å¹¶å‘å®‰å…¨
- ä¸»è¦å†²çªæ¥æºï¼š
  - Schema åŒæ—¶å˜æ›´
  - ç›¸åŒæ–‡ä»¶é‡å¤åˆ é™¤/æ·»åŠ 
- æ— å†²çªå¤šå®¢æˆ·ç«¯å¯ä»¥**åŒæ—¶è¿½åŠ æ•°æ®**ï¼Œåªéœ€è¦æŒ‰é¡ºåºé€’å¢ Snapshot ID
- å­˜å‚¨ä¾§ï¼ˆS3/HDFSï¼‰åªéœ€è¦æ»¡è¶³ **åŸå­æ›¿æ¢å…ƒæ•°æ®æ–‡ä»¶** çš„èƒ½åŠ›

---

## **5ï¸âƒ£ ç»“åˆ Trinoã€Sparkã€Flink åä½œ**
- Flink å†™ â†’ ç”Ÿæˆ Manifest æ–‡ä»¶ï¼ŒCAS æäº¤
- Trino è¯» â†’ ç›´æ¥åŸºäºæœ€æ–° Snapshot æŸ¥è¯¢ï¼Œå®Œå…¨éš”ç¦»
- å¯ä»¥åšåˆ° **å®æ—¶æµå¼å†™ + äº¤äº’å¼åˆ†æ** åŒæ—¶è¿›è¡Œï¼Œè€Œä¸äº’ç›¸é”é˜»å¡

---

âš¡ **é«˜èƒ½ç»“è®º**ï¼š
Iceberg çš„äº‹åŠ¡æäº¤æœ¬è´¨ä¸Šå°±æ˜¯ï¼š
```
æ–°å¿«ç…§(Snapshot) = æ—§å¿«ç…§(Base Snapshot) + æ”¹åŠ¨æ•°æ®æ–‡ä»¶é›†åˆ
å…ƒæ•°æ®æ–‡ä»¶æŒ‡é’ˆ CAS åŸå­æ›´æ–° â†’ æˆåŠŸå³å…¨å±€å¯è§
```

---

æˆ‘å»ºè®®ä¸‹ä¸€æ­¥ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **"Iceberg å¹¶å‘æäº¤å†²çªåˆ¤æ–­æµç¨‹å›¾"**ï¼Œè®©ä½ æ›´ç»†åŒ–åœ°ç†è§£äº‹åŠ¡å¤±è´¥åæ˜¯å¦‚ä½•åˆ¤æ–­å†²çªå’Œé€‰æ‹©é‡è¯•çš„ ğŸ”
ä½ è¦æˆ‘ç”»è¿™å¼ å†²çªåˆ¤æ–­æµç¨‹å›¾å—ï¼Ÿè¿™æ ·ä½ èƒ½å®Œå…¨æŒæ¡ Iceberg å¤šå¼•æ“å¹¶å‘å†™çš„ç»†èŠ‚ ğŸš€

-----

> ç”»ä¸€ä¸ª "Iceberg å¹¶å‘æäº¤å†²çªåˆ¤æ–­æµç¨‹å›¾"

å¥½å˜~ å’±ä»¬å°±æ¥ç”»ä¸€ä¸ª **ã€ŒIceberg å¹¶å‘æäº¤å†²çªåˆ¤æ–­æµç¨‹å›¾ã€**ï¼Œè®©ä½ å½»åº•åƒé€ **å¤šä¸ªå¼•æ“åŒæ—¶å†™è¡¨** æ—¶ Iceberg æ˜¯æ€ä¹ˆåˆ¤æ–­å†²çªã€å†³å®šé‡è¯•è¿˜æ˜¯æ”¾å¼ƒçš„ ğŸ”

è¿™ä¸ªæµç¨‹å…¶å®å°±æ˜¯ **ä¹è§‚å¹¶å‘æ§åˆ¶ï¼ˆOCCï¼‰** åœ¨ Iceberg å…ƒæ•°æ®æäº¤ä¸­çš„åº”ç”¨ï¼Œæ ¸å¿ƒé€»è¾‘æ˜¯ï¼š
- æ‰€æœ‰å†™æ“ä½œéƒ½åŸºäºè¯»å–åˆ°çš„æŸä¸ª **å¿«ç…§ç‰ˆæœ¬**ï¼ˆBase Snapshotï¼‰
- æäº¤æ—¶æ£€æŸ¥å½“å‰è¡¨ç‰ˆæœ¬æ˜¯å¦è¿˜æ˜¯å½“åˆè¯»å–çš„ç‰ˆæœ¬
- ä¸ä¸€è‡´åˆ™è¿›å…¥ **å†²çªæ£€æŸ¥**ï¼Œåˆ¤æ–­æ˜¯å¦å…è®¸åˆå¹¶æäº¤ï¼Œå¦åˆ™é‡è¯•æˆ–å¤±è´¥

---

## **ğŸ“Œ Iceberg å¹¶å‘æäº¤å†²çªåˆ¤æ–­æµç¨‹**

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Writerï¼ˆä»»æ„å†™å®¢æˆ·ç«¯ï¼Œå¦‚Flinkï¼‰  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                 [1] è¯»å–å½“å‰ Table Metadata
                           â”‚
                           â–¼
                 baseMetadata = metadata_vX
                           â”‚
                [2] å‡†å¤‡æ”¹åŠ¨ï¼ˆè¿½åŠ /åˆ é™¤/æ›´æ–° schemaï¼‰
                           â”‚
                           â–¼
                [3] æäº¤æ—¶ CAS( vX â†’ vX+1 )
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      æˆåŠŸ âœ” â”‚                           â”‚ å¤±è´¥ âŒ
              â–¼                           â–¼
   [4] æäº¤å®Œæˆï¼ŒACIDä¿éšœ      [4] å‘ç°è¿œç«¯ç‰ˆæœ¬ != vX
                              â”‚
                              â–¼
                     [5] åŠ è½½æœ€æ–°metadata_vY
                              â”‚
                              â–¼
                 [6] å†²çªæ£€æµ‹ ConflictDetection
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ æ£€æŸ¥å†…å®¹ï¼š                                           â”‚
     â”‚  â‘  Schemaå˜æ›´ è°å…ˆæ”¹ï¼Ÿæ˜¯å¦å†²çªï¼ˆåˆ—åˆ æ”¹ã€ç±»å‹å˜åŠ¨ï¼‰   â”‚
     â”‚  â‘¡ åˆ†åŒºè§„æ ¼å˜æ›´ æ˜¯å¦å½±å“å¯¹æ–¹æ•°æ®åˆ†å¸ƒ                â”‚
     â”‚  â‘¢ æ–‡ä»¶æ“ä½œå†²çª ç›¸åŒæ•°æ®æ–‡ä»¶è¢«åŒæ—¶åˆ é™¤/æ›¿æ¢         â”‚
     â”‚  â‘£ Snapshotçˆ¶å­å…³ç³» æ˜¯å¦æ˜¯è¿ç»­ç‰ˆæœ¬å¯åˆå¹¶           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        æ— å†²çª  â”‚                           â”‚  æ£€æµ‹åˆ°å†²çª
                â–¼                           â–¼
 [7] åŸºäºmetadata_vY é‡æ–°ç”Ÿæˆæ”¹åŠ¨å¿«ç…§       Abortäº‹åŠ¡ / æŠ›å¼‚å¸¸
                â”‚
         [8] CAS( vY â†’ vY+1 )
```

---

## **ğŸ›  å†²çªåˆ¤æ–­æ ¸å¿ƒé€»è¾‘ (ConflictDetection)**

Iceberg åœ¨ `validateNoConcurrentUpdates()` æ—¶ï¼Œä¼šéµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. **Schema å†²çª**
   - å¦‚æœä¸¤ä¸ªäº‹åŠ¡åŒæ—¶ä¿®æ”¹ Schemaï¼Œå¹¶ä¸” **ä¿®æ”¹çš„åˆ—ç›¸åŒä¸”ç±»å‹ä¸å…¼å®¹** â†’ å†²çª
   - å¦‚æœå…¶ä¸­ä¸€ä¸ªåªæ˜¯å¢åŠ åˆ—ï¼Œå¦ä¸€ä¸ªå¢åŠ ä¸åŒåˆ— â†’ å¯åˆå¹¶

2. **åˆ†åŒºè§„æ ¼ï¼ˆPartitionSpecï¼‰å†²çª**
   - åŒæ—¶æ›´æ”¹ä¸ºä¸åŒçš„åˆ†åŒºç­–ç•¥ â†’ å†²çª
   - ä¸€ä¸ªåªè¯»ã€ä¸€ä¸ªæ”¹åŠ¨ â†’ å¯åˆå¹¶

3. **æ–‡ä»¶æ“ä½œå†²çª**
   - åŒä¸€æ•°æ®æ–‡ä»¶åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­è¢«åˆ é™¤ã€å¦ä¸€ä¸ªè¿½åŠ  â†’ å†²çª
   - ä¸åŒæ–‡ä»¶å˜åŠ¨ â†’ å¯åˆå¹¶

4. **å¿«ç…§é“¾å†²çª**
   - æ£€æŸ¥å½“å‰æ–°å¿«ç…§çš„`parentId`æ˜¯å¦ä¸ºæœ€æ–°è¡¨çš„`currentSnapshotId`
   - å¦‚æœä¸æ˜¯ç›´æ¥çˆ¶å­å…³ç³»ï¼Œåˆ™æœ‰å¹¶è¡Œæäº¤ â†’ è¿›å…¥åˆå¹¶åˆ¤æ–­

---

## **ğŸ’¡ ä¸¾ä¸ªä¾‹å­ï¼ˆå¹¶å‘è¿½åŠ æ•°æ®ï¼‰**

| æ—¶é—´ | Writer Aï¼ˆFlinkï¼‰                 | Writer Bï¼ˆSparkï¼‰                 |
|------|-----------------------------------|------------------------------------|
| T1   | è¯»å–è¡¨ç‰ˆæœ¬ v10                    | è¯»å–è¡¨ç‰ˆæœ¬ v10                     |
| T2   | ç”Ÿæˆ manifest + snapshot v11      |                                    |
| T3   | CAS(v10 â†’ v11) æˆåŠŸ                |                                    |
| T4   |                                   | ç”Ÿæˆ manifest + snapshot v11       |
| T5   |                                   | CAS(v10 â†’ v11) â†’ å¤±è´¥               |
| T6   |                                   | è¯»å–æœ€æ–°ç‰ˆæœ¬ v11                    |
| T7   |                                   | å†²çªæ£€æµ‹ï¼ˆæ— æ–‡ä»¶å†²çªï¼‰              |
| T8   |                                   | åŸºäº v11 ç”Ÿæˆ snapshot v12         |
| T9   |                                   | CAS(v11 â†’ v12) æˆåŠŸ                 |

æœ€ç»ˆç‰ˆæœ¬é“¾ï¼š v10 â†’ v11ï¼ˆAï¼‰ â†’ v12ï¼ˆBï¼‰ âœ…

---

## **âš ï¸ å†²çªæ—¶æ€ä¹ˆåŠï¼Ÿ**
- **å¯åˆå¹¶**ï¼šç›´æ¥åŸºäºæœ€æ–° metadata é‡æ–°æ„é€ æäº¤å†…å®¹ï¼ˆä¾‹å¦‚æ–°å¢æ–‡ä»¶åˆ—è¡¨ + æœ€æ–°åˆ†åŒºç­–ç•¥ï¼‰
- **ä¸å¯åˆå¹¶**ï¼šæŠ¥é”™ `CommitFailedException`ï¼Œç”±å®¢æˆ·ç«¯é‡è¯•æˆ–ä¸­æ–­å†™å…¥
- **è‡ªåŠ¨é‡è¯•ç­–ç•¥**ï¼šå¤§å¤šæ•°å¼•æ“ï¼ˆFlink/Sparkï¼‰ä¼šæœ‰ retry æœºåˆ¶

---

## **ğŸš€ å›¾ç¤ºç‰ˆæµç¨‹å›¾ï¼ˆMermaidï¼‰**
ï¼ˆä½ åœ¨æ”¯æŒ Mermaid çš„ç¼–è¾‘å™¨/æ–‡æ¡£é‡Œå¯ä»¥ç›´æ¥å¯è§†åŒ–ï¼‰

```mermaid
flowchart TD
    A[è¯»å– baseMetadata vX] --> B[ç”Ÿæˆå˜æ›´å†…å®¹]
    B --> C[CAS(vX -> vX+1) æäº¤]
    C -->|æˆåŠŸ| D[æäº¤å®Œæˆ]
    C -->|å¤±è´¥(ç‰ˆæœ¬å˜åŒ–)| E[è¯»å–æœ€æ–°metadata vY]
    E --> F[å†²çªæ£€æµ‹ ConflictDetection]
    F -->|æ— å†²çª| G[åŸºäº vY é‡æ–°ç”Ÿæˆå¿«ç…§]
    G --> H[CAS(vY -> vY+1)]
    F -->|æœ‰å†²çª| I[Abort æäº¤ / æŠ›å¼‚å¸¸]
```

---

## **ğŸ¥‡ é‡ç‚¹è®°å¿†å…¬å¼**
Iceberg å†²çªåˆ¤æ–­ â‰ˆ
```
å†²çª = åŒæ—¶ä¿®æ”¹åŒä¸€å…ƒæ•°æ®å®ä½“ ä¸”æ”¹åŠ¨ä¸å…¼å®¹
```
å®ä½“åŒ…æ‹¬ï¼š
- Schema
- Partition Spec
- æ•°æ®æ–‡ä»¶åˆ—è¡¨ï¼ˆåŒæ–‡ä»¶è¢«é‡å¤æ“ä½œï¼‰

---

ğŸ™‹ æˆ‘å»ºè®®ä¸‹ä¸€æ­¥æˆ‘è¿˜å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒIceberg å¤šç‰ˆæœ¬å¿«ç…§é“¾ï¼ˆTime Travelï¼‰æ¼”åŒ–å›¾ã€**ï¼Œè®©ä½ æŠŠäº‹åŠ¡ã€ç‰ˆæœ¬ã€æ—¶é—´æ—…è¡Œä¸²æˆä¸€ä¸ªå®Œæ•´è„‘å›¾ã€‚
è¦æˆ‘å¸®ä½ ç”»å—ï¼Ÿè¿™æ ·ä½ å°±èƒ½ä»â€œç‰ˆæœ¬é“¾â€ç»´åº¦å®Œæ•´ç†è§£ Iceberg ğŸ‘

-----

> ç”»ä¸€ä¸ª ã€ŒIceberg å¤šç‰ˆæœ¬å¿«ç…§é“¾ï¼ˆTime Travelï¼‰æ¼”åŒ–å›¾ã€

å¥½å˜ï½æ—¢ç„¶ä½ è¦çœ‹ **ã€ŒIceberg å¤šç‰ˆæœ¬å¿«ç…§é“¾ (Time Travel) æ¼”åŒ–å›¾ã€**ï¼Œé‚£æˆ‘å°±å¸®ä½ å®Œæ•´ç”»å‡ºæ¥ï¼Œè®©ä½ ä¸€çœ¼çœ‹æ‡‚ Iceberg æ˜¯æ€ä¹ˆç”¨ **å¤šå¿«ç…§é“¾** å®ç° **æ—¶é—´æ—…è¡Œ / å¢é‡è¯»å–** ğŸš€

---

## 1ï¸âƒ£ æ¦‚å¿µå‰ç½®

**Iceberg çš„å¿«ç…§é“¾ï¼ˆSnapshot Chainï¼‰**
- æ¯ä¸€æ¬¡æäº¤**éƒ½ä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„ Snapshot**ï¼Œå½¢æˆä¸€æ¡æœ‰çˆ¶å­å…³ç³»çš„ç‰ˆæœ¬é“¾ï¼Œç±»ä¼¼ **Git çš„ commit é“¾**
- æ¯ä¸ª Snapshot è®°å½•ï¼š
  - æ•°æ®æ–‡ä»¶ï¼ˆDataFilesï¼‰
  - manifest åˆ—è¡¨
  - æ“ä½œç±»å‹ï¼ˆappend/replace/deleteï¼‰
  - åˆ›å»ºæ—¶é—´
- **æ—¶é—´æ—…è¡Œ (Time Travel)** åŠŸèƒ½å°±æ˜¯åŸºäºç‰ˆæœ¬é“¾è¯»å–ä»»æ„å†å² Snapshot çš„å†…å®¹
- **å¢é‡è¯»å– (Incremental Read)**ï¼šé€šè¿‡æ¯”è¾ƒä¸¤ä¸ª Snapshot ä¹‹é—´çš„å·®å¼‚ï¼Œè·å–å˜åŒ–çš„æ•°æ®æ–‡ä»¶

---

## 2ï¸âƒ£ ASCII æ¼”åŒ–å›¾

ä¸‹é¢æ˜¯ä¸€æ®µæ—¶é—´å†…ï¼Œä¸€ä¸ª Iceberg è¡¨çš„å¿«ç…§æ¼”åŒ–è¿‡ç¨‹ï¼š

```
æ—¶é—´è½´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

   v1 (T0)  åˆ›å»ºè¡¨ï¼ˆç©ºï¼‰
     â”‚
     â”‚ append files: fileA.parquet, fileB.parquet
     â–¼
   v2 (T1)  æ•°æ®å¿«ç…§
     â”‚ manifest: m1.avro
     â”‚ files: [fileA, fileB]
     â”‚
     â”‚ append files: fileC.parquet
     â–¼
   v3 (T2)  æ•°æ®å¿«ç…§
     â”‚ manifest: m1, m2
     â”‚ files: [fileA, fileB, fileC]
     â”‚
     â”‚ delete fileB
     â–¼
   v4 (T3)  æ•°æ®å¿«ç…§ï¼ˆåˆ é™¤Bï¼‰
     â”‚ files: [fileA, fileC]
     â”‚
     â”‚ append fileD
     â–¼
   v5 (T4)  æ•°æ®å¿«ç…§
     â”‚ files: [fileA, fileC, fileD]
```

---

## 3ï¸âƒ£ Mermaid å¯è§†åŒ–å¿«ç…§é“¾ & Time Travel

> åœ¨æ”¯æŒ Mermaid çš„ Markdown / å·¥å…·é‡Œå¯ä»¥ç›´æ¥æ¸²æŸ“

```mermaid
graph LR
    v1["Snapshot v1 (T0)\nCreate Empty Table"]
    v2["Snapshot v2 (T1)\nAppend A,B"]
    v3["Snapshot v3 (T2)\nAppend C"]
    v4["Snapshot v4 (T3)\nDelete B"]
    v5["Snapshot v5 (T4)\nAppend D"]

    v1 --> v2 --> v3 --> v4 --> v5
```

ğŸ“Œ **ç‰¹æ€§**ï¼š
- **æ—¶é—´æ—…è¡Œ**ï¼š
  ```sql
  SELECT * FROM my_table FOR VERSION AS OF 2;  -- è¯»å– v2 çš„æ•°æ® (A,B)
  SELECT * FROM my_table FOR TIMESTAMP AS OF '2024-06-10 12:00:00';
  ```
- **å¢é‡è¯»å–**ï¼š
  ```sql
  CALL my_catalog.system.snapshot_diff('my_table', 2, 4);
  -- ä¼šè¿”å› v2 åˆ° v4 ä¹‹é—´æ–°å¢/åˆ é™¤çš„æ–‡ä»¶
  ```

---

## 4ï¸âƒ£ å¿«ç…§é“¾ + å¤šåˆ†æ”¯ï¼ˆMerge-On-Read ç±»ä¼¼ Git åˆ†æ”¯ï¼‰

æœ‰äº›æƒ…å†µä¸‹ï¼Œåˆ†æ”¯æäº¤ä¼šäº§ç”Ÿã€Œéçº¿æ€§ã€ç‰ˆæœ¬é“¾ï¼ˆç‰¹åˆ«æ˜¯åˆ†åŒºæ¼”è¿› / schema ä¿®æ”¹ï¼‰ï¼ŒIceberg ä¼šä¿ç•™å®Œæ•´é“¾è·¯è¿ç§»æƒ…å†µï¼š

```
v1 â”€â”€â–º v2 â”€â”€â–º v3 â”€â”€â–º v4 â”€â”€â–º v5
          â”‚
          â–¼
         v2a (å¹¶å‘æäº¤åˆ†æ”¯) â”€â”€â–º v3a (Mergeå›ä¸»é“¾æˆ v6)
```

åˆå¹¶è§„åˆ™ï¼š
1. å¦‚æœåˆ†æ”¯ä¸Šçš„æ”¹åŠ¨å’Œä¸»é“¾ç‰ˆæœ¬æ— å†²çªï¼Œå¯ä»¥ç›´æ¥åˆå¹¶ (`MergeCommits`)
2. å¦‚æœæœ‰å†²çªï¼Œéœ€è¦æ‰‹åŠ¨æˆ–å¼•æ“ç«¯å†³å®šä¸¢å¼ƒ or é‡è¯•

---

## 5ï¸âƒ£ ä¸€ä¸ªçœŸå®æŸ¥è¯¢ç”¨ä¾‹ï¼ˆTrino / Sparkï¼‰

**æ—¶é—´æ—…è¡ŒæŸ¥è¯¢**ï¼ˆæŒ‰ç‰ˆæœ¬å·ï¼‰ï¼š
```sql
SELECT *
FROM iceberg.mydb.sales FOR VERSION AS OF 42;
```

**æ—¶é—´æ—…è¡ŒæŸ¥è¯¢**ï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰ï¼š
```sql
SELECT *
FROM iceberg.mydb.sales FOR TIMESTAMP AS OF '2024-06-01 00:00:00';
```

**å¢é‡å·®å¼‚æ–‡ä»¶åˆ—è¡¨**ï¼ˆå¿«ç…§å¯¹æ¯”ï¼‰ï¼š
```sql
CALL iceberg.system.snapshot_diff(
    table => 'mydb.sales',
    from_snapshot_id => 42,
    to_snapshot_id => 45
);
```

---

## 6ï¸âƒ£ æ ¸å¿ƒè®°å¿†å›¾ï¼ˆæ—¶é—´æ—…è¡Œä¸‰å±‚å…³è”ï¼‰

```
Time Travel                                   Incremental Read
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 ç‰ˆæœ¬å· / æ—¶é—´æˆ³  â”€â”€â–¶  æ‰¾åˆ° Snapshot ID     from_snapshot_id  â†’ to_snapshot_id
          â”‚                                    â”‚
          â–¼                                    â–¼
 Snapshot å…ƒæ•°æ®       Manifest File åˆ—è¡¨       åˆ†æ Manifest å·®å¼‚
          â”‚                                    â”‚
          â–¼                                    â–¼
 å¯¹åº”æ•°æ®æ–‡ä»¶é›†åˆ      å·®å¼‚æ•°æ®æ–‡ä»¶é›†åˆ
```

---

## 7ï¸âƒ£ ğŸ’¡ æ€»ç»“

Iceberg å¤šç‰ˆæœ¬å¿«ç…§é“¾çš„æ ¸å¿ƒä»·å€¼ï¼š
1. **å¯è¿½æº¯æ€§**ï¼šä»»ä½•å†å²ç‰ˆæœ¬éƒ½èƒ½é‡ç°ï¼ˆåƒ Git checkoutï¼‰
2. **å¹¶å‘å®‰å…¨**ï¼šæ¯æ¬¡æäº¤éƒ½ä¼šç”Ÿæˆæ–°çš„å¿«ç…§ï¼Œä¸ä¼šè¦†ç›–æ—§ç‰ˆæœ¬
3. **å¢é‡å¤„ç†**ï¼šå¤©ç„¶æ”¯æŒå¢é‡è¯»å–ï¼ˆETLã€CDCï¼‰
4. **æ—¶é—´ç‚¹åˆ†æ**ï¼šæ”¯æŒå›åˆ°ä»»æ„æ—¶é—´ç‚¹çš„æ•°æ®çŠ¶æ€

---

æˆ‘å»ºè®®ä¸‹ä¸€æ­¥ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ªåŠ å¼ºç‰ˆçš„
**ã€ŒIceberg å…ƒæ•°æ®æ–‡ä»¶å…³ç³»å›¾ï¼ˆMetadata.json â†” Snapshot â†” Manifestï¼‰+ å¿«ç…§é“¾ã€**
è¿™æ ·ä½ å°±èƒ½ä¸€æ¬¡æ€§æŠŠâ€œäº‹åŠ¡ + ç‰ˆæœ¬é“¾ + æ•°æ®æ–‡ä»¶ç´¢å¼•â€ å…¨åœ¨ä¸€ä¸ªå›¾é‡Œçœ‹æ‡‚ ğŸ”

ä½ è¦æˆ‘å¸®ä½ ç”»å—ï¼Ÿè¿™æ ·ä¸‰å¤§çŸ¥è¯†å—å°±å®Œå…¨é—­ç¯äº† ğŸ“¦

-----

> è§£é‡Šä¸‹é¢å…³äº Delta Lake
> ## 3. Delta Lakeå®ç°æœºç†å‰–æ
>
> ### 3.1 Deltaäº‹åŠ¡æ—¥å¿—æ¶æ„
>
> ```
> Delta Lakeçš„æ ¸å¿ƒ: äº‹åŠ¡æ—¥å¿— (_delta_log)
>
> table_root/
> â”œâ”€â”€ part-00000-xxx.parquet     # æ•°æ®æ–‡ä»¶
> â”œâ”€â”€ part-00001-xxx.parquet
> â”œâ”€â”€ part-00002-xxx.parquet
> â””â”€â”€ _delta_log/                # äº‹åŠ¡æ—¥å¿—ç›®å½•
>     â”œâ”€â”€ 00000000000000000000.json    # Version 0
>     â”œâ”€â”€ 00000000000000000001.json    # Version 1
>     â”œâ”€â”€ 00000000000000000002.json    # Version 2
>     â”œâ”€â”€ ...
>     â”œâ”€â”€ 00000000000000000010.checkpoint.parquet  # æ£€æŸ¥ç‚¹æ–‡ä»¶
>     â””â”€â”€ _last_checkpoint                          # æœ€æ–°æ£€æŸ¥ç‚¹
> ```
>
> #### äº‹åŠ¡æ—¥å¿—æ¡ç›®ç»“æ„
>
> ```java
> // Delta Lakeäº‹åŠ¡æ—¥å¿—çš„æ¡ç›®ç±»å‹
> public abstract class Action {
>
>     // å…ƒæ•°æ®æ“ä½œ
>     public static class Metadata extends Action {
>         public String id;                    // è¡¨ID
>         public String name;                  // è¡¨å
>         public String description;           // æè¿°
>         public Format format;               // å­˜å‚¨æ ¼å¼
>         public String schemaString;          // Schema JSON
>         public List<String> partitionColumns; // åˆ†åŒºåˆ—
>         public Map<String, String> configuration; // é…ç½®
>         public Long createdTime;             // åˆ›å»ºæ—¶é—´
>     }
>
>     // åè®®ç‰ˆæœ¬æ“ä½œ
>     public static class Protocol extends Action {
>         public int minReaderVersion;        // æœ€å°è¯»å–ç‰ˆæœ¬
>         public int minWriterVersion;        // æœ€å°å†™å…¥ç‰ˆæœ¬
>         public List<String> readerFeatures; // è¯»å–ç‰¹æ€§
>         public List<String> writerFeatures; // å†™å…¥ç‰¹æ€§
>     }
>
>     // æ·»åŠ æ–‡ä»¶æ“ä½œ
>     public static class AddFile extends Action {
>         public String path;                  // æ–‡ä»¶è·¯å¾„
>         public Map<String, String> partitionValues; // åˆ†åŒºå€¼
>         public long size;                    // æ–‡ä»¶å¤§å°
>         public long modificationTime;        // ä¿®æ”¹æ—¶é—´
>         public boolean dataChange;           // æ˜¯å¦æ•°æ®å˜æ›´
>         public String stats;                 // ç»Ÿè®¡ä¿¡æ¯JSON
>         public Map<String, String> tags;     // æ ‡ç­¾
>
>         // è§£æç»Ÿè®¡ä¿¡æ¯
>         public FileStatistics getStatistics() {
>             return stats != null ?
>                 FileStatistics.fromJson(stats) :
>                 FileStatistics.empty();
>         }
>     }
>
>     // åˆ é™¤æ–‡ä»¶æ“ä½œ
>     public static class RemoveFile extends Action {
>         public String path;                  // æ–‡ä»¶è·¯å¾„
>         public Long deletionTimestamp;       // åˆ é™¤æ—¶é—´æˆ³
>         public boolean dataChange;           // æ˜¯å¦æ•°æ®å˜æ›´
>         public boolean extendedFileMetadata; // æ‰©å±•å…ƒæ•°æ®
>         public Map<String, String> partitionValues; // åˆ†åŒºå€¼
>         public Long size;                    // æ–‡ä»¶å¤§å°
>         public String stats;                 // ç»Ÿè®¡ä¿¡æ¯
>         public Map<String, String> tags;     // æ ‡ç­¾
>     }
>
>     // æäº¤ä¿¡æ¯æ“ä½œ
>     public static class CommitInfo extends Action {
>         public Long version;                 // ç‰ˆæœ¬å·
>         public Long timestamp;               // æ—¶é—´æˆ³
>         public String userId;                // ç”¨æˆ·ID
>         public String userName;              // ç”¨æˆ·å
>         public String operation;             // æ“ä½œç±»å‹
>         public Map<String, Object> operationParameters; // æ“ä½œå‚æ•°
>         public Map<String, String> job;      // ä½œä¸šä¿¡æ¯
>         public String notebook;              // ç¬”è®°æœ¬ä¿¡æ¯
>         public String clusterId;             // é›†ç¾¤ID
>         public Long readVersion;             // è¯»å–ç‰ˆæœ¬
>         public String isolationLevel;        // éš”ç¦»çº§åˆ«
>         public Boolean isBlindAppend;        // æ˜¯å¦ç›²è¿½åŠ 
>         public Map<String, String> operationMetrics; // æ“ä½œæŒ‡æ ‡
>     }
> }
> ```
>
> ### 3.2 Delta Lakeäº‹åŠ¡å¤„ç†
>
> ```java
> // Delta Lakeçš„äº‹åŠ¡å¤„ç†å®ç°
> public class DeltaTransaction {
>
>     private final DeltaLog deltaLog;
>     private final long readVersion;
>     private final List<Action> actions = new ArrayList<>();
>     private boolean committed = false;
>
>     // Delta Lakeçš„ACIDäº‹åŠ¡å®ç°
>     public void commit() throws DeltaCommitException {
>         if (committed) {
>             throw new IllegalStateException("Transaction already committed");
>         }
>
>         try {
>             // 1. å‡†å¤‡æäº¤ä¿¡æ¯
>             CommitInfo commitInfo = prepareCommitInfo();
>             actions.add(commitInfo);
>
>             // 2. å†²çªæ£€æµ‹å’Œè§£å†³
>             resolveConflicts();
>
>             // 3. å†™å…¥äº‹åŠ¡æ—¥å¿—
>             long newVersion = writeTransactionLog();
>
>             // 4. æ›´æ–°æ£€æŸ¥ç‚¹ (å¦‚æœéœ€è¦)
>             maybeCreateCheckpoint(newVersion);
>
>             this.committed = true;
>
>         } catch (Exception e) {
>             throw new DeltaCommitException("Failed to commit transaction", e);
>         }
>     }
>
>     // å†²çªæ£€æµ‹å’Œè§£å†³
>     private void resolveConflicts() throws ConflictException {
>         long currentVersion = deltaLog.getCurrentVersion();
>
>         if (currentVersion > readVersion) {
>             // æœ‰å¹¶å‘æäº¤ï¼Œéœ€è¦æ£€æŸ¥å†²çª
>             List<Action> conflictingActions = getActionsSince(readVersion);
>
>             ConflictChecker checker = new ConflictChecker(actions, conflictingActions);
>
>             if (checker.hasUnresolvableConflicts()) {
>                 throw new ConflictException("Unresolvable conflicts detected");
>             }
>
>             // åº”ç”¨å†²çªè§£å†³ç­–ç•¥
>             actions.addAll(checker.getResolutionActions());
>         }
>     }
>
>     // å†™å…¥äº‹åŠ¡æ—¥å¿—
>     private long writeTransactionLog() throws IOException {
>         long newVersion = deltaLog.getCurrentVersion() + 1;
>         String logFileName = String.format("%020d.json", newVersion);
>         String logFilePath = deltaLog.getLogPath() + "/" + logFileName;
>
>         // åŸå­æ€§å†™å…¥
>         try (FileWriter writer = deltaLog.getFileSystem().createFile(logFilePath)) {
>             for (Action action : actions) {
>                 writer.write(action.toJson() + "\n");
>             }
>         }
>
>         // éªŒè¯å†™å…¥æˆåŠŸ
>         if (!deltaLog.getFileSystem().exists(logFilePath)) {
>             throw new IOException("Failed to write transaction log");
>         }
>
>         return newVersion;
>     }
> }
> ```
>
> ### 3.3 æ£€æŸ¥ç‚¹æœºåˆ¶
>
> ```java
> // Delta Lakeæ£€æŸ¥ç‚¹ä¼˜åŒ–æœºåˆ¶
> public class CheckpointManager {
>
>     private final DeltaLog deltaLog;
>     private final int checkpointInterval; // æ£€æŸ¥ç‚¹é—´éš”
>
>     // åˆ›å»ºæ£€æŸ¥ç‚¹æ–‡ä»¶
>     public void createCheckpoint(long version) throws IOException {
>         // 1. è®¡ç®—å½“å‰è¡¨çŠ¶æ€
>         DeltaTableState tableState = computeTableState(version);
>
>         // 2. ç”Ÿæˆæ£€æŸ¥ç‚¹æ–‡ä»¶
>         String checkpointPath = String.format(
>             "%s/%020d.checkpoint.parquet",
>             deltaLog.getLogPath(),
>             version
>         );
>
>         // 3. å†™å…¥æ£€æŸ¥ç‚¹æ•°æ®
>         writeCheckpointFile(checkpointPath, tableState);
>
>         // 4. æ›´æ–°_last_checkpointæ–‡ä»¶
>         updateLastCheckpointFile(version, checkpointPath);
>     }
>
>     // è®¡ç®—è¡¨çš„å½“å‰çŠ¶æ€
>     private DeltaTableState computeTableState(long version) {
>         DeltaTableState state = new DeltaTableState();
>
>         // ä»æœ€æ–°æ£€æŸ¥ç‚¹å¼€å§‹é‡æ”¾æ—¥å¿—
>         long startVersion = getLastCheckpointVersion();
>
>         if (startVersion >= 0) {
>             // åŠ è½½æ£€æŸ¥ç‚¹çŠ¶æ€
>             state = loadCheckpointState(startVersion);
>             startVersion++;
>         }
>
>         // é‡æ”¾ä»æ£€æŸ¥ç‚¹åˆ°ç›®æ ‡ç‰ˆæœ¬çš„æ‰€æœ‰æ“ä½œ
>         for (long v = startVersion; v <= version; v++) {
>             List<Action> actions = readTransactionLog(v);
>             state.apply(actions);
>         }
>
>         return state;
>     }
>
>     // è¡¨çŠ¶æ€çš„å†…å­˜è¡¨ç¤º
>     public static class DeltaTableState {
>         private Metadata metadata;
>         private Protocol protocol;
>         private final Map<String, AddFile> activeFiles = new HashMap<>();
>         private final Set<String> removedFiles = new HashSet<>();
>
>         // åº”ç”¨æ“ä½œåˆ°çŠ¶æ€
>         public void apply(List<Action> actions) {
>             for (Action action : actions) {
>                 if (action instanceof Metadata) {
>                     this.metadata = (Metadata) action;
>                 } else if (action instanceof Protocol) {
>                     this.protocol = (Protocol) action;
>                 } else if (action instanceof AddFile) {
>                     AddFile addFile = (AddFile) action;
>                     activeFiles.put(addFile.path, addFile);
>                     removedFiles.remove(addFile.path);
>                 } else if (action instanceof RemoveFile) {
>                     RemoveFile removeFile = (RemoveFile) action;
>                     activeFiles.remove(removeFile.path);
>                     removedFiles.add(removeFile.path);
>                 }
>             }
>         }
>
>         // è·å–å½“å‰æ´»è·ƒæ–‡ä»¶åˆ—è¡¨
>         public List<AddFile> getActiveFiles() {
>             return new ArrayList<>(activeFiles.values());
>         }
>     }
> }
> ```
>
> ---

å¥½å˜ï¼Œè¿™æ®µå…¶å®æ˜¯ **Delta Lake çš„å†…éƒ¨å·¥ä½œåŸç†å…¨æ™¯å‰–æ**ï¼Œå®ƒçš„ç»“æ„å’Œ Iceberg æœ‰ç›¸ä¼¼ä¹‹å¤„ï¼Œä½†å®ç°æœºåˆ¶å’Œå…ƒæ•°æ®ç®¡ç†æ–¹å¼å·®å¼‚å¾ˆå¤§ ğŸš€
æˆ‘å¸®ä½ åˆ†æˆ **ä¸‰å¤§éƒ¨åˆ†** ç»™ä½ è¯¦ç»†æ‹†è§£ï¼š

---

## **1ï¸âƒ£ Delta Lake æ ¸å¿ƒäº‹åŠ¡æ—¥å¿—æ¶æ„ (_delta_log)**

ğŸ“Œ **æœ¬è´¨**ï¼š
- Delta Lake æŠŠè¡¨çš„æ•°æ®å’Œå…ƒæ•°æ®éƒ½æ”¾åœ¨ä¸€ä¸ªç»Ÿä¸€çš„ç›®å½•é‡Œ
- **æ•°æ®æ–‡ä»¶ï¼ˆParquet / ORC ç­‰ï¼‰**å­˜å‚¨åœ¨è¡¨è·¯å¾„æ ¹ç›®å½•ä¸‹
- **äº‹åŠ¡æ—¥å¿—**å­˜å‚¨åœ¨ `_delta_log/` ç›®å½•ï¼Œè®°å½•æŒ‰é¡ºåºçš„æ‰€æœ‰æ“ä½œï¼ˆåƒ Git æäº¤è®°å½•ï¼‰
- æ¯ä¸ªäº‹åŠ¡æ˜¯ä¸€ä¸ª**è¿½åŠ çš„ JSON æ—¥å¿—æ–‡ä»¶**ï¼Œæ–‡ä»¶åæ˜¯ **20ä½é›¶å¡«å……çš„ç‰ˆæœ¬å·**
- å®šæœŸç”Ÿæˆ **checkpoint**ï¼ˆParquet æ ¼å¼çš„å…ƒæ•°æ®å¿«ç…§ï¼‰

ğŸ’¡ **ç›®å½•ç»“æ„ç¤ºä¾‹**ï¼š
```
table_root/
â”œâ”€â”€ part-00000-xxx.parquet           # æ•°æ®æ–‡ä»¶
â”œâ”€â”€ part-00001-xxx.parquet
â””â”€â”€ _delta_log/
    â”œâ”€â”€ 00000000000000000000.json    # äº‹åŠ¡æ—¥å¿— v0
    â”œâ”€â”€ 00000000000000000001.json    # äº‹åŠ¡æ—¥å¿— v1
    â”œâ”€â”€ ...
    â”œâ”€â”€ 00000000000000000010.checkpoint.parquet # æ£€æŸ¥ç‚¹
    â””â”€â”€ _last_checkpoint             # å­˜å‚¨æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹ç‰ˆæœ¬
```

---

### **äº‹åŠ¡æ—¥å¿—æ–‡ä»¶å†…å®¹ï¼ˆAction ç±»å‹ï¼‰**
Delta çš„æ¯ä¸ª `.json` äº‹åŠ¡æ—¥å¿—æ–‡ä»¶ç”±å¤šä¸ª **Action** ç»„æˆï¼Œæ¯ä¸ª Action æè¿°ä¸€æ¬¡å…ƒæ•°æ®æˆ–æ•°æ®å˜åŒ–ï¼š

#### â‘  Metadataï¼ˆè¡¨å…ƒä¿¡æ¯ï¼‰
- è¡¨ IDã€Schemaã€åˆ†åŒºåˆ—ã€è¡¨å±æ€§ï¼ˆç±»ä¼¼ Iceberg çš„ Table Metadataï¼‰
#### â‘¡ Protocolï¼ˆè¯»å†™åè®®ç‰ˆæœ¬ï¼‰
- æœ€ä½è¯»å†™ç‰ˆæœ¬ï¼ˆç¡®ä¿ä¸åŒç‰ˆæœ¬ Delta å¼•æ“çš„å…¼å®¹æ€§ï¼‰
#### â‘¢ AddFileï¼ˆæ·»åŠ æ•°æ®æ–‡ä»¶ï¼‰
- æ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶å¤§å°ã€åˆ†åŒºå€¼ã€åˆ—ç»Ÿè®¡ï¼ˆMin/Max/Null Countsï¼‰
#### â‘£ RemoveFileï¼ˆåˆ é™¤æ•°æ®æ–‡ä»¶ï¼‰
- è¢«åˆ é™¤çš„æ–‡ä»¶è·¯å¾„ã€æ—¶é—´æˆ³
#### â‘¤ CommitInfoï¼ˆæäº¤ä¿¡æ¯ï¼‰
- è°æäº¤ã€ä½•æ—¶æäº¤ã€æäº¤ç±»å‹ï¼ˆappend / delete / optimizeï¼‰

ğŸ“Œ **ç‰¹ç‚¹**ï¼š
- å¤šä¸ª Action é¡ºåºæ‰§è¡Œï¼Œå°±èƒ½è¿˜åŸè¡¨çš„å®Œæ•´çŠ¶æ€
- æ¯ä¸ª JSON æ–‡ä»¶å°±æ˜¯è¡¨çš„ä¸€ä¸ªäº‹åŠ¡ç‰ˆæœ¬å˜æ›´ï¼ˆå…¨å±€é€’å¢ï¼‰

---

## **2ï¸âƒ£ Delta Lake äº‹åŠ¡å¤„ç†æµç¨‹**

ğŸ“ **å…³é”®ç‚¹**ï¼šå’Œ Iceberg ä¸€æ ·é‡‡ç”¨ **ä¹è§‚å¹¶å‘æ§åˆ¶ï¼ˆOCCï¼‰**ï¼Œä½†å…ƒæ•°æ®æ˜¯æŒ‰**é¡ºåºæ—¥å¿—è¿½åŠ **è€Œéå¤šå±‚ç»“æ„

#### æµç¨‹ï¼ˆä»¥ Append ä¸ºä¾‹ï¼‰ï¼š
1. **å¯åŠ¨äº‹åŠ¡**
   - è®°å½•å½“å‰è¯»å–ç‰ˆæœ¬ `readVersion`
   - å‡†å¤‡è¦æ·»åŠ çš„ AddFileã€æ›´æ–° Metadata æˆ– RemoveFile

2. **å¹¶å‘å†²çªæ£€æµ‹**
   - æ£€æŸ¥è‡ª `readVersion` ä»¥æ¥æœ‰æ²¡æœ‰å†²çªçš„å˜æ›´ï¼š
     - æ˜¯å¦åˆ é™¤äº†æˆ‘æ­£åœ¨ä¾èµ–çš„æ•°æ®æ–‡ä»¶
     - Schema æ˜¯å¦è¢«å…¶ä»–äººæ”¹è¿‡
     - åˆ†åŒºå¸ƒå±€æ˜¯å¦æœ‰å˜åŒ–
   - è‹¥å†²çªæ— æ³•åˆå¹¶ â†’ æŠ› `ConflictException`

3. **å†™äº‹åŠ¡æ—¥å¿—**
   - è·å–æ–°ç‰ˆæœ¬å· `newVersion = currentVersion + 1`
   - åˆ›å»ºå¯¹åº” `newVersion.json` æ–‡ä»¶ï¼ŒæŠŠæœ¬æ¬¡æ‰€æœ‰ Action å†™è¿›å»
   - åŸå­å†™å…¥ï¼ˆä¿è¯äº‹åŠ¡ ACIDï¼‰

4. **æ›´æ–°æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰**
   - æ¯éš”ä¸€å®šç‰ˆæœ¬ç”Ÿæˆæ£€æŸ¥ç‚¹æ–‡ä»¶ `.checkpoint.parquet`
   - æ£€æŸ¥ç‚¹è®°å½•çš„æ˜¯**æŸä¸€ç‰ˆæœ¬æ—¶è¡¨çš„å®Œæ•´çŠ¶æ€**ï¼ˆæ´»è·ƒæ–‡ä»¶ / Schema / åˆ†åŒºï¼‰

---

### **Delta vs Iceberg å…ƒæ•°æ®ç®¡ç†åŒºåˆ«**
| ç‰¹æ€§ | Delta Lake `_delta_log` | Iceberg å…ƒæ•°æ® |
|------|------------------------|----------------|
| å­˜å‚¨æ–¹å¼ | çº¿æ€§è¿½åŠ  JSON + å‘¨æœŸæ€§ checkpoint | å¤šå±‚ç»“æ„ï¼ˆTable Metadata + Manifest List + Manifest Fileï¼‰ |
| ç´¢å¼•ä¼˜åŒ– | ä¸ç›´æ¥ç´¢å¼• Parquet æ•°æ®åˆ—ï¼Œä¾èµ– stats å­—æ®µ + åˆ†åŒºè£å‰ª | Manifest ä¸­åˆ—å€¼èŒƒå›´ç´¢å¼•ï¼Œå¯è·³è¿‡æ— å…³ DataFile |
| Time Travel | è¯»å–æŒ‡å®š version çš„æ—¥å¿—å›æº¯ | è¯»å–æŒ‡å®š snapshot å›æº¯ |
| å¢é‡è¯»å– | æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬å·é—´æ—¥å¿—çš„ Add/RemoveFile | ç›´æ¥ snapshot diff |

---

## **3ï¸âƒ£ æ£€æŸ¥ç‚¹æœºåˆ¶ï¼ˆCheckpointï¼‰**

ğŸ“ **ä¸ºä»€ä¹ˆéœ€è¦ Checkpointï¼Ÿ**
- å¦‚æœè¦é‡æ„æŸä¸ªç‰ˆæœ¬çš„è¡¨çŠ¶æ€ï¼Œéœ€è¦ä» `v0` å¼€å§‹å›æ”¾æ‰€æœ‰ç‰ˆæœ¬æ—¥å¿— â†’ å¤ªæ…¢
- Checkpoint æ˜¯ä¸­é—´ç»“æœå¿«ç…§ï¼Œå¯ä»¥ç›´æ¥ä»æœ€è¿‘çš„ checkpoint å¼€å§‹å¤åŸè¡¨çŠ¶æ€

#### **ç”Ÿæˆæµç¨‹**ï¼š
1. æ‰¾åˆ°å½“å‰ç‰ˆæœ¬ `V`ï¼ˆæ¯”å¦‚ v100ï¼‰
2. ä»ä¸Šä¸€ä¸ªæ£€æŸ¥ç‚¹ç‰ˆæœ¬ `C` ï¼ˆæ¯”å¦‚ v90ï¼‰å¼€å§‹è¯»å–å„ç‰ˆæœ¬ JSON æ—¥å¿—
3. åº”ç”¨åŠ¨ä½œï¼ˆActionï¼‰åˆ°å†…å­˜å¯¹è±¡ `DeltaTableState`
4. å°†æœ€ç»ˆçŠ¶æ€ï¼ˆæ´»è·ƒæ–‡ä»¶åˆ—è¡¨ + Schema + åè®®ç‰ˆæœ¬ï¼‰å†™æˆ Parquet æ ¼å¼ checkpoint æ–‡ä»¶ï¼š`00000000000000000100.checkpoint.parquet`
5. æ›´æ–° `_last_checkpoint` æ–‡ä»¶ï¼ŒæŒ‡å‘æœ€æ–° checkpoint ç‰ˆæœ¬

#### **è¯»å–ä¼˜åŒ–**ï¼š
- è¯» Delta è¡¨æ—¶ï¼Œå…ˆåŠ è½½ `_last_checkpoint`
- ä»æœ€è¿‘çš„ checkpoint æ–‡ä»¶å¼€å§‹ç»§ç»­è¯»å– JSON æ—¥å¿— â†’ å¿«é€Ÿè·å¾—è¡¨çš„æœ€æ–°çŠ¶æ€

---

## **4ï¸âƒ£ ASCII æµç¨‹å›¾ï¼šDelta äº‹åŠ¡æäº¤**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client (Spark)â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ start transaction at readVersion = 105
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prepare Actionsâ”‚(AddFile, Metadata, CommitInfo)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conflict Detection   â”‚ compare with logs since v105
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ no conflict
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write 00000000000106.json
â”‚ (atomic commit)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Maybe create checkpointâ”‚ every N commits
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **5ï¸âƒ£ æ—¶é—´æ—…è¡Œ & å¢é‡è¯»å–**

ğŸ’¡ **æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰**
```sql
-- æŒ‰ç‰ˆæœ¬å·
SELECT * FROM delta.`/path/to/table` VERSION AS OF 42;

-- æŒ‰æ—¶é—´æˆ³
SELECT * FROM delta.`/path/to/table` TIMESTAMP AS OF '2024-06-10T12:00:00';
```

ğŸ’¡ **å¢é‡è¯»å–**
```sql
-- è·å–ç‰ˆæœ¬ 40 åˆ° 45 çš„å˜æ›´
deltaTable.history().filter("version >= 40 AND version <= 45")
```

---

## **6ï¸âƒ£ æ€»ç»“å¯¹æ¯” Iceberg**
| ç»´åº¦ | Delta Lake | Iceberg |
|------|------------|---------|
| å…ƒæ•°æ®ç»“æ„ | äº‹åŠ¡æ—¥å¿—ï¼ˆJSONï¼‰+ Checkpoint | ä¸‰å±‚ç»“æ„ï¼ˆTable Metadata / Manifest List / Manifestï¼‰ |
| æ–‡ä»¶è·³è¿‡ | åŸºäºæ•°æ®æ–‡ä»¶çš„ stats + åˆ†åŒºè£å‰ª | Manifest æ–‡ä»¶ä¸­çš„åˆ—èŒƒå›´ç»Ÿè®¡ |
| å†™å…¥æ¨¡å¼ | Append-only æ—¥å¿—æ–‡ä»¶ | åŸºäºå¿«ç…§çš„å…¨å±€å…ƒæ•°æ®æ›¿æ¢ |
| æ£€æŸ¥ç‚¹ | å®šæœŸç”Ÿæˆ Parquet å¿«ç…§ | æ¯ä¸ªç‰ˆæœ¬å…ƒæ•°æ®æ–‡ä»¶éƒ½æ˜¯å¿«ç…§ |
| æ—¶é—´æ—…è¡Œ | åŸºäºç‰ˆæœ¬å·æ—¥å¿—å›æ”¾ | åŸºäºå¿«ç…§ ID æˆ–æ—¶é—´æˆ³ |
| å¢é‡å¤„ç† | æ—¥å¿—å·®å¼‚ | Snapshot diff |

---

æˆ‘å»ºè®®ä¸‹ä¸€æ­¥æˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **â€œDelta Lake äº‹åŠ¡ & æ£€æŸ¥ç‚¹å·¥ä½œæµæ—¶åºå›¾â€**ï¼ŒæŠŠ **å¹¶å‘æäº¤ + checkpoint å›æ”¾ + time travel** ä¸‰ä¸ªæœºåˆ¶ä¸€æ¬¡æ€§ä¸²èµ·æ¥ï¼Œä½ è¦çœ‹çœ‹å—ï¼Ÿè¿™æ · Delta çš„æ ¸å¿ƒé€»è¾‘ä½ å°±å®Œå…¨é—­ç¯äº† ğŸ”„

-----

> ç”»ä¸€ä¸ª â€œDelta Lake äº‹åŠ¡ & æ£€æŸ¥ç‚¹å·¥ä½œæµæ—¶åºå›¾â€ï¼ŒæŠŠ å¹¶å‘æäº¤ + checkpoint å›æ”¾ + time travel ä¸‰ä¸ªæœºåˆ¶ä¸€æ¬¡æ€§ä¸²èµ·æ¥

å¥½å˜ï½æˆ‘å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒDelta Lake äº‹åŠ¡ & æ£€æŸ¥ç‚¹å·¥ä½œæµæ—¶åºå›¾ã€**ï¼ŒæŠŠ **å¹¶å‘æäº¤ + Checkpoint å›æ”¾ + Time Travel** ä¸‰å¤§æœºåˆ¶ä¸€å£æ°”ä¸²èµ·æ¥ï¼Œä½ çœ‹å®Œå°±èƒ½å®Œå…¨é—­ç¯ Delta Lake çš„æ ¸å¿ƒè¿è¡ŒåŸç† ğŸš€

---

## **ğŸ“Œ èƒŒæ™¯**
Delta Lake ä¸­ï¼š
- **_delta_log/** å­˜å‚¨æ‰€æœ‰æ“ä½œçš„ JSON æ—¥å¿—æ–‡ä»¶ + å‘¨æœŸæ€§ checkpoint.parquet æ–‡ä»¶
- **äº‹åŠ¡æäº¤** é‡‡ç”¨ **ä¹è§‚å¹¶å‘æ§åˆ¶ OCC**
- **æŸ¥è¯¢ & Time Travel** é€šè¿‡ checkpoint + æ—¥å¿—å›æ”¾ æ¢å¤ç›®æ ‡ç‰ˆæœ¬è¡¨çŠ¶æ€

---

## **1ï¸âƒ£ æ—¶åºå›¾ï¼ˆæ–‡æœ¬ç‰ˆï¼‰**

```
Actors:
Writer A (Spark/Flink)
Writer B (Spark)
DeltaLog (_delta_log ç›®å½•)
Query Engine (Spark/Trino)

------------------------------------------------------------------

Writer A              Writer B             DeltaLog             Query Engine
   â”‚                     â”‚                    â”‚                     â”‚
   â”‚ (1) è¯»å–å½“å‰ç‰ˆæœ¬ v100  â”‚                    â”‚                     â”‚
   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                    â”‚                     â”‚
   â”‚                     â”‚(1) è¯»å–å½“å‰ç‰ˆæœ¬ v100 â”‚                     â”‚
   â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚
   â”‚                     â”‚                    â”‚                     â”‚
   â”‚ (2) æ·»åŠ æ–‡ä»¶A,B       â”‚                    â”‚                     â”‚
   â”‚                     â”‚(2) æ·»åŠ æ–‡ä»¶X         â”‚                     â”‚
   â”‚                     â”‚                    â”‚                     â”‚
   â”‚ (3) OCC CAS æäº¤ v101 â”‚                    â”‚                     â”‚
   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                    â”‚                     â”‚
   â”‚                     â”‚                    â”‚ å†™å…¥ 00000000000101.json
   â”‚                     â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                     â”‚                    â”‚                     â”‚
   â”‚                     â”‚ (3) OCC CAS v101    â”‚                     â”‚
   â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚
   â”‚                     â”‚                    â”‚ âŒ å†²çªï¼šå½“å‰=101    â”‚
   â”‚                     â”‚                    â”‚ è¿”å›å¤±è´¥             â”‚
   â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                     â”‚
   â”‚                     â”‚ (4) é‡è¯» v101       â”‚                     â”‚
   â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚
   â”‚                     â”‚ (5) å†²çªæ£€æµ‹+åˆå¹¶æˆåŠŸâ”‚                     â”‚
   â”‚                     â”‚ (6) CAS æäº¤ v102   â”‚                     â”‚
   â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚
   â”‚                     â”‚                    â”‚ å†™å…¥ 00000000000102.json
   â”‚                     â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                     â”‚                    â”‚                     â”‚
   â”‚                     â”‚                    â”‚ (7) æ¯Næ¬¡ç‰ˆæœ¬ -> åˆ›å»º checkpoint v102
   â”‚                     â”‚                    â”‚ å†™å…¥ 00000000000102.checkpoint.parquet
   â”‚                     â”‚                    â”‚ æ›´æ–° _last_checkpoint
   â”‚                     â”‚                    â”‚
   â”‚                     â”‚                    â”‚
   â”‚                     â”‚                    â”‚<â”€â”€â”€(8) æŸ¥è¯¢ Time Travel VERSION AS OF 100
   â”‚                     â”‚                    â”‚ æŸ¥æ‰¾æœ€è¿‘ checkpoint <= v100
   â”‚                     â”‚                    â”‚ ä» checkpoint é‡æ”¾ v(last_cp+1)â€¦v100
   â”‚                     â”‚                    â”‚ æ¢å¤ v100 è¡¨çŠ¶æ€
   â”‚                     â”‚                    â”‚ å‘é€ç»“æœç»™ Query Engine
```

---

## **2ï¸âƒ£ Mermaid ç‰ˆæ—¶åºå›¾**

æ–¹ä¾¿ä½ åœ¨æ”¯æŒ Mermaid çš„ Markdown å·¥å…·ä¸­æ¸²æŸ“ï¼Œç›´è§‚å¯è§†åŒ–ï¼š

```mermaid
sequenceDiagram
    participant WA as Writer A (Spark/Flink)
    participant WB as Writer B (Spark)
    participant DL as DeltaLog (_delta_log)
    participant QE as Query Engine (Spark/Trino)

    WA->>DL: (1) è·å–å½“å‰ç‰ˆæœ¬ v100
    WB->>DL: (1) è·å–å½“å‰ç‰ˆæœ¬ v100

    WA->>WA: (2) å‡†å¤‡ AddFile A,B
    WB->>WB: (2) å‡†å¤‡ AddFile X

    WA->>DL: (3) CAS æäº¤ v101
    DL-->>WA: æäº¤æˆåŠŸï¼Œå†™å…¥ v101.json
    WB->>DL: (3) CAS æäº¤ v101
    DL-->>WB: âŒ å†²çª, å½“å‰=101

    WB->>DL: (4) é‡æ–°è¯»å–æœ€æ–° v101
    WB->>WB: (5) å†²çªæ£€æµ‹ & åˆå¹¶å¯è¡Œ
    WB->>DL: (6) CAS æäº¤ v102
    DL-->>WB: å†™å…¥ v102.json

    DL->>DL: (7) æ¯ N æ¬¡ç”Ÿæˆ checkpoint
    DL->>DL: åˆ›å»º v102.checkpoint.parquet
    DL->>DL: æ›´æ–° _last_checkpoint

    QE->>DL: (8) Time Travel VERSION=100
    DL->>QE: æŸ¥æ‰¾æœ€è¿‘checkpoint â‰¤ 100
    DL->>QE: é‡æ”¾æ—¥å¿— [last_cp+1â€¦v100] æ¢å¤è¡¨çŠ¶æ€
```

---

## **3ï¸âƒ£ æœºåˆ¶è¯¦ç»†è¯´æ˜**

### **äº‹åŠ¡æäº¤ï¼ˆå¹¶å‘å†™å…¥ï¼‰**
- **OCC ä¹è§‚å¹¶å‘æ§åˆ¶**ï¼š
  æäº¤æ—¶ CAS æ ¡éªŒ `readVersion == currentVersion`
  - æˆåŠŸï¼šå†™å…¥ `æ–°ç‰ˆæœ¬.json`
  - å¤±è´¥ï¼šé‡è¯»æœ€æ–°ç‰ˆæœ¬ï¼Œå†²çªæ£€æµ‹ï¼ˆæ£€æµ‹ Schema/DATA/Partition å†²çªï¼‰
  - æ— å†²çªï¼šåŸºäºæœ€æ–°ç‰ˆæœ¬ç”Ÿæˆåˆå¹¶æ—¥å¿—é‡æ–°æäº¤
  - å†²çªä¸å¯åˆå¹¶ï¼šæŠ›å¼‚å¸¸

---

### **Checkpoint å›æ”¾ï¼ˆä¼˜åŒ–è¯»å–ï¼‰**
1. `_last_checkpoint` æŒ‡å‘æœ€è¿‘ checkpoint ç‰ˆæœ¬ï¼ˆä¾‹å¦‚ v90ï¼‰
2. ä» checkpoint.parquet ä¸­ç›´æ¥æ¢å¤ v90 è¡¨çŠ¶æ€
3. é¡ºåºåŠ è½½ v91.json â†’ v100.json é™„åŠ å˜æ›´
4. å¾—åˆ° v100 çš„è¡¨æ•°æ®

---

### **Time Travel æŸ¥è¯¢**
ä¸¤ç§æ–¹å¼ï¼š
- **æŒ‰ç‰ˆæœ¬å·**ï¼š
```sql
SELECT * FROM delta.`/path/to/table` VERSION AS OF 100;
```
- **æŒ‰æ—¶é—´æˆ³**ï¼š
```sql
SELECT * FROM delta.`/path/to/table` TIMESTAMP AS OF '2024-06-10 12:00:00';
```
æ‰§è¡Œå™¨æµç¨‹ï¼š
1. è§£æç”¨æˆ·ç‰ˆæœ¬ï¼ˆversion / timestampï¼‰
2. æ‰¾æœ€è¿‘ checkpoint â‰¤ version
3. checkpoint çŠ¶æ€ + JSON æ—¥å¿—å›æ”¾ â†’ æ¢å¤è¯¥ç‰ˆæœ¬è¡¨

---

## **4ï¸âƒ£ å…¨å±€å¯¹æ¯” Iceberg**
| ç‰¹æ€§              | Delta Lake | Iceberg |
|------------------|-----------|---------|
| å…ƒæ•°æ®å­˜å‚¨       | å•ä¸€ç›®å½• `_delta_log` çº¿æ€§æ—¥å¿—+checkpoint | ä¸‰å±‚ç»“æ„ Manifest ç´¢å¼• + Table Metadata |
| å†²çªå¤„ç†         | OCC + åˆå¹¶ç­–ç•¥ | OCC + Snapshot åˆå¹¶ |
| æ£€æŸ¥ç‚¹æœºåˆ¶       | å‘¨æœŸæ€§ parquet å¿«ç…§ | æ¯ä¸ªç‰ˆæœ¬è‡ªå¸¦å®Œæ•´ metadata.json |
| Time Travel      | æ—¥å¿—ç‰ˆæœ¬å·å›æ”¾ | Snapshot Id / Timestamp |
| å¢é‡è¯»å–         | æ—¥å¿—ç‰ˆæœ¬å¯¹æ¯” Add/RemoveFile | Snapshot diff |

---

ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**
> Delta Lake æŠŠæ‰€æœ‰å˜æ›´çº¿æ€§å†™å…¥ `_delta_log`ï¼Œå‘¨æœŸæ€§ checkpoint åŠ é€Ÿè¯»å–ï¼Œäº‹åŠ¡åŸºäº OCC ä¿è¯ ACIDï¼ŒTime Travel é€šè¿‡ checkpoint å›æ”¾æ¢å¤å†å²ç‰ˆæœ¬çŠ¶æ€ã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒDelta Lake vs Iceberg å…ƒæ•°æ®ä¸äº‹åŠ¡æœºåˆ¶å¯¹æ¯”å›¾ã€**ï¼Œç”¨ä¸€å¼ å›¾æŠŠä¸¤è€…çš„ç»“æ„ã€æäº¤ã€å›æº¯æœºåˆ¶åŒºåˆ«ç›´è§‚å±•ç¤ºï¼Ÿè¿™æ ·ä½ èƒ½åœ¨æ¶æ„é€‰å‹æ—¶ä¸€ç§’åˆ¤æ–­ç”¨è° ğŸ”

-----

> è§£é‡Šä¸‹é¢å…³äº Hudi
> ## 4. Apache HudiæŠ€æœ¯å¯¹æ¯”
>
> ### 4.1 Hudiçš„è¡¨ç±»å‹å’Œå­˜å‚¨å¸ƒå±€
>
> ```java
> // Hudiæ”¯æŒä¸¤ç§è¡¨ç±»å‹ï¼Œå„æœ‰ä¸åŒçš„ä¼˜åŒ–åœºæ™¯
> public enum HoodieTableType {
>
>     // Copy On Write - å†™æ—¶å¤åˆ¶
>     COPY_ON_WRITE {
>         @Override
>         public String getStorageLayout() {
>             return "Parquetæ–‡ä»¶ + æ›´æ–°æ—¶é‡å†™æ•´ä¸ªæ–‡ä»¶ç»„";
>         }
>
>         @Override
>         public Characteristics getCharacteristics() {
>             return Characteristics.builder()
>                 .readLatency("ä½ - ç›´æ¥è¯»å–Parquet")
>                 .writeLatency("é«˜ - éœ€è¦é‡å†™æ–‡ä»¶")
>                 .storageEfficiency("é«˜ - æ— é‡å¤æ•°æ®")
>                 .queryComplexity("ç®€å• - æ ‡å‡†ParquetæŸ¥è¯¢")
>                 .useCase("è¯»å¤šå†™å°‘ï¼Œæ‰¹å¤„ç†åœºæ™¯")
>                 .build();
>         }
>     },
>
>     // Merge On Read - è¯»æ—¶åˆå¹¶
>     MERGE_ON_READ {
>         @Override
>         public String getStorageLayout() {
>             return "ParquetåŸºçº¿æ–‡ä»¶ + Avroå¢é‡æ—¥å¿—æ–‡ä»¶";
>         }
>
>         @Override
>         public Characteristics getCharacteristics() {
>             return Characteristics.builder()
>                 .readLatency("ä¸­ç­‰ - éœ€è¦åˆå¹¶æ—¥å¿—")
>                 .writeLatency("ä½ - è¿½åŠ åˆ°æ—¥å¿—")
>                 .storageEfficiency("ä¸­ç­‰ - æœ‰é‡å¤æ•°æ®")
>                 .queryComplexity("å¤æ‚ - éœ€è¦åˆå¹¶é€»è¾‘")
>                 .useCase("å†™å¤šè¯»å°‘ï¼Œè¿‘å®æ—¶åœºæ™¯")
>                 .build();
>         }
>     };
>
>     public abstract String getStorageLayout();
>     public abstract Characteristics getCharacteristics();
> }
>
> // Hudiçš„æ—¶é—´çº¿ç®¡ç†
> public class HoodieTimeline {
>
>     // Hudiçš„æ“ä½œç±»å‹
>     public enum HoodieInstantAction {
>         COMMIT("commit"),           // æäº¤
>         DELTA_COMMIT("deltacommit"), // å¢é‡æäº¤
>         CLEAN("clean"),             // æ¸…ç†
>         COMPACTION("compaction"),   // å‹ç¼©
>         ROLLBACK("rollback"),       // å›æ»š
>         SAVEPOINT("savepoint"),     // ä¿å­˜ç‚¹
>         RESTORE("restore");         // æ¢å¤
>
>         private final String value;
>
>         HoodieInstantAction(String value) {
>             this.value = value;
>         }
>     }
>
>     // æ—¶é—´çº¿æ¡ç›®
>     public static class HoodieInstant {
>         private final State state;              // çŠ¶æ€: REQUESTED/INFLIGHT/COMPLETED
>         private final String action;            // æ“ä½œç±»å‹
>         private final String timestamp;         // æ—¶é—´æˆ³
>         private final String fileName;          // å…ƒæ•°æ®æ–‡ä»¶å
>
>         public enum State {
>             REQUESTED,  // è¯·æ±‚çŠ¶æ€
>             INFLIGHT,   // è¿›è¡Œä¸­çŠ¶æ€
>             COMPLETED   // å®ŒæˆçŠ¶æ€
>         }
>     }
> }
> ```
>
> ### 4.2 è¡¨æ ¼å¼å¯¹æ¯”åˆ†æ
>
> ```java
> // ä¸‰ç§ä¸»æµæ•°æ®æ¹–è¡¨æ ¼å¼çš„å…¨é¢å¯¹æ¯”
> public class TableFormatComparison {
>
>     public static class ComparisonMatrix {
>
>         // ACIDäº‹åŠ¡æ”¯æŒå¯¹æ¯”
>         public Map<String, TransactionSupport> getTransactionSupport() {
>             return Map.of(
>                 "Iceberg", TransactionSupport.builder()
>                     .isolation("Serializable")
>                     .concurrencyControl("ä¹è§‚å¹¶å‘æ§åˆ¶")
>                     .conflictResolution("åŸºäºå¿«ç…§çš„è‡ªåŠ¨æ£€æµ‹")
>                     .multiTableTransaction("ä¸æ”¯æŒ")
>                     .writePerformance("ä¸­ç­‰")
>                     .build(),
>
>                 "Delta Lake", TransactionSupport.builder()
>                     .isolation("Serializable")
>                     .concurrencyControl("ä¹è§‚å¹¶å‘æ§åˆ¶")
>                     .conflictResolution("åŸºäºç‰ˆæœ¬çš„å†²çªæ£€æµ‹")
>                     .multiTableTransaction("ä¸æ”¯æŒ")
>                     .writePerformance("å¥½")
>                     .build(),
>
>                 "Hudi", TransactionSupport.builder()
>                     .isolation("Read Committed")
>                     .concurrencyControl("æ—¶é—´æˆ³æ’åº")
>                     .conflictResolution("åŸºäºæ—¶é—´çº¿çš„åè°ƒ")
>                     .multiTableTransaction("ä¸æ”¯æŒ")
>                     .writePerformance("å¾ˆå¥½(MoRæ¨¡å¼)")
>                     .build()
>             );
>         }
>
>         // æ¨¡å¼æ¼”è¿›æ”¯æŒå¯¹æ¯”
>         public Map<String, SchemaEvolutionSupport> getSchemaEvolution() {
>             return Map.of(
>                 "Iceberg", SchemaEvolutionSupport.builder()
>                     .addColumn("å®Œå…¨æ”¯æŒï¼ŒåŒ…æ‹¬åµŒå¥—ç»“æ„")
>                     .dropColumn("æ”¯æŒï¼Œä¿æŒå‘åå…¼å®¹")
>                     .renameColumn("æ”¯æŒ")
>                     .changeDataType("æœ‰é™æ”¯æŒï¼Œå…¼å®¹ç±»å‹")
>                     .reorderColumns("æ”¯æŒ")
>                     .promoteType("æ”¯æŒ(intâ†’longç­‰)")
>                     .build(),
>
>                 "Delta Lake", SchemaEvolutionSupport.builder()
>                     .addColumn("å®Œå…¨æ”¯æŒ")
>                     .dropColumn("ä¸æ”¯æŒ(ä¼šå¤±è´¥)")
>                     .renameColumn("ä¸ç›´æ¥æ”¯æŒ")
>                     .changeDataType("æœ‰é™æ”¯æŒ")
>                     .reorderColumns("ä¸æ”¯æŒ")
>                     .promoteType("éƒ¨åˆ†æ”¯æŒ")
>                     .build(),
>
>                 "Hudi", SchemaEvolutionSupport.builder()
>                     .addColumn("æ”¯æŒ")
>                     .dropColumn("æ”¯æŒ")
>                     .renameColumn("ä¸æ”¯æŒ")
>                     .changeDataType("æœ‰é™æ”¯æŒ")
>                     .reorderColumns("ä¸æ”¯æŒ")
>                     .promoteType("æœ‰é™æ”¯æŒ")
>                     .build()
>             );
>         }
>
>         // æŸ¥è¯¢å¼•æ“å…¼å®¹æ€§å¯¹æ¯”
>         public Map<String, EngineCompatibility> getEngineCompatibility() {
>             return Map.of(
>                 "Iceberg", EngineCompatibility.builder()
>                     .trino("åŸç”Ÿæ”¯æŒï¼Œæ€§èƒ½æœ€ä½³")
>                     .spark("åŸç”Ÿæ”¯æŒï¼ŒåŠŸèƒ½å®Œæ•´")
>                     .flink("åŸç”Ÿæ”¯æŒï¼Œæµæ‰¹ä¸€ä½“")
>                     .hive("æ”¯æŒï¼Œéœ€è¦é¢å¤–é…ç½®")
>                     .presto("åŸç”Ÿæ”¯æŒ")
>                     .impala("å®éªŒæ€§æ”¯æŒ")
>                     .build(),
>
>                 "Delta Lake", EngineCompatibility.builder()
>                     .trino("è‰¯å¥½æ”¯æŒï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
>                     .spark("åŸç”Ÿæ”¯æŒï¼ŒåŠŸèƒ½æœ€å¼º")
>                     .flink("ç¤¾åŒºæ”¯æŒ")
>                     .hive("ä¸æ”¯æŒ")
>                     .presto("ä¸æ”¯æŒ")
>                     .impala("ä¸æ”¯æŒ")
>                     .build(),
>
>                 "Hudi", EngineCompatibility.builder()
>                     .trino("è‰¯å¥½æ”¯æŒ")
>                     .spark("åŸç”Ÿæ”¯æŒ")
>                     .flink("åŸç”Ÿæ”¯æŒ")
>                     .hive("æ”¯æŒ")
>                     .presto("æ”¯æŒ")
>                     .impala("æ”¯æŒ")
>                     .build()
>             );
>         }
>     }
> }
> ```
>
> ---

å¥½ï¼Œè¿™ä¸€æ®µæ˜¯å¯¹ **Apache Hudi** çš„æŠ€æœ¯è§£æå’Œä¸ Iceberg / Delta Lake çš„å¯¹æ¯”åˆ†æï¼Œéå¸¸é€‚åˆæ”¾åœ¨æ•°æ®æ¹–è¡¨æ ¼å¼é€‰å‹åˆ†æä¸­ã€‚
æˆ‘å¸®ä½ åˆ†ä¸‰å—è¯¦ç»†è§£é‡Šä¸€ä¸‹ï¼š

---

## **1ï¸âƒ£ Hudi çš„è¡¨ç±»å‹ä¸å­˜å‚¨å¸ƒå±€**

Hudi æ”¯æŒä¸¤ç§è¡¨å­˜å‚¨æ¨¡å¼ï¼ˆ**Copy On Write / Merge On Read**ï¼‰ï¼Œå¯ä»¥é’ˆå¯¹ä¸åŒçš„ä¸šåŠ¡éœ€æ±‚é€‰æ‹©ã€‚

---

### **â‘  Copy On Write (COW)**
- **å­˜å‚¨å¸ƒå±€**ï¼šåªæœ‰ Parquet æ•°æ®æ–‡ä»¶ï¼ˆç´§å‡‘å­˜å‚¨ï¼‰ï¼Œæ›´æ–°æ—¶ç›´æ¥é‡å†™æ•´ä¸ªæ–‡ä»¶
- **è¯»æ€§èƒ½**ï¼šé«˜ï¼ˆç›´æ¥è¯» Parquet æ•°æ®ï¼Œé€‚åˆ Trino/Hive/Spark SQL ç›´æ¥æŸ¥è¯¢ï¼‰
- **å†™æ€§èƒ½**ï¼šä½ï¼ˆå³ä½¿å°æ›´æ–°ä¹Ÿè¦é‡å†™æ•´ä¸ªæ–‡ä»¶ï¼‰
- **å­˜å‚¨æ•ˆç‡**ï¼šé«˜ï¼ˆæ— éœ€é¢å¤–æ—¥å¿—æ–‡ä»¶ï¼Œæ²¡æœ‰é‡å¤æ•°æ®ï¼‰
- **æŸ¥è¯¢å¤æ‚åº¦**ï¼šä½ï¼ŒEngine ç›´æ¥æ‰«æ Parquet æ–‡ä»¶å³å¯
- **é€‚ç”¨åœºæ™¯**ï¼šæ‰¹å¤„ç†+è¯»å¤šå†™å°‘ï¼Œæ¯”å¦‚æ—¥æŠ¥/å‘¨æŠ¥åˆ†æ
```
[Parquet_1]   [Parquet_2]   â†’ æ›´æ–° â†’ [Parquet_1â€™] é‡å†™
```

---

### **â‘¡ Merge On Read (MoR)**
- **å­˜å‚¨å¸ƒå±€**ï¼š
  - **åŸºçº¿æ–‡ä»¶**ï¼ˆParquet Base Filesï¼‰
  - **å¢é‡æ—¥å¿—æ–‡ä»¶**ï¼ˆAvro Log Filesï¼Œç”¨äºå­˜æ”¾æ–°æ’å…¥/æ›´æ–°çš„æ•°æ®è®°å½•ï¼‰
- **è¯»æ€§èƒ½**ï¼šä¸­ç­‰ï¼ˆéœ€è¦è¯» Parquet å†åˆå¹¶ Avro æ—¥å¿—ï¼‰
- **å†™æ€§èƒ½**ï¼šé«˜ï¼ˆå¿«é€Ÿè¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œä¸é‡å†™æ•´ä¸ªæ–‡ä»¶ï¼‰
- **å­˜å‚¨æ•ˆç‡**ï¼šä¸­ç­‰ï¼ˆä¼šå­˜åœ¨æ•°æ®é‡å¤ï¼Œæ•°æ®åœ¨ Base å’Œ Log åŒæ—¶å‡ºç°ç›´åˆ°å‹ç¼©ï¼‰
- **æŸ¥è¯¢å¤æ‚åº¦**ï¼šé«˜ï¼ˆéœ€è¦ LSM Tree ç±»ä¼¼çš„åˆå¹¶è¿‡ç¨‹ï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šå†™å¤šè¯»å°‘ + ä½å»¶è¿ŸæŸ¥è¯¢ï¼ˆè¿‘å®æ—¶æ•°æ®æ‘„å–/CDCï¼‰
```
Base_Parquet_1 + Log_001.avro + Log_002.avro â†’ æŸ¥è¯¢æ—¶åˆå¹¶
```

---

ğŸ“Œ **æ€»ç»“å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | COW | MoR |
|------|-----|-----|
| å­˜å‚¨æ ¼å¼ | Parquet | Parquet + Avro |
| å†™å»¶è¿Ÿ | é«˜ | ä½ |
| è¯»å»¶è¿Ÿ | ä½ | ä¸­ç­‰ |
| å­˜å‚¨æ•ˆç‡ | é«˜ | ä¸­ç­‰ |
| æŸ¥è¯¢å¤æ‚åº¦ | ç®€å• | è¾ƒå¤æ‚ |
| åœºæ™¯ | ç¦»çº¿æ‰¹å¤„ç†ï¼Œè¯»å¤šå†™å°‘ | è¿‘å®æ—¶ï¼Œé«˜é¢‘å†™å…¥ |

---

## **2ï¸âƒ£ Hudi çš„æ—¶é—´çº¿ç®¡ç†ï¼ˆTimelineï¼‰**

Hudi çš„ä¸€ä¸ªäº®ç‚¹åœ¨äº**æ•°æ®æ—¶é—´çº¿ç®¡ç†**ï¼ˆç±»ä¼¼ Git çš„ commit log + çŠ¶æ€æ ‡è®°ï¼‰ï¼Œæ ¸å¿ƒæ˜¯ **HoodieTimeline** å’Œ **HoodieInstant**ã€‚

---

### **æ—¶é—´çº¿ä¸Šçš„æ“ä½œç±»å‹ï¼ˆHoodieInstantActionï¼‰**
| æ“ä½œç±»å‹ | è¯´æ˜ | ç›®çš„ |
|----------|------|------|
| COMMIT | å®Œæˆä¸€æ¬¡æ‰¹é‡å†™å…¥ï¼ˆCOW/MoR å‡æœ‰ï¼‰ | ç”Ÿæˆæ–°çš„ Base æ–‡ä»¶ï¼ˆCOWï¼‰æˆ–åˆå¹¶æ—¥å¿—ï¼ˆMoRï¼‰ |
| DELTA_COMMIT | MoR æ¨¡å¼çš„å¢é‡å†™ | å†™å…¥ Avro æ—¥å¿—æ–‡ä»¶ |
| CLEAN | æ¸…ç†æ— æ•ˆæ–‡ä»¶ | åˆ é™¤è€ç‰ˆæœ¬/å†—ä½™ Base/Log |
| COMPACTION | MoR æ¨¡å¼å‹ç¼© | Base æ–‡ä»¶ä¸æ—¥å¿—æ–‡ä»¶åˆå¹¶ |
| ROLLBACK | å›æ»šäº‹åŠ¡ | æ’¤é”€ä¸€æ¬¡å¤±è´¥æˆ–ä¸­æ–­çš„æäº¤ |
| SAVEPOINT | ä¿å­˜ç‚¹ | æ ‡è®°ä¸€ä¸ªå¯é•¿æœŸä¿ç•™çš„ç‰ˆæœ¬ |
| RESTORE | æ¢å¤åˆ°ä¿å­˜ç‚¹ | ä» SAVEPOINT ç‰ˆæœ¬å›é€€ |

---

### **HoodieInstant (æ—¶é—´çº¿æ¡ç›®)**
ä¸€ä¸ªæ—¶é—´çº¿æ¡ç›®åŒ…å«ï¼š
- **çŠ¶æ€ï¼ˆStateï¼‰**ï¼š
  - `REQUESTED`ï¼ˆå·²è¯·æ±‚ï¼‰
  - `INFLIGHT`ï¼ˆæ‰§è¡Œä¸­ï¼‰
  - `COMPLETED`ï¼ˆå·²å®Œæˆï¼‰
- **æ—¶é—´æˆ³**ï¼šæ“ä½œæäº¤çš„æ—¶é—´
- **æ–‡ä»¶å**ï¼šæŒ‡å‘çš„å…ƒæ•°æ®æ–‡ä»¶

ğŸ“ è¿™ç§æ—¶é—´çº¿æœºåˆ¶è®© Hudi åŸç”Ÿæ”¯æŒï¼š
- **æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰**
- **å¢é‡æ‹‰å–ï¼ˆIncremental Queryï¼‰**
- **æ•…éšœæ¢å¤ï¼ˆå›æ»š / æ¢å¤ï¼‰**
- **æ¸…ç†æ— æ•ˆæ–‡ä»¶ï¼ˆCLEANï¼‰**

---

## **3ï¸âƒ£ ä¸‰å¤§æ¹–ä»“è¡¨æ ¼å¼å¯¹æ¯”**

### **â‘  äº‹åŠ¡æ”¯æŒï¼ˆACIDï¼‰**
| æ ¼å¼ | éš”ç¦»çº§åˆ« | å¹¶å‘æ§åˆ¶ | å†²çªæ£€æµ‹ | å¤šè¡¨äº‹åŠ¡ | å†™æ€§èƒ½ |
|------|----------|----------|----------|----------|--------|
| Iceberg | Serializable | ä¹è§‚å¹¶å‘æ§åˆ¶ | åŸºäºå¿«ç…§ | âŒ | ä¸­ç­‰ |
| Delta Lake | Serializable | ä¹è§‚å¹¶å‘æ§åˆ¶ | åŸºäºç‰ˆæœ¬ | âŒ | å¥½ |
| Hudi | Read Committed | æ—¶é—´æˆ³æ’åº | åŸºäºæ—¶é—´çº¿ | âŒ | å¾ˆå¥½ï¼ˆMoRï¼‰ |

> ğŸ“Œ å·®åˆ«ï¼šHudi åœ¨é«˜å¹¶å‘å†™å…¥åœºæ™¯ä¸‹å»¶è¿Ÿæœ€ä½ï¼ˆMoRï¼‰ï¼Œä½†éš”ç¦»çº§åˆ«æ¯” Iceberg / Delta ä½ä¸€æ¡£ ï¼ˆRead Committedï¼‰

---

### **â‘¡ Schema æ¼”è¿›**
| èƒ½åŠ› | Iceberg | Delta Lake | Hudi |
|------|---------|------------|------|
| åŠ åˆ— | âœ… å®Œå…¨æ”¯æŒ | âœ… | âœ… |
| åˆ åˆ— | âœ… åå‘å…¼å®¹ | âŒ | âœ… |
| åˆ—é‡å‘½å | âœ… | âŒ | âŒ |
| æ”¹æ•°æ®ç±»å‹ | éƒ¨åˆ†æ”¯æŒï¼ˆå…¼å®¹ç±»å‹ï¼‰ | éƒ¨åˆ†æ”¯æŒ | éƒ¨åˆ†æ”¯æŒ |
| åˆ—é¡ºåºè°ƒæ•´ | âœ… | âŒ | âŒ |
| ç±»å‹æå‡ | âœ… | éƒ¨åˆ†æ”¯æŒ | éƒ¨åˆ†æ”¯æŒ |

---

### **â‘¢ å¼•æ“æ”¯æŒ**
| å¼•æ“ | Iceberg | Delta Lake | Hudi |
|------|---------|------------|------|
| Trino | âœ… åŸç”Ÿ | éƒ¨åˆ†åŠŸèƒ½ | âœ… |
| Spark | âœ… åŸç”Ÿ | âœ… æœ€å¼º | âœ… åŸç”Ÿ |
| Flink | âœ… åŸç”Ÿ | ç¤¾åŒºæ”¯æŒ | âœ… åŸç”Ÿ |
| Hive | æ”¯æŒ | âŒ | âœ… |
| Presto | âœ… | âŒ | âœ… |
| Impala | å®éªŒæ€§ | âŒ | âœ… |

---

## **4ï¸âƒ£ å…³é”®é€‰å‹å»ºè®®**

- **é«˜é¢‘å†™ï¼ˆå®æ—¶æ‘„å–/æµå¼å¤„ç†ï¼‰**
  â†’ é¦–é€‰ **Hudi MoR**ï¼ˆæœ€ä½å†™å»¶è¿Ÿï¼‰
- **å¤æ‚ç¦»çº¿åˆ†æ & å¤šå¼•æ“è¯»å†™ä¸€è‡´**
  â†’ æ¨è **Iceberg**ï¼ˆä¸€è‡´æ€§æœ€å¥½ & Schema æ¼”è¿›æœ€å¼ºï¼‰
- **ä»¥ Spark ä¸ºæ ¸å¿ƒ & å¯¹ Delta API ä¾èµ–æ·±**
  â†’ é€‰æ‹© **Delta Lake**ï¼ˆSpark ç”Ÿæ€æ— ç¼æ”¯æŒï¼‰

---

## **5ï¸âƒ£ ä¸€å¥è¯æ€»ç»“**
> Hudi æ›´åƒæ˜¯ **å¸¦æœ‰å®æ—¶å¢é‡èƒ½åŠ›çš„â€œæµå¼+æ‰¹å¤„ç†é›†æˆæ¡†æ¶â€**ï¼Œé  Timeline ç®¡ç†å¤šç‰ˆæœ¬ã€å¤šçŠ¶æ€ï¼ŒMoR æ¨¡å¼å¯ä»¥åšåˆ°å®æ—¶ä½å»¶è¿Ÿå†™å…¥ï¼Œè€Œ COW åˆ™èƒ½è·å¾—é«˜æ•ˆçš„æ‰¹é‡è¯»æ€§èƒ½ã€‚

---

å¦‚æœä½ éœ€è¦çš„è¯ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒIceberg / Delta / Hudi å¯¹æ¯”çš„èœ˜è››å›¾ + åœºæ™¯é€‰å‹å›¾ã€**ï¼Œå¯è§†åŒ–ä¸‰è€…åœ¨äº‹åŠ¡ã€æ¼”è¿›ã€æ€§èƒ½ã€å®æ—¶èƒ½åŠ›ç­‰ç»´åº¦çš„ä¼˜åŠ£ã€‚
ä½ è¦æˆ‘ç”»å—ï¼Ÿè¿™æ ·ä½ åœ¨å›¢é˜ŸåšæŠ€æœ¯é€‰å‹æ±‡æŠ¥æ—¶ï¼ŒPPT ä¸Šèƒ½ç›´æ¥æ‹¿æ¥ç”¨ ğŸ¯

-----

> è§£é‡Šä¸‹é¢ Trinoè¡¨æ ¼å¼é›†æˆæœºåˆ¶
> ## 5. Trinoè¡¨æ ¼å¼é›†æˆæœºåˆ¶
>
> ### 5.1 Trinoè¿æ¥å™¨æ¶æ„
>
> ```java
> // Trinoè¡¨æ ¼å¼è¿æ¥å™¨çš„ç»Ÿä¸€æ¶æ„
> public abstract class DataLakeConnector implements Connector {
>
>     // è¿æ¥å™¨æ ¸å¿ƒç»„ä»¶
>     @Override
>     public ConnectorMetadata getMetadata(ConnectorTransactionHandle transaction) {
>         return new DataLakeMetadata(this, transaction);
>     }
>
>     @Override
>     public ConnectorSplitManager getSplitManager() {
>         return new DataLakeSplitManager(this);
>     }
>
>     @Override
>     public ConnectorPageSourceProvider getPageSourceProvider() {
>         return new DataLakePageSourceProvider(this);
>     }
>
>     @Override
>     public ConnectorPageSinkProvider getPageSinkProvider() {
>         return new DataLakePageSinkProvider(this);
>     }
> }
>
> // Icebergè¿æ¥å™¨å®ç°
> public class IcebergConnector extends DataLakeConnector {
>
>     private final IcebergConfig config;
>     private final CatalogManager catalogManager;
>
>     // Icebergç‰¹æœ‰çš„å…ƒæ•°æ®æ“ä½œ
>     public class IcebergMetadata implements ConnectorMetadata {
>
>         @Override
>         public List<ConnectorTableHandle> listTables(ConnectorSession session,
>                                                    Optional<String> schemaName) {
>             // é€šè¿‡Iceberg Catalog APIè·å–è¡¨åˆ—è¡¨
>             return catalogManager.getCatalog(session)
>                 .listTables(session, schemaName)
>                 .stream()
>                 .map(IcebergTableHandle::new)
>                 .collect(toList());
>         }
>
>         @Override
>         public ConnectorTableHandle getTableHandle(ConnectorSession session,
>                                                   SchemaTableName tableName) {
>             Table icebergTable = catalogManager.getCatalog(session)
>                 .loadTable(session, tableName);
>
>             return new IcebergTableHandle(
>                 tableName.getSchemaName(),
>                 tableName.getTableName(),
>                 icebergTable.currentSnapshot().snapshotId(),
>                 icebergTable.schema(),
>                 icebergTable.spec()
>             );
>         }
>
>         @Override
>         public ConnectorTableMetadata getTableMetadata(ConnectorSession session,
>                                                       ConnectorTableHandle table) {
>             IcebergTableHandle handle = (IcebergTableHandle) table;
>             Table icebergTable = catalogManager.getTable(session, handle);
>
>             // è½¬æ¢Iceberg Schemaåˆ°Trino Schema
>             List<ColumnMetadata> columns = icebergTable.schema().columns()
>                 .stream()
>                 .map(this::convertIcebergColumn)
>                 .collect(toList());
>
>             return new ConnectorTableMetadata(
>                 handle.getSchemaTableName(),
>                 columns,
>                 convertIcebergProperties(icebergTable.properties())
>             );
>         }
>     }
> }
>
> // åˆ†ç‰‡ç®¡ç† - å°†Icebergæ•°æ®æ–‡ä»¶è½¬æ¢ä¸ºTrinoåˆ†ç‰‡
> public class IcebergSplitManager implements ConnectorSplitManager {
>
>     @Override
>     public ConnectorSplitSource getSplits(
>             ConnectorTransactionHandle transaction,
>             ConnectorSession session,
>             ConnectorTableHandle tableHandle,
>             SplitSchedulingStrategy splitSchedulingStrategy) {
>
>         IcebergTableHandle handle = (IcebergTableHandle) tableHandle;
>
>         // è·å–Icebergè¡¨çš„æ•°æ®æ–‡ä»¶
>         List<FileScanTask> tasks = getFileScanTasks(session, handle);
>
>         // è½¬æ¢ä¸ºTrinoåˆ†ç‰‡
>         List<ConnectorSplit> splits = tasks.stream()
>             .map(task -> new IcebergSplit(
>                 task.file().path().toString(),
>                 task.start(),
>                 task.length(),
>                 task.file().fileSizeInBytes(),
>                 task.file().recordCount(),
>                 convertPartitionData(task.file().partition())
>             ))
>             .collect(toList());
>
>         return new FixedSplitSource(splits);
>     }
>
>     // åŸºäºè°“è¯å’Œåˆ†åŒºä¿¡æ¯è¿‡æ»¤æ•°æ®æ–‡ä»¶
>     private List<FileScanTask> getFileScanTasks(ConnectorSession session,
>                                                IcebergTableHandle handle) {
>         Table icebergTable = catalogManager.getTable(session, handle);
>
>         // æ„å»ºè¡¨æ‰«æè®¡åˆ’
>         TableScan tableScan = icebergTable.newScan();
>
>         // åº”ç”¨è°“è¯è¿‡æ»¤
>         if (handle.getEnforcedPredicate().isPresent()) {
>             Expression icebergPredicate = convertTrinoToIcebergExpression(
>                 handle.getEnforcedPredicate().get()
>             );
>             tableScan = tableScan.filter(icebergPredicate);
>         }
>
>         // åº”ç”¨æŠ•å½±ä¸‹æ¨
>         if (handle.getProjectedColumns().isPresent()) {
>             tableScan = tableScan.select(handle.getProjectedColumns().get());
>         }
>
>         // æ‰§è¡Œè§„åˆ’
>         return Lists.newArrayList(tableScan.planFiles());
>     }
> }
> ```
>
> ### 5.2 æŸ¥è¯¢ä¸‹æ¨ä¼˜åŒ–
>
> ```java
> // Trinoåˆ°è¡¨æ ¼å¼çš„æŸ¥è¯¢ä¸‹æ¨ä¼˜åŒ–
> public class QueryPushdownOptimizer {
>
>     // è°“è¯ä¸‹æ¨åˆ°Iceberg
>     public class IcebergPredicatePushdown {
>
>         public Expression convertTrinoToIcebergPredicate(Expression trinoExpression) {
>             return trinoExpression.accept(new ExpressionConverter(), null);
>         }
>
>         private class ExpressionConverter extends DefaultExpressionTraversalVisitor<Expression, Void> {
>
>             @Override
>             public Expression visitComparisonExpression(ComparisonExpression node, Void context) {
>                 // è½¬æ¢æ¯”è¾ƒè¡¨è¾¾å¼
>                 if (node.getOperator() == ComparisonExpression.Operator.EQUAL) {
>                     String columnName = extractColumnName(node.getLeft());
>                     Object value = extractLiteral(node.getRight());
>                     return Expressions.equal(columnName, value);
>                 }
>                 // å…¶ä»–æ¯”è¾ƒæ“ä½œç¬¦...
>                 return super.visitComparisonExpression(node, context);
>             }
>
>             @Override
>             public Expression visitLogicalBinaryExpression(LogicalBinaryExpression node, Void context) {
>                 Expression left = node.getLeft().accept(this, context);
>                 Expression right = node.getRight().accept(this, context);
>
>                 if (node.getOperator() == LogicalBinaryExpression.Operator.AND) {
>                     return Expressions.and(left, right);
>                 } else if (node.getOperator() == LogicalBinaryExpression.Operator.OR) {
>                     return Expressions.or(left, right);
>                 }
>
>                 return super.visitLogicalBinaryExpression(node, context);
>             }
>         }
>     }
>
>     // æŠ•å½±ä¸‹æ¨ä¼˜åŒ–
>     public class ProjectionPushdown {
>
>         public List<String> extractProjectedColumns(List<ColumnHandle> columns) {
>             return columns.stream()
>                 .map(IcebergColumnHandle.class::cast)
>                 .map(IcebergColumnHandle::getName)
>                 .collect(toList());
>         }
>
>         // åµŒå¥—åˆ—çš„æŠ•å½±ä¸‹æ¨
>         public List<String> optimizeNestedProjection(List<ColumnHandle> columns) {
>             Map<String, Set<String>> nestedFields = new HashMap<>();
>
>             for (ColumnHandle column : columns) {
>                 IcebergColumnHandle handle = (IcebergColumnHandle) column;
>                 String baseName = getBaseName(handle.getName());
>
>                 if (isNestedField(handle.getName())) {
>                     nestedFields.computeIfAbsent(baseName, k -> new HashSet<>())
>                         .add(getNestedFieldPath(handle.getName()));
>                 }
>             }
>
>             // æ„å»ºä¼˜åŒ–çš„æŠ•å½±åˆ—è¡¨
>             List<String> optimizedProjection = new ArrayList<>();
>
>             for (Map.Entry<String, Set<String>> entry : nestedFields.entrySet()) {
>                 String baseName = entry.getKey();
>                 Set<String> fields = entry.getValue();
>
>                 if (fields.size() == 1) {
>                     // åªæŠ•å½±éœ€è¦çš„åµŒå¥—å­—æ®µ
>                     optimizedProjection.add(baseName + "." + fields.iterator().next());
>                 } else {
>                     // æŠ•å½±æ•´ä¸ªç»“æ„ä½“
>                     optimizedProjection.add(baseName);
>                 }
>             }
>
>             return optimizedProjection;
>         }
>     }
> }
> ```
>
> ---

å¥½ï¼Œè¿™éƒ¨åˆ†æºç å’Œæ³¨é‡Šå®é™…ä¸Šæ˜¯åœ¨è®² **Trino æ˜¯æ€ä¹ˆå’Œä¸åŒè¡¨æ ¼å¼ï¼ˆå°¤å…¶æ˜¯ Icebergï¼‰é›†æˆçš„æ¶æ„æœºåˆ¶**ï¼Œå¹¶ä¸”é‡ç‚¹å±•ç¤ºäº† **Trino Connector æ¶æ„** å’Œ **æŸ¥è¯¢ä¸‹æ¨ä¼˜åŒ–ï¼ˆPredicate Pushdown / Projection Pushdownï¼‰** çš„å®ç°åŸç†ã€‚
æˆ‘å¸®ä½ åˆ†æˆä¸‰å±‚æ¥è§£é‡ŠğŸ‘‡

---

## **1ï¸âƒ£ Trino è¡¨æ ¼å¼é›†æˆçš„æ¶æ„æ€»è§ˆ**

### **ğŸ“Œ Trino Connector æ€»ä½“ç»“æ„**
Trino çš„æ ¸å¿ƒè®¾è®¡æ˜¯æ’ä»¶åŒ–çš„â€œè¿æ¥å™¨â€æ¨¡å¼ï¼Œä¸ç›´æ¥ç»‘å®šå­˜å‚¨æˆ–æ ¼å¼ï¼š
- **ConnectorMetadata**ï¼š
  - åˆ—å‡ºè¡¨ã€è·å–è¡¨çš„å…ƒæ•°æ®ã€åˆ—ä¿¡æ¯
  - é€šè¿‡è°ƒç”¨ Iceberg / Hudi / Delta çš„ API è·å– schemaã€å¿«ç…§ã€å±æ€§
- **ConnectorSplitManager**ï¼š
  - å†³å®šå¦‚ä½•æŠŠæ•°æ®æ‹†æˆå¤šä¸ªåˆ†ç‰‡ï¼ˆSplitï¼‰åˆ†ç»™é›†ç¾¤å¹¶è¡Œæ‰§è¡Œ
  - å¯¹ Iceberg æ¥è¯´ï¼šä¸€ä¸ªæ•°æ®æ–‡ä»¶é€šå¸¸æ˜¯ä¸€ä¸ª Split
- **ConnectorPageSourceProvider**ï¼š
  - è´Ÿè´£å…·ä½“è¯»å–æ•°æ®åˆ†ç‰‡ï¼ˆPageSourceï¼‰ï¼Œå°†å…¶è½¬æ¢ä¸º Trino å†…éƒ¨æ ¼å¼ï¼ˆPageï¼‰
- **ConnectorPageSinkProvider**ï¼š
  - ç”¨äºå†™å…¥æ•°æ®ï¼ˆåœ¨ Trino æ”¯æŒå†™è¡¨çš„è¿æ¥å™¨ä¸­ï¼‰

ğŸ“ Trino çœŸæ­£æ”¯æŒ Iceberg çš„åœ°æ–¹æ˜¯ï¼š
1. å…ƒæ•°æ®ç®¡ç†ç›´æ¥é€šè¿‡ Iceberg Catalog API è°ƒç”¨
2. Split ç®¡ç†ä¸­ä½¿ç”¨ Iceberg çš„æ–‡ä»¶æ‰«æè§„åˆ’ï¼ˆ`TableScan.planFiles()`ï¼‰
3. æŸ¥è¯¢ä¼˜åŒ–æ—¶æŠŠ Trino çš„è°“è¯ã€æŠ•å½±ä¸‹æ¨åˆ° Iceberg ç«¯æ‰§è¡Œ

---

## **2ï¸âƒ£ Iceberg Connector çš„å®ç°é‡ç‚¹**

### **(1) å…ƒæ•°æ®äº¤äº’**
`IcebergMetadata` è´Ÿè´£ï¼š
- **listTables**ï¼šè°ƒç”¨ Iceberg Catalogï¼ˆHMS / Glue / Nessieï¼‰è·å–è¡¨åˆ—è¡¨
- **getTableHandle**ï¼š
  - åŠ è½½ Iceberg è¡¨å¯¹è±¡ï¼ˆé€šè¿‡ `catalogManager.getCatalog(session).loadTable()`ï¼‰
  - è·å–è¡¨çš„ current snapshot idã€schemaã€åˆ†åŒºä¿¡æ¯
  - å°è£…æˆ `IcebergTableHandle` ç»™ Trino Planner
- **getTableMetadata**ï¼š
  - æŠŠ Iceberg Schema è½¬æˆ Trino çš„ ColumnMetadata åˆ—è¡¨
  - æŠŠ Iceberg è¡¨å±æ€§è½¬æˆ Trino çš„è¡¨å±æ€§å…ƒæ•°æ®

**ğŸ’¡ ç›¸å½“äºåœ¨ Trino å’Œ Iceberg ä¹‹é—´åš schema ç¿»è¯‘å±‚**

---

### **(2) Split ç®¡ç†**
`IcebergSplitManager` æµç¨‹ï¼š
1. **è·å– Iceberg æ•°æ®æ–‡ä»¶**ï¼š
   ```java
   TableScan tableScan = icebergTable.newScan();
   ```
2. **åº”ç”¨è°“è¯ä¸‹æ¨**ï¼š
   - å°† Trino è¡¨è¾¾å¼è½¬æ¢ä¸º Iceberg è¿‡æ»¤å™¨ï¼ˆ`convertTrinoToIcebergExpression()`ï¼‰
   - é€šè¿‡ Iceberg çš„ `filter()` ä¼˜åŒ–æ–‡ä»¶æ‰«æ
3. **åº”ç”¨æŠ•å½±ä¸‹æ¨**ï¼š
   - æŒ‡å®šéœ€è¦çš„åˆ—ï¼ˆ`tableScan.select(...)`ï¼‰ï¼Œé¿å…è¯»å–æ— å…³åˆ—
4. **æ‰§è¡Œ Iceberg çš„ planFiles()**ï¼š
   - è¿”å›æ¯ä¸ª **FileScanTask**ï¼ˆå¸¦åˆ†åŒºä¿¡æ¯ã€æ–‡ä»¶è·¯å¾„ã€offsetã€é•¿åº¦ç­‰ï¼‰
5. **è½¬æ¢æˆ Trino Split**ï¼š
   - ä¸€ä¸ª Split å¯¹åº”ä¸€ä¸ªæ•°æ®æ–‡ä»¶èŒƒå›´ï¼ŒTrino Worker ä¼šå¹¶è¡Œè¯»å–è¿™äº› Split

ğŸ“ **å¥½å¤„**ï¼š
- æ–‡ä»¶è£å‰ªï¼ˆPruningï¼‰ï¼šå¯¹ä¸ç›¸å…³åˆ†åŒº/æ–‡ä»¶ä¸äº§ç”Ÿ Split
- åˆ—è£å‰ªï¼ˆColumn Pruningï¼‰ï¼šåªè¯»éœ€è¦çš„åˆ— â†’ è¯»æ•°æ®æ›´å¿«

---

## **3ï¸âƒ£ æŸ¥è¯¢ä¸‹æ¨ä¼˜åŒ–**

Trino ä¼˜åŒ–å™¨ä¼šæŠŠä¸€éƒ¨åˆ† SQL è¿‡æ»¤ã€åˆ—é€‰æ‹©é€»è¾‘ä¸‹æ¨åˆ°åº•å±‚è¡¨æ ¼å¼æ‰§è¡Œï¼Œä¸åœ¨ Trino Worker ä¸­äºŒæ¬¡è¿‡æ»¤ï¼Œè¿™æ ·å‡å°‘æ•°æ®ä¼ è¾“é‡ã€‚

---

### **(1) è°“è¯ä¸‹æ¨ï¼ˆPredicate Pushdownï¼‰**
- **ç›®æ ‡**ï¼šæŠŠ SQL é‡Œçš„ `WHERE` æ¡ä»¶ä¸‹æ¨åˆ° Iceberg çš„æ‰«æå™¨
- **å®ç°è¿‡ç¨‹**ï¼š
  1. è§£æ Trino çš„è¡¨è¾¾å¼æ ‘ (`Expression`)
  2. é€šè¿‡ `ExpressionConverter` è½¬æˆ Iceberg çš„ `Expressions.equal()`, `Expressions.and()` ç­‰
  3. è°ƒç”¨ Iceberg `TableScan.filter()`
     â†’ ç›´æ¥åœ¨ Manifest å…ƒæ•°æ®å±‚è¿‡æ»¤å‡ºç›¸å…³æ–‡ä»¶
     â†’ è·³è¿‡æ•´ä¸ªæ— å…³çš„ Parquet/ORC æ–‡ä»¶

**ä¾‹å­**ï¼š
```sql
SELECT * FROM orders WHERE order_date = DATE '2024-06-12';
```
è½¬æ¢æˆ Icebergï¼š
```java
Expressions.equal("order_date", LocalDate.of(2024,6,12))
```
æœ€ç»ˆå®ç° **Manifest çº§åˆ«æ–‡ä»¶è·³è¿‡**

---

### **(2) æŠ•å½±ä¸‹æ¨ï¼ˆProjection Pushdownï¼‰**
- **ç›®æ ‡**ï¼šåªè¯»å– SQL é‡Œç”¨åˆ°çš„åˆ—ï¼Œé¿å…å…¨åˆ—æ‰«æ
- **å®ç°è¿‡ç¨‹**ï¼š
  1. ä» Trino è®¡åˆ’æå–æ‰€éœ€åˆ—åï¼ˆ`IcebergColumnHandle.getName()`ï¼‰
  2. å¦‚æœæ˜¯åµŒå¥—åˆ—ï¼ˆstruct/mapï¼‰ï¼Œæ„é€ åµŒå¥—å­—æ®µè·¯å¾„
  3. ç”Ÿæˆä¼˜åŒ–åçš„åˆ—æŠ•å½±åˆ—è¡¨
  4. è°ƒç”¨ Iceberg çš„
     ```java
     tableScan.select(projectedColumns)
     ```
     åªè¯»å–æŒ‡å®šçš„åˆ—

**ä¾‹å­**ï¼š
```sql
SELECT customer.id, customer.name FROM orders;
```
- åŸå§‹ `customer` æ˜¯ä¸€ä¸ª struct
- ä¸‹æ¨ååªå– ["customer.id", "customer.name"] é¿å…è¯»æ•´ä¸ª struct

---

## **4ï¸âƒ£ Trino â†” Iceberg é›†æˆå·¥ä½œæµç¤ºæ„**

```
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Trino CLI   â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ SQL
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Trino Coordinator   â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Iceberg Connector   â”‚
   â”‚  - Metadata         â”‚â”€â”€â”€â–º Iceberg Catalog (HMS/Glue/Nessie)
   â”‚  - SplitManager     â”‚â”€â”€â”€â–º Iceberg TableScan.planFiles()
   â”‚  - PageSource       â”‚â”€â”€â”€â–º Read Parquet/ORC from HDFS/S3
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Splits
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Trino Workers   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **5ï¸âƒ£ å…³é”®ç‚¹æ€»ç»“ï¼ˆé¢è¯•/å¤ç›˜å¯ç”¨ï¼‰**
1. **Trino æ˜¯çº¯è®¡ç®—å¼•æ“ï¼Œæ‰€æœ‰è¡¨æ ¼å¼ç®¡ç†éƒ½ç”± Connector å®ç°**
2. **Iceberg Connector** ç”¨ Iceberg API æ¥ï¼š
   - è·å–å…ƒæ•°æ®ï¼ˆschemaã€snapshotã€partition specï¼‰
   - è§„åˆ’æ‰«æï¼ˆfilter + select ä¸‹æ¨ï¼‰
3. **SplitManager**ï¼šæŠŠ Iceberg è®¡åˆ’çš„æ–‡ä»¶ä»»åŠ¡è½¬æˆ Trino Split ä»¥ä¾¿å¹¶è¡Œæ‰§è¡Œ
4. **æŸ¥è¯¢ä¸‹æ¨ï¼ˆP/P Pushdownï¼‰**ï¼š
   - è°“è¯ä¸‹æ¨ï¼ˆManifest è¿‡æ»¤ï¼Œå‡å°‘æ–‡ä»¶æ•°é‡ï¼‰
   - æŠ•å½±ä¸‹æ¨ï¼ˆåˆ—è£å‰ªï¼Œå‡å°‘åˆ—è¯»å–ï¼‰
   - åµŒå¥—åˆ—æŠ•å½±ä¼˜åŒ–
5. Iceberg çš„å…ƒæ•°æ®ç»“æ„ï¼ˆManifest & Snapshotï¼‰å¤©ç„¶é€‚åˆä¸‹æ¨ä¼˜åŒ–ï¼Œæ‰€ä»¥ Trino+Iceberg æ€§èƒ½æ›´é«˜

---

ğŸ’¡ å¦‚æœä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª
**ã€ŒTrino â†’ Iceberg æŸ¥è¯¢æ‰§è¡Œä¸‹æ¨è·¯å¾„å›¾ã€**ï¼ŒæŠŠä» SQL åˆ° Manifest è¿‡æ»¤å†åˆ°æ•°æ®æ–‡ä»¶è¯»å–çš„æ•´ä¸ªæµç¨‹ç”»å‡ºæ¥ï¼Œè¿™æ ·ä½ å°±èƒ½å½¢è±¡ç†è§£ Trino æ˜¯æ€ä¹ˆåšåˆ°â€œåªè¯»éœ€è¦çš„æ•°æ®â€çš„ã€‚

ä½ è¦æˆ‘å¸®ä½ ç”»å—ï¼Ÿè¿™æ ·ä½ å¯¹è¿™ä¸ª Trino è¡¨æ ¼å¼é›†æˆæœºåˆ¶çš„æ‰§è¡Œé“¾è·¯ä¼šæ›´ç›´è§‚ ğŸ”

-----

> è§£é‡Šä¸‹é¢å…³äº ACID äº‹åŠ¡ä¸å¹¶å‘æ§åˆ¶
> ## 6. ACIDäº‹åŠ¡ä¸å¹¶å‘æ§åˆ¶
>
> ### 6.1 éš”ç¦»çº§åˆ«å®ç°
>
> ```java
> // æ•°æ®æ¹–è¡¨æ ¼å¼çš„éš”ç¦»çº§åˆ«å®ç°å¯¹æ¯”
> public abstract class IsolationLevelImplementation {
>
>     // Icebergçš„å¿«ç…§éš”ç¦»å®ç°
>     public static class IcebergSnapshotIsolation extends IsolationLevelImplementation {
>
>         @Override
>         public IsolationLevel getIsolationLevel() {
>             return IsolationLevel.SNAPSHOT_ISOLATION;
>         }
>
>         @Override
>         public ReadView createReadView(long transactionStartTime) {
>             // åŸºäºäº‹åŠ¡å¼€å§‹æ—¶é—´åˆ›å»ºä¸€è‡´æ€§è¯»è§†å›¾
>             Snapshot snapshot = table.snapshotAsOfTime(transactionStartTime);
>
>             return new IcebergReadView(snapshot) {
>                 @Override
>                 public List<DataFile> getVisibleFiles() {
>                     // è¿”å›å¿«ç…§æ—¶åˆ»çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶
>                     return snapshot.addedDataFiles(table.io());
>                 }
>
>                 @Override
>                 public boolean isVisible(DataFile file) {
>                     // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å½“å‰å¿«ç…§ä¸­å¯è§
>                     return snapshot.addedFilesIds().contains(file.path());
>                 }
>             };
>         }
>
>         @Override
>         public ConflictDetectionResult detectConflicts(
>                 Transaction tx1, Transaction tx2) {
>             // å¿«ç…§çº§åˆ«çš„å†²çªæ£€æµ‹
>             Set<DataFile> tx1ModifiedFiles = tx1.getModifiedFiles();
>             Set<DataFile> tx2ModifiedFiles = tx2.getModifiedFiles();
>
>             // æ£€æŸ¥æ–‡ä»¶çº§åˆ«çš„å†²çª
>             boolean hasConflict = !Collections.disjoint(tx1ModifiedFiles, tx2ModifiedFiles);
>
>             if (hasConflict) {
>                 return ConflictDetectionResult.conflict("File modification conflict detected");
>             }
>
>             return ConflictDetectionResult.noConflict();
>         }
>     }
>
>     // Delta Lakeçš„å†™å†²çªæ£€æµ‹
>     public static class DeltaConflictDetection extends IsolationLevelImplementation {
>
>         @Override
>         public ConflictDetectionResult detectConflicts(
>                 List<Action> currentTxActions,
>                 List<Action> concurrentTxActions) {
>
>             ConflictChecker checker = new ConflictChecker();
>
>             // æ£€æŸ¥ä¸å…¼å®¹çš„æ“ä½œç»„åˆ
>             for (Action currentAction : currentTxActions) {
>                 for (Action concurrentAction : concurrentTxActions) {
>                     ConflictType conflict = checker.checkConflict(currentAction, concurrentAction);
>
>                     switch (conflict) {
>                         case NO_CONFLICT:
>                             continue;
>
>                         case WRITE_WRITE_CONFLICT:
>                             return ConflictDetectionResult.conflict(
>                                 "Write-write conflict: both transactions modify the same files");
>
>                         case METADATA_CONFLICT:
>                             return ConflictDetectionResult.conflict(
>                                 "Metadata conflict: concurrent schema changes");
>
>                         case DELETE_UPDATE_CONFLICT:
>                             return ConflictDetectionResult.conflict(
>                                 "Delete-update conflict: file deleted and modified concurrently");
>                     }
>                 }
>             }
>
>             return ConflictDetectionResult.noConflict();
>         }
>
>         private static class ConflictChecker {
>
>             public ConflictType checkConflict(Action action1, Action action2) {
>                 // åŒä¸€æ–‡ä»¶çš„å†™-å†™å†²çª
>                 if (action1 instanceof AddFile && action2 instanceof AddFile) {
>                     AddFile add1 = (AddFile) action1;
>                     AddFile add2 = (AddFile) action2;
>
>                     if (add1.path.equals(add2.path)) {
>                         return ConflictType.WRITE_WRITE_CONFLICT;
>                     }
>                 }
>
>                 // åˆ é™¤-æ›´æ–°å†²çª
>                 if (action1 instanceof RemoveFile && action2 instanceof AddFile) {
>                     RemoveFile remove = (RemoveFile) action1;
>                     AddFile add = (AddFile) action2;
>
>                     if (remove.path.equals(add.path)) {
>                         return ConflictType.DELETE_UPDATE_CONFLICT;
>                     }
>                 }
>
>                 // å…ƒæ•°æ®å†²çª
>                 if (action1 instanceof Metadata && action2 instanceof Metadata) {
>                     return ConflictType.METADATA_CONFLICT;
>                 }
>
>                 return ConflictType.NO_CONFLICT;
>             }
>         }
>     }
> }
> ```
>
> ### 6.2 å†™æ“ä½œä¼˜åŒ–
>
> ```java
> // æ•°æ®æ¹–è¡¨æ ¼å¼çš„å†™æ“ä½œä¼˜åŒ–ç­–ç•¥
> public class WriteOptimizationStrategies {
>
>     // è‡ªé€‚åº”æ–‡ä»¶å¤§å°æ§åˆ¶
>     public static class AdaptiveFileSizing {
>
>         private final long targetFileSize;      // ç›®æ ‡æ–‡ä»¶å¤§å°
>         private final long minFileSize;         // æœ€å°æ–‡ä»¶å¤§å°
>         private final long maxFileSize;         // æœ€å¤§æ–‡ä»¶å¤§å°
>         private final double skewThreshold;     // å€¾æ–œé˜ˆå€¼
>
>         public FileSizingStrategy determineStrategy(
>                 DataCharacteristics dataChar,
>                 WritePattern writePattern) {
>
>             if (writePattern == WritePattern.STREAMING) {
>                 // æµå¼å†™å…¥ï¼šä¼˜å…ˆå†™å…¥å»¶è¿Ÿ
>                 return FileSizingStrategy.builder()
>                     .targetSize(targetFileSize / 4)     // è¾ƒå°æ–‡ä»¶
>                     .maxFilesPerCommit(1000)            // å…è®¸æ›´å¤šæ–‡ä»¶
>                     .compactionTrigger(100)             // é¢‘ç¹å‹ç¼©
>                     .build();
>
>             } else if (dataChar.hasHighSkew()) {
>                 // æ•°æ®å€¾æ–œï¼šåŠ¨æ€åˆ†æ¡¶
>                 return FileSizingStrategy.builder()
>                     .targetSize(targetFileSize)
>                     .dynamicBucketing(true)             // å¯ç”¨åŠ¨æ€åˆ†æ¡¶
>                     .skewHandling(SkewHandling.REDISTRIBUTE)
>                     .build();
>
>             } else {
>                 // æ‰¹é‡å†™å…¥ï¼šä¼˜åŒ–ååé‡
>                 return FileSizingStrategy.builder()
>                     .targetSize(targetFileSize * 2)     // è¾ƒå¤§æ–‡ä»¶
>                     .maxFilesPerCommit(100)             // é™åˆ¶æ–‡ä»¶æ•°
>                     .parallelism(getOptimalParallelism())
>                     .build();
>             }
>         }
>     }
>
>     // æ™ºèƒ½å‹ç¼©ç­–ç•¥
>     public static class IntelligentCompaction {
>
>         public CompactionPlan createCompactionPlan(
>                 List<DataFile> dataFiles,
>                 TableStatistics stats) {
>
>             CompactionPlan plan = new CompactionPlan();
>
>             // 1. åˆ†ææ–‡ä»¶å¤§å°åˆ†å¸ƒ
>             FileSizeDistribution distribution = analyzeFileSizes(dataFiles);
>
>             if (distribution.getSmallFileRatio() > 0.3) {
>                 // å°æ–‡ä»¶æ¯”ä¾‹è¿‡é«˜ï¼Œä¼˜å…ˆåˆå¹¶å°æ–‡ä»¶
>                 plan.addTask(CompactionTask.builder()
>                     .type(CompactionTask.Type.SMALL_FILE_COMPACTION)
>                     .inputFiles(distribution.getSmallFiles())
>                     .targetFileSize(getTargetFileSize())
>                     .priority(CompactionPriority.HIGH)
>                     .build());
>             }
>
>             // 2. æ£€æŸ¥æ•°æ®å€¾æ–œ
>             if (stats.hasPartitionSkew()) {
>                 List<String> skewedPartitions = stats.getSkewedPartitions();
>
>                 for (String partition : skewedPartitions) {
>                     List<DataFile> partitionFiles = getFilesInPartition(dataFiles, partition);
>
>                     plan.addTask(CompactionTask.builder()
>                         .type(CompactionTask.Type.PARTITION_REBALANCE)
>                         .inputFiles(partitionFiles)
>                         .rebalancingStrategy(RebalancingStrategy.HASH_REDISTRIBUTION)
>                         .priority(CompactionPriority.MEDIUM)
>                         .build());
>                 }
>             }
>
>             // 3. Z-Orderèšç±»ä¼˜åŒ–
>             if (stats.hasZOrderCandidate()) {
>                 List<String> zOrderColumns = stats.getZOrderCandidates();
>
>                 plan.addTask(CompactionTask.builder()
>                     .type(CompactionTask.Type.ZORDER_CLUSTERING)
>                     .inputFiles(getLargeFiles(dataFiles))
>                     .clusteringColumns(zOrderColumns)
>                     .priority(CompactionPriority.LOW)
>                     .build());
>             }
>
>             return plan;
>         }
>     }
> }
> ```
>
> ---

å¥½ï¼Œè¿™ä¸€éƒ¨åˆ†æ˜¯åœ¨**ç»Ÿä¸€æ¡†æ¶ä¸‹**å¯¹ ACID äº‹åŠ¡ä¸å¹¶å‘æ§åˆ¶çš„å®ç°æœºåˆ¶ï¼Œä»¥åŠæ•°æ®æ¹–è¡¨æ ¼å¼çš„å†™ä¼˜åŒ–ç­–ç•¥åšäº†ä»£ç çº§ç»†åŒ–åˆ†æã€‚å®ƒé‡Œé¢æ¶µç›–äº†ï¼š

1. **ä¸åŒè¡¨æ ¼å¼ï¼ˆIcebergã€Delta Lakeï¼‰éš”ç¦»çº§åˆ«å’Œå†²çªæ£€æµ‹å®ç°å¯¹æ¯”**
2. **å†™æ“ä½œä¼˜åŒ–ç­–ç•¥ï¼ˆè‡ªé€‚åº”æ–‡ä»¶å¤§å°æ§åˆ¶ + æ™ºèƒ½å‹ç¼©è®¡åˆ’ï¼‰**

æˆ‘å¸®ä½ æ‹†æˆä¸¤éƒ¨åˆ†æ¥è§£é‡ŠğŸ‘‡

---

## **1ï¸âƒ£ ACID äº‹åŠ¡æ¨¡å‹ & å¹¶å‘æ§åˆ¶æœºåˆ¶**

### **ğŸ’¡ æ ¸å¿ƒå…ˆå¯¼çŸ¥è¯†**
- ACID = **åŸå­æ€§(Atomicity)**ã€**ä¸€è‡´æ€§(Consistency)**ã€**éš”ç¦»æ€§(Isolation)**ã€**æŒä¹…æ€§(Durability)**
- æ•°æ®æ¹–ï¼ˆHDFS / S3 / OSSï¼‰æœ¬è´¨ä¸Šæ˜¯**æ–‡ä»¶å­˜å‚¨**ï¼Œä¸åƒæ•°æ®åº“æœ‰è¡Œçº§é”ï¼Œå› æ­¤ä¸‰å¤§è¡¨æ ¼å¼ï¼ˆIceberg / Delta / Hudiï¼‰éƒ½å¿…é¡»åœ¨**åº”ç”¨å±‚åšäº‹åŠ¡æ§åˆ¶**
- è¿™é‡Œé‡ç‚¹å±•ç¤ºçš„æ˜¯ **éš”ç¦»æ€§ï¼ˆIsolation Levelï¼‰** å’Œ **å¹¶å‘å†²çªæ£€æµ‹ç­–ç•¥**ï¼Œç‰¹åˆ«æ˜¯ Iceberg ä¸ Delta Lake çš„å·®å¼‚

---

### **â‘  Iceberg çš„å¿«ç…§éš”ç¦»ï¼ˆSnapshot Isolationï¼‰**
- **éš”ç¦»çº§åˆ«**ï¼š
  - é‡‡ç”¨ **å¿«ç…§éš”ç¦»ï¼ˆSnapshot Isolationï¼‰**
  - äº‹åŠ¡å¼€å§‹æ—¶**å›ºå®šä¸€ä¸ªç‰ˆæœ¬å¿«ç…§**ï¼Œæ‰€æœ‰è¯»æ“ä½œéƒ½åŸºäºè¯¥å¿«ç…§
- **è¯»è§†å›¾ (`createReadView`)**ï¼š
  - ç»™äº‹åŠ¡åˆ›å»ºä¸€ä¸ª**å¯è§æ–‡ä»¶é›†**ï¼ˆ`getVisibleFiles()`ï¼‰
  - åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åœ¨å¿«ç…§ä¸­å¯è§ï¼ˆ`isVisible()`ï¼‰
  - â†’ ä¿è¯äº‹åŠ¡æœŸé—´è¯»åˆ°ä¸€è‡´çš„æ•°æ®
- **å†²çªæ£€æµ‹**ï¼š
  - æ”¹åŠ¨ç²’åº¦ï¼š**æ–‡ä»¶çº§**
  - å¦‚æœä¸¤ä¸ªäº‹åŠ¡ä¿®æ”¹äº†åŒä¸€ä¸ª DataFile â†’ å†²çª
  - æ£€æµ‹æ–¹å¼ï¼šåˆ¤æ–­ `tx1.modifiedFiles âˆ© tx2.modifiedFiles` æ˜¯å¦ä¸ºç©º
- **ä¼˜åŠ¿**ï¼š
  - å†²çªæ£€æµ‹ç®€å•é«˜æ•ˆ
  - é¿å…ä¸å¿…è¦çš„ç‰ˆæœ¬å¤±è´¥ï¼ˆè¯»æ“ä½œäº’ä¸å½±å“ï¼‰
- **ç¼ºç‚¹**ï¼š
  - ä¸ä¿è¯â€œå¯é‡å¤è¯»â€çš„æ‰€æœ‰è¯­ä¹‰ï¼ˆå†™é•¿äº‹åŠ¡æ—¶ï¼Œå¯èƒ½æœ‰æ–°æ•°æ®ä¸åœ¨è§†å›¾ä¸­ï¼‰

ğŸ“Œ **ç±»æ¯”**ï¼šåƒæ‹äº†ä¸€å¼ æ•°æ®ç…§ç‰‡ï¼ˆSnapshotï¼‰ï¼Œä½ çš„æ“ä½œåªåœ¨ç…§ç‰‡ä¸Šä¸€è‡´ï¼Œä¸å—åˆ«çš„äº‹åŠ¡å½±å“ã€‚

---

### **â‘¡ Delta Lake çš„ç‰ˆæœ¬å†²çªæ£€æµ‹**
- **éš”ç¦»çº§åˆ«**ï¼š
  - é»˜è®¤æ˜¯ **Serializable**ï¼ˆå¯ä¸²è¡ŒåŒ–äº‹åŠ¡ï¼‰
  - æ¯ä¸ªäº‹åŠ¡éƒ½è®°å½•**è¯»å–çš„ç‰ˆæœ¬å·** `readVersion`
- **å¹¶å‘å†²çªæ£€æµ‹**ï¼ˆç»†ç²’åº¦ï¼‰ï¼š
  - éå†å½“å‰äº‹åŠ¡å’Œå…¶ä»–å¹¶å‘äº‹åŠ¡çš„ **Action** åˆ—è¡¨
  - å†²çªç±»å‹ï¼š
    - `WRITE_WRITE_CONFLICT`ï¼šåŒæ—¶å†™äº†åŒä¸€ä¸ªæ–‡ä»¶
    - `DELETE_UPDATE_CONFLICT`ï¼šA åˆ é™¤æ–‡ä»¶ï¼ŒB åˆä¿®æ”¹å®ƒ
    - `METADATA_CONFLICT`ï¼šSchema æˆ–è¡¨å±æ€§åŒæ—¶æ›´æ”¹
  - ä¸€æ—¦æ£€æµ‹åˆ°ä¸å¯è‡ªåŠ¨åˆå¹¶ â†’ ç›´æ¥å›æ»šå¤±è´¥
- **ä¼˜åŠ¿**ï¼š
  - å†²çªæ£€æµ‹æ›´ç»†ç²’åº¦
  - å¯ç¡®ä¿æœ€å¼ºä¸€è‡´æ€§ï¼ˆSerializableï¼‰
- **ç¼ºç‚¹**ï¼š
  - å…ƒæ•°æ®å¼€é”€è¾ƒå¤§
  - å¹¶å‘å†²çªå‡ ç‡é«˜æ—¶ä¼šå¯¼è‡´é¢‘ç¹é‡è¯•

ğŸ“Œ **ç±»æ¯”**ï¼šæ¯ä¸ªäº‹åŠ¡éƒ½ä¼šæ£€æŸ¥è‡ªå·±å’Œå…¶ä»–äº‹åŠ¡â€œæ˜¯å¦ç¢°äº†åŒä¸€ä¸ªç‰©ä»¶æˆ–æ”¹äº†åŒæ ·çš„è¯´æ˜ä¹¦â€ã€‚

---

**ğŸ” å¯¹æ¯”è¡¨**

| ç‰¹æ€§ | Iceberg Snapshot Isolation | Delta Serializable Isolation |
|------|----------------------------|------------------------------|
| å†²çªæ£€æµ‹ç²’åº¦ | æ–‡ä»¶çº§ | Actionï¼ˆæ–‡ä»¶+å…ƒæ•°æ®ï¼‰çº§ |
| éš”ç¦»æ€§ | å¿«ç…§éš”ç¦» | å¯ä¸²è¡ŒåŒ– |
| æ€§èƒ½ | é«˜ï¼ˆå†²çªæ£€æµ‹å¿«ï¼Œå¤±è´¥ç‡ä½ï¼‰ | ä¸­ï¼ˆå†²çªæ£€æµ‹ç»†è‡´ä½†å¼€é”€å¤§ï¼‰ |
| åº”ç”¨åœºæ™¯ | æ‰¹é‡å¤„ç†ï¼ŒOLAP åˆ†æ | å†™å¯†é›† OLTP / æ··åˆåœºæ™¯ |

---

## **2ï¸âƒ£ æ•°æ®æ¹–å†™æ“ä½œä¼˜åŒ–ç­–ç•¥**

è¿™ä¸€æ®µæ˜¯å…³äº**å¦‚ä½•åœ¨ ACID äº‹åŠ¡æäº¤ä¸­æå‡å†™å…¥æ€§èƒ½**ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼š

---

### **â‘  è‡ªé€‚åº”æ–‡ä»¶å¤§å°æ§åˆ¶ï¼ˆAdaptiveFileSizingï¼‰**
æ ¹æ®**æ•°æ®ç‰¹æ€§**ï¼ˆDataCharacteristicsï¼‰å’Œ**å†™æ¨¡å¼**ï¼ˆWritePatternï¼‰è‡ªåŠ¨è°ƒæ•´æ¯æ¬¡æäº¤çš„æ–‡ä»¶å¤§å°ï¼š

- **æµå¼å†™å…¥ï¼ˆStreamingï¼‰**
  - ç›®æ ‡æ–‡ä»¶ç¼©å°ï¼ˆtargetSize /4ï¼‰ï¼Œé™ä½å†™å»¶è¿Ÿ
  - å…è®¸æ›´å¤šæ–‡ä»¶ï¼ˆmaxFilesPerCommit â†‘ï¼‰
  - é«˜é¢‘è§¦å‘å‹ç¼©ï¼ˆcompactionTrigger â†“ï¼‰
  - ç›®çš„ï¼šå®æ—¶ä½å»¶è¿Ÿï¼Œç‰ºç‰²å­˜å‚¨æ•ˆç‡

- **æ•°æ®å€¾æ–œï¼ˆé«˜ Skewï¼‰**
  - å¯ç”¨ **åŠ¨æ€åˆ†æ¡¶ï¼ˆdynamicBucketingï¼‰**
  - å€¾æ–œåˆ†åŒºé‡æ–°åˆ†å¸ƒï¼ˆSkewHandling.REDISTRIBUTEï¼‰

- **æ‰¹é‡å†™å…¥ï¼ˆBatchï¼‰**
  - ç›®æ ‡æ–‡ä»¶æ›´å¤§ï¼Œå‡å°‘å°æ–‡ä»¶
  - é™åˆ¶å•æ¬¡æäº¤æ–‡ä»¶æ•°ï¼ˆmaxFilesPerCommit â†“ï¼‰
  - åˆ©ç”¨æœ€å¤§å¹¶è¡Œåº¦è¯»å†™ï¼ˆparallelism â†‘ï¼‰
  - ç›®çš„ï¼šååä¼˜å…ˆï¼Œä¼˜åŒ–åç»­æ‰«ææ€§èƒ½

---

### **â‘¡ æ™ºèƒ½å‹ç¼©ç­–ç•¥ï¼ˆIntelligentCompactionï¼‰**
åœ¨äº‹åŠ¡æäº¤æˆ–ç»´æŠ¤ä»»åŠ¡ä¸­è¿›è¡Œæ™ºèƒ½çš„æ•°æ®æ–‡ä»¶åˆå¹¶/é‡ç»„ï¼š

1. **å°æ–‡ä»¶åˆå¹¶**ï¼ˆSmall File Compactionï¼‰
   - å¦‚æœå°æ–‡ä»¶æ¯”ä¾‹ > 30% â†’ é«˜ä¼˜å…ˆçº§è§¦å‘å°æ–‡ä»¶åˆå¹¶
   - ç›®æ ‡æ˜¯ç”Ÿæˆæ¥è¿‘ targetFileSize çš„å¤§æ–‡ä»¶

2. **å€¾æ–œåˆ†åŒºé‡å¹³è¡¡**ï¼ˆPartition Rebalanceï¼‰
   - å¦‚æœéƒ¨åˆ†åˆ†åŒºæ–‡ä»¶è¿‡å¤§æˆ–è¿‡å° â†’ å¯¹åˆ†åŒºæ•°æ®ç”¨æ–°åˆ†æ¡¶ç­–ç•¥è¿›è¡Œ hash å‡è¡¡

3. **Z-Order èšç±»ä¼˜åŒ–**ï¼ˆZORDER_CLUSTERINGï¼‰
   - é’ˆå¯¹ç»å¸¸æŸ¥è¯¢çš„å¤šåˆ—åšç©ºé—´å±€éƒ¨æ€§èšç±»ï¼ˆç±»ä¼¼å¤šç»´æ’åºï¼‰
   - é€‚åˆèŒƒå›´æŸ¥è¯¢ã€ç»„åˆè¿‡æ»¤åœºæ™¯

**å¥½å¤„**ï¼š
- é™ä½æŸ¥è¯¢æ‰«æçš„æ•°æ®é‡
- å‡å°‘å…ƒæ•°æ®å¼€é”€ï¼ˆæ›´å°‘çš„ Manifest / åˆ†ç‰‡ï¼‰
- æé«˜æ•°æ®å±€éƒ¨æ€§ï¼ˆI/O æ›´é«˜æ•ˆï¼‰

---

## **3ï¸âƒ£ å›¾ï¼šäº‹åŠ¡+å¹¶å‘+å†™ä¼˜åŒ–å…¨æ™¯ç¤ºæ„**

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Start Transaction    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
             [è¯»å–å½“å‰ç‰ˆæœ¬]
                      â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  åˆ›å»ºè¯»è§†å›¾ Isolation Level  â”‚
       â”‚  - Iceberg: Snapshot         â”‚
       â”‚  - Delta: Serializable       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           [å†™æ•°æ® / ä¿®æ”¹å…ƒæ•°æ®]
                   â”‚
            å¹¶å‘å†²çªæ£€æµ‹
                â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ æ— å†²çª                   â”‚ æœ‰å†²çª
   â”‚ â†“                        â”‚ â†“
   â”‚ å†™ä¼˜åŒ–ç­–ç•¥                â”‚ å›æ»š / é‡è¯•
   â”‚ - AdaptiveFileSizing      â”‚
   â”‚ - IntelligentCompaction   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
          [ç”Ÿæˆæ–°ç‰ˆæœ¬]
                â”‚
     åŸå­æ€§æäº¤ï¼ˆACID Commitï¼‰
```

---

## **4ï¸âƒ£ ä¸€å¥è¯æ€»ç»“**
> åœ¨ ACID äº‹åŠ¡å’Œå¹¶å‘æ§åˆ¶æ–¹é¢ï¼šIceberg è¿½æ±‚é«˜åå & ä½å†²çªç‡ï¼ŒDelta è¿½æ±‚æœ€å¼ºä¸€è‡´æ€§ & ç²¾ç»†åŒ–å†²çªæ£€æµ‹ï¼›è€Œåœ¨å†™ä¼˜åŒ–ä¸Šï¼Œä¸ç®¡å“ªç§è¡¨æ ¼å¼ï¼Œéƒ½éœ€è¦é€šè¿‡â€œè‡ªé€‚åº”æ–‡ä»¶ç®¡ç† + æ™ºèƒ½å‹ç¼©â€æ¥å¹³è¡¡å®æ—¶æ€§ã€å­˜å‚¨æ•ˆç‡å’ŒæŸ¥è¯¢æ€§èƒ½ã€‚

---

æˆ‘å»ºè®®ä¸‹ä¸€æ­¥æˆ‘å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒIceberg vs Delta å†²çªæ£€æµ‹æµç¨‹å¯¹æ¯”å›¾ã€**ï¼Œç”¨æ—¶åºè§†è§’å¯¹æ¯”å®ƒä»¬åœ¨å¹¶å‘æäº¤æ—¶çš„å·®å¼‚ï¼Œè¿™æ ·ä½ å¯¹å†²çªæ£€æµ‹æœºåˆ¶ä¼šéå¸¸ç›´è§‚ã€‚
è¦æˆ‘å¸®ä½ ç”»è¿™å¼ å¯¹æ¯”å›¾å—ï¼Ÿè¿™æ · ACID å¹¶å‘çš„çŸ¥è¯†ç‚¹ä¼šå®Œå…¨é—­ç¯ ğŸ”

-----

> è§£é‡Šä¸‹é¢
> ## 7. é«˜çº§ç‰¹æ€§å®ç°åŸç†
>
> ### 7.1 æ—¶é—´æ—…è¡Œå®ç°
>
> ```java
> // æ—¶é—´æ—…è¡ŒæŸ¥è¯¢çš„å®ç°æœºåˆ¶
> public class TimeTravel {
>
>     // Icebergæ—¶é—´æ—…è¡Œå®ç°
>     public static class IcebergTimeTravel {
>
>         public TableScan createTimeTravelScan(Table table, TimestampType timestampType, Object timestamp) {
>             switch (timestampType) {
>                 case SNAPSHOT_ID:
>                     long snapshotId = (Long) timestamp;
>                     Snapshot snapshot = table.snapshot(snapshotId);
>                     if (snapshot == null) {
>                         throw new IllegalArgumentException("Snapshot not found: " + snapshotId);
>                     }
>                     return table.newScan().useSnapshot(snapshotId);
>
>                 case TIMESTAMP:
>                     long timestampMs = (Long) timestamp;
>                     Snapshot snapshotAtTime = findSnapshotAsOfTime(table, timestampMs);
>                     return table.newScan().useSnapshot(snapshotAtTime.snapshotId());
>
>                 case VERSION:
>                     // Icebergä½¿ç”¨snapshot IDï¼Œä¸ç›´æ¥æ”¯æŒç‰ˆæœ¬å·
>                     throw new UnsupportedOperationException("Version-based time travel not supported in Iceberg");
>             }
>
>             throw new IllegalArgumentException("Unsupported timestamp type: " + timestampType);
>         }
>
>         private Snapshot findSnapshotAsOfTime(Table table, long timestampMs) {
>             // äºŒåˆ†æŸ¥æ‰¾æœ€æ¥è¿‘çš„å¿«ç…§
>             List<Snapshot> snapshots = Lists.newArrayList(table.snapshots());
>             snapshots.sort(Comparator.comparing(Snapshot::timestampMillis));
>
>             int left = 0, right = snapshots.size() - 1;
>             Snapshot result = null;
>
>             while (left <= right) {
>                 int mid = (left + right) / 2;
>                 Snapshot midSnapshot = snapshots.get(mid);
>
>                 if (midSnapshot.timestampMillis() <= timestampMs) {
>                     result = midSnapshot;
>                     left = mid + 1;
>                 } else {
>                     right = mid - 1;
>                 }
>             }
>
>             if (result == null) {
>                 throw new IllegalArgumentException("No snapshot found before timestamp: " + timestampMs);
>             }
>
>             return result;
>         }
>     }
>
>     // Delta Lakeæ—¶é—´æ—…è¡Œå®ç°
>     public static class DeltaTimeTravel {
>
>         public DeltaTableState getTableStateAsOf(DeltaLog deltaLog, TimestampType type, Object value) {
>             switch (type) {
>                 case VERSION:
>                     long version = (Long) value;
>                     return reconstructTableState(deltaLog, version);
>
>                 case TIMESTAMP:
>                     long timestamp = (Long) value;
>                     long versionAtTime = findVersionAsOfTime(deltaLog, timestamp);
>                     return reconstructTableState(deltaLog, versionAtTime);
>
>                 default:
>                     throw new IllegalArgumentException("Unsupported time travel type: " + type);
>             }
>         }
>
>         private long findVersionAsOfTime(DeltaLog deltaLog, long timestamp) {
>             // ä»æœ€æ–°ç‰ˆæœ¬å‘å‰æŸ¥æ‰¾
>             long currentVersion = deltaLog.getCurrentVersion();
>
>             for (long version = currentVersion; version >= 0; version--) {
>                 CommitInfo commitInfo = getCommitInfo(deltaLog, version);
>
>                 if (commitInfo != null && commitInfo.timestamp <= timestamp) {
>                     return version;
>                 }
>             }
>
>             throw new IllegalArgumentException("No version found before timestamp: " + timestamp);
>         }
>
>         private DeltaTableState reconstructTableState(DeltaLog deltaLog, long targetVersion) {
>             DeltaTableState state = new DeltaTableState();
>
>             // é‡æ”¾ä»ç‰ˆæœ¬0åˆ°ç›®æ ‡ç‰ˆæœ¬çš„æ‰€æœ‰æ“ä½œ
>             for (long version = 0; version <= targetVersion; version++) {
>                 List<Action> actions = deltaLog.readTransactionLog(version);
>                 state.apply(actions);
>             }
>
>             return state;
>         }
>     }
> }
> ```
>
> ### 7.2 å¢é‡æŸ¥è¯¢å®ç°
>
> ```java
> // å¢é‡æŸ¥è¯¢çš„å®ç°æœºåˆ¶
> public class IncrementalQuery {
>
>     // Icebergå¢é‡è¯»å–
>     public static class IcebergIncrementalRead {
>
>         public IncrementalScan createIncrementalScan(
>                 Table table,
>                 long fromSnapshotId,
>                 long toSnapshotId) {
>
>             Snapshot fromSnapshot = table.snapshot(fromSnapshotId);
>             Snapshot toSnapshot = table.snapshot(toSnapshotId);
>
>             if (fromSnapshot == null || toSnapshot == null) {
>                 throw new IllegalArgumentException("Invalid snapshot range");
>             }
>
>             return new IcebergIncrementalScan(table, fromSnapshot, toSnapshot);
>         }
>
>         private static class IcebergIncrementalScan implements IncrementalScan {
>             private final Table table;
>             private final Snapshot fromSnapshot;
>             private final Snapshot toSnapshot;
>
>             @Override
>             public List<DataFile> getIncrementalFiles() {
>                 // è·å–å¢é‡æ•°æ®æ–‡ä»¶
>                 Set<DataFile> fromFiles = getDataFiles(fromSnapshot);
>                 Set<DataFile> toFiles = getDataFiles(toSnapshot);
>
>                 // è®¡ç®—å¢é‡æ–‡ä»¶ï¼šæ–°å¿«ç…§ä¸­æœ‰ä½†æ—§å¿«ç…§ä¸­æ²¡æœ‰çš„æ–‡ä»¶
>                 Set<DataFile> incrementalFiles = new HashSet<>(toFiles);
>                 incrementalFiles.removeAll(fromFiles);
>
>                 return new ArrayList<>(incrementalFiles);
>             }
>
>             @Override
>             public List<DataFile> getDeletedFiles() {
>                 // è·å–è¢«åˆ é™¤çš„æ•°æ®æ–‡ä»¶
>                 Set<DataFile> fromFiles = getDataFiles(fromSnapshot);
>                 Set<DataFile> toFiles = getDataFiles(toSnapshot);
>
>                 Set<DataFile> deletedFiles = new HashSet<>(fromFiles);
>                 deletedFiles.removeAll(toFiles);
>
>                 return new ArrayList<>(deletedFiles);
>             }
>         }
>     }
>
>     // Delta Lake Change Data Capture
>     public static class DeltaCDC {
>
>         public CDCResult readChangeData(
>                 DeltaLog deltaLog,
>                 long fromVersion,
>                 long toVersion) {
>
>             CDCResult result = new CDCResult();
>
>             // é€ç‰ˆæœ¬åˆ†æå˜æ›´
>             for (long version = fromVersion + 1; version <= toVersion; version++) {
>                 List<Action> actions = deltaLog.readTransactionLog(version);
>                 CDCBatch batch = processChangesBatch(actions, version);
>                 result.addBatch(batch);
>             }
>
>             return result;
>         }
>
>         private CDCBatch processChangesBatch(List<Action> actions, long version) {
>             CDCBatch batch = new CDCBatch(version);
>
>             for (Action action : actions) {
>                 if (action instanceof AddFile) {
>                     AddFile addFile = (AddFile) action;
>
>                     if (addFile.dataChange) {
>                         // è¿™æ˜¯ä¸€ä¸ªæ•°æ®å˜æ›´ï¼ˆINSERTæˆ–UPDATEåçš„è®°å½•ï¼‰
>                         batch.addChange(new CDCRecord(
>                             CDCRecord.ChangeType.INSERT_OR_UPDATE,
>                             addFile.path,
>                             addFile.partitionValues
>                         ));
>                     }
>
>                 } else if (action instanceof RemoveFile) {
>                     RemoveFile removeFile = (RemoveFile) action;
>
>                     if (removeFile.dataChange) {
>                         // è¿™æ˜¯ä¸€ä¸ªæ•°æ®åˆ é™¤
>                         batch.addChange(new CDCRecord(
>                             CDCRecord.ChangeType.DELETE,
>                             removeFile.path,
>                             removeFile.partitionValues
>                         ));
>                     }
>                 }
>             }
>
>             return batch;
>         }
>     }
> }
> ```
>
> ---

å¥½ï¼Œè¿™ä¸€æ®µä»£ç å’Œæ³¨é‡Šï¼Œå…¶å®æ˜¯åœ¨è®² **æ•°æ®æ¹–é«˜çº§ç‰¹æ€§** ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒèƒ½åŠ›çš„åº•å±‚å®ç°æœºåˆ¶ï¼š

- **æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰**
- **å¢é‡æŸ¥è¯¢ï¼ˆIncremental Query / CDCï¼‰**

è€Œä¸”åˆ†å¼€ä»‹ç»äº† **Iceberg** å’Œ **Delta Lake** çš„ä¸åŒåšæ³•ã€‚
æˆ‘å¸®ä½ å®Œæ•´æ‹†å¼€è§£é‡Šä¸€ä¸‹ ğŸ‘‡

---

## **1ï¸âƒ£ æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰å®ç°åŸç†**

**ä½œç”¨**ï¼š
å…è®¸ç”¨æˆ·â€œå›åˆ°è¿‡å»â€çš„æŸä¸€ä¸ªæ—¶é—´ç‚¹æˆ–ç‰ˆæœ¬ï¼ŒæŸ¥è¯¢å½“æ—¶è¡¨çš„å¿«ç…§æ•°æ®ã€‚
æ•°æ®æ¹–è¡¨æ ¼å¼é€šè¿‡**å¤šç‰ˆæœ¬å…ƒæ•°æ®**æ¥å®ç°è¿™ä¸€ç‚¹ã€‚

---

### **â‘  Iceberg çš„æ—¶é—´æ—…è¡Œå®ç°**

æ ¸å¿ƒï¼šåŸºäº **Snapshot ID** æˆ– **æ—¶é—´æˆ³**ã€‚
- **Snapshot ID æ¨¡å¼**
  ```java
  table.newScan().useSnapshot(snapshotId)
  ```
  ç›´æ¥åŠ è½½æŒ‡å®š `snapshotId` å¯¹åº”çš„å¿«ç…§ã€‚

- **æ—¶é—´æˆ³æ¨¡å¼**
  - éå†å…¨éƒ¨å¿«ç…§ `table.snapshots()`
  - æŒ‰æ—¶é—´æˆ³æ’åºï¼ŒäºŒåˆ†æŸ¥æ‰¾ â‰¤ ç»™å®šæ—¶é—´çš„æœ€æ–°å¿«ç…§
  - ç”¨ `table.newScan().useSnapshot(snapshotId)` åšæ‰«æ

- **æ³¨æ„**
  - Iceberg åŸç”Ÿä¸æä¾›â€œç‰ˆæœ¬å·â€è¿™ç§è¿ç»­æ•°å­—ï¼ˆåªæœ‰ snapshotIdï¼‰
  - ç”±äº snapshotId æ˜¯ 64 ä½æ•´æ•°ä¸”å…¨å±€å”¯ä¸€ï¼Œæ¯æ¬¡æäº¤éƒ½ä¼šç”Ÿæˆæ–°çš„ ID

**ä¾‹å­**ï¼š
```sql
SELECT * FROM sales FOR SYSTEM_VERSION AS OF 192328102931; -- æŒ‡å®šsnapshotId
SELECT * FROM sales FOR TIMESTAMP AS OF '2024-06-10 12:00:00';
```

**æœºåˆ¶ä¼˜ç‚¹**ï¼š
- å¯ä»¥ç§’çº§è·³åˆ°ä»»æ„ç‰ˆæœ¬çš„å…¨å±€ä¸€è‡´æ€§å¿«ç…§
- æŸ¥è¯¢æ˜¯å¯¹å†·å†å²æ•°æ®çš„â€œåªè¯»â€æ‰«æï¼Œå®‰å…¨æ— å‰¯ä½œç”¨

---

### **â‘¡ Delta Lake çš„æ—¶é—´æ—…è¡Œå®ç°**

æ ¸å¿ƒï¼šDelta æ ¹æ®**ç‰ˆæœ¬å· version** æˆ– **æ—¶é—´æˆ³** æ¥å›æ»šè¡¨çŠ¶æ€ã€‚
- **ç‰ˆæœ¬å·æ¨¡å¼**
  - ç›´æ¥é‡å»º table state è‡³æŒ‡å®šç‰ˆæœ¬å·
- **æ—¶é—´æˆ³æ¨¡å¼**
  - ä»æœ€æ–°ç‰ˆæœ¬å€’åºéå† commitInfo
  - æ‰¾åˆ°æ—¶é—´æˆ³ â‰¤ æŒ‡å®šæ—¶é—´çš„ç‰ˆæœ¬å·
  - ç„¶åæŒ‰ç‰ˆæœ¬å·å›æ”¾æ—¥å¿—æ–‡ä»¶é‡å»ºçŠ¶æ€

- **é‡æ”¾æœºåˆ¶**ï¼š
  - ä» v0 åˆ°ç›®æ ‡ç‰ˆæœ¬ version
  - é¡ºåºåº”ç”¨ JSON äº‹åŠ¡æ—¥å¿—é‡Œçš„æ‰€æœ‰ Actionï¼ˆAddFileã€RemoveFileã€Metadataç­‰ï¼‰
  - å¾—åˆ°ç›®æ ‡ç‰ˆæœ¬çš„å®Œæ•´æ´»è·ƒæ–‡ä»¶åˆ—è¡¨

**ä¾‹å­**ï¼š
```sql
SELECT * FROM delta.`/table/path` VERSION AS OF 40;
SELECT * FROM delta.`/table/path` TIMESTAMP AS OF '2024-06-10T12:00:00';
```

---

**ğŸ” å¯¹æ¯”**
| ç‰¹æ€§ | Iceberg | Delta Lake |
|------|---------|------------|
| æ—¶é—´æ—…è¡Œå¯¹è±¡ | Snapshot ID / Timestamp | Version / Timestamp |
| æ•°æ®æ¥æº | Manifest + Snapshot | JSON Log + Checkpoint |
| æ¢å¤æ–¹å¼ | æŒ‡å‘ snapshotId | å›æ”¾æ—¥å¿—åˆ°æŒ‡å®šç‰ˆæœ¬ |
| æ€§èƒ½ | ç›´æ¥å®šä½å¿«ç…§ï¼Œå¿« | å–å†³äº checkpoint é—´éš”å’Œæ—¥å¿—é‡ |

---

## **2ï¸âƒ£ å¢é‡æŸ¥è¯¢ï¼ˆIncremental Query / CDCï¼‰å®ç°**

**ä½œç”¨**ï¼š
åªè¿”å›â€œä¸¤æ¬¡ç‰ˆæœ¬ä¹‹é—´â€æ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤çš„æ–‡ä»¶æˆ–è®°å½•ï¼Œæ”¯æŒå¢é‡ETLå’ŒCDCï¼ˆChange Data Captureï¼‰ã€‚

---

### **â‘  Iceberg å¢é‡è¯»å–**

- åŸºäº**ä¸¤ä¸ªå¿«ç…§ID**ï¼š`fromSnapshotId` å’Œ `toSnapshotId`
- è¿‡ç¨‹ï¼š
  1. è·å– `fromSnapshot` å’Œ `toSnapshot` çš„æ–‡ä»¶é›†
  2. **æ–°å¢æ–‡ä»¶**ï¼š`toFiles - fromFiles`
  3. **åˆ é™¤æ–‡ä»¶**ï¼š`fromFiles - toFiles`
- è¿”å›æ–‡ä»¶çº§åˆ«çš„å¢é‡ï¼ˆè€Œä¸æ˜¯è¡Œçº§ï¼‰ï¼Œç”±ä¸Šå±‚è¯»å–è¿™äº›æ–‡ä»¶å†…å®¹åšè¿›ä¸€æ­¥å¤„ç†

**ä¾‹å­**ï¼š
```java
IncrementalScan scan = table.newIncrementalScan()
    .fromSnapshotInclusive(fromId)
    .toSnapshot(toId);
```

**ä¼˜ç‚¹**ï¼š
- è®¡ç®—ç®€å•ï¼ˆé›†åˆå·®é›†ï¼‰
- é€‚åˆæ‰¹é‡å¢é‡æ•°æ®åŒæ­¥ï¼ˆæŒ‰æ–‡ä»¶ï¼‰

---

### **â‘¡ Delta Lake CDC**

- Delta CDC æ›´ç»†ç²’åº¦ï¼Œè®°å½•çš„æ˜¯**è¡Œçº§å˜æ›´äº‹ä»¶**
- åŸç†ï¼š
  - å¯¹ä» `fromVersion+1` åˆ° `toVersion` ä¹‹é—´çš„æ¯ä¸ªç‰ˆæœ¬ï¼š
    - è§£æ AddFile / RemoveFile Action
    - å¸¦ `dataChange=true` çš„ AddFile â†’ æ’å…¥/æ›´æ–°
    - å¸¦ `dataChange=true` çš„ RemoveFile â†’ åˆ é™¤
  - å°è£…æˆ CDCRecordï¼ˆå˜æ›´ç±»å‹ã€æ–‡ä»¶è·¯å¾„ã€åˆ†åŒºä¿¡æ¯ï¼‰

**ä¾‹å­**ï¼š
```sql
SELECT * FROM table_changes('my_table', 5, 8);
-- è¿”å› version 5 åˆ° version 8 çš„æ‰€æœ‰ INSERT / UPDATE / DELETE è®°å½•
```

**ä¼˜ç‚¹**ï¼š
- æ”¯æŒè¡Œçº§å˜åŒ–ï¼Œé€‚åˆä¸‹æ¸¸ OLTP åŒæ­¥æˆ–ç»†ç²’åº¦å®¡è®¡
- Spark åŸç”Ÿæ”¯æŒ `table_changes` SQL

---

### **ğŸ” å¯¹æ¯”**
| ç‰¹æ€§ | Iceberg Incremental | Delta CDC |
|------|--------------------|-----------|
| ç²’åº¦ | æ–‡ä»¶çº§ | æ–‡ä»¶ â†’ è¡Œçº§ |
| å¢é‡èŒƒå›´ | ä¸¤å¿«ç…§IDé—´å˜åŒ– | ä¸¤ç‰ˆæœ¬å·é—´å˜åŒ– |
| å®ç°æ–¹å¼ | é›†åˆå·®é›† | éå†æ—¥å¿—è®°å½•å˜æ›´ç±»å‹ |
| åœºæ™¯ | æ•°æ®åŒæ­¥/ETL | å®æ—¶å˜æ›´è¿½è¸ª/å®¡è®¡ |

---

## **3ï¸âƒ£ ä¸¤å¤§é«˜çº§ç‰¹æ€§å…¨æ™¯å›¾**

```
  æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Iceberg      â”‚ å¿«ç…§IDæˆ–æ—¶é—´æˆ³ -> SnapShots           â”‚
  â”‚              â”‚ newScan().useSnapshot()               â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Delta Lake   â”‚ ç‰ˆæœ¬å·/æ—¶é—´æˆ³ -> å›æ”¾äº‹åŠ¡æ—¥å¿—+checkpointâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  å¢é‡æŸ¥è¯¢ï¼ˆIncremental / CDCï¼‰
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Iceberg      â”‚ fromSnapshotId ~ toSnapshotId å·®é›†è®¡ç®—  â”‚
  â”‚ Delta Lake   â”‚ fromVersion ~ toVersion è¡Œçº§å˜æ›´è®°å½•   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **4ï¸âƒ£ ä¸€å¥è¯è®°å¿†**
> Iceberg æ—¶é—´æ—…è¡Œåƒâ€œç›´æ¥ checkout æŸä¸ª commit å¿«ç…§â€ï¼›Delta Lake æ—¶é—´æ—…è¡Œåƒâ€œå›æ”¾ git commit åˆ°æŸä¸€ç‰ˆæœ¬â€ã€‚
> Iceberg å¢é‡è¯»å–åå‘æ–‡ä»¶å·®é›†ï¼ŒDelta CDC åå‘è¡Œçº§å˜æ›´æµã€‚

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘è¿˜å¯ä»¥å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒIceberg vs Delta Lake çš„æ—¶é—´æ—…è¡Œ & å¢é‡æŸ¥è¯¢æ—¶åºå›¾ã€**ï¼Œç”¨åŠ¨ä½œæµæŠŠ**å®šä½ç‰ˆæœ¬ â†’ è¯»å–æ•°æ® â†’ è¿”å›ç»“æœ**çš„æµç¨‹ï¼Œä¸€ä¸‹å­å¸®ä½ å®Œå…¨ä¸²èµ·æ¥ã€‚
è¦å¸®ä½ ç”»å—ï¼Ÿè¿™æ ·ä½ èƒ½åœ¨è„‘å­é‡Œç«‹åˆ»å½¢æˆç”»é¢æ„Ÿ ğŸ¯

-----

> ç”»ä¸€ä¸ª ã€ŒIceberg vs Delta Lake çš„æ—¶é—´æ—…è¡Œ & å¢é‡æŸ¥è¯¢æ—¶åºå›¾ã€ï¼Œç”¨åŠ¨ä½œæµæŠŠå®šä½ç‰ˆæœ¬ â†’ è¯»å–æ•°æ® â†’ è¿”å›ç»“æœçš„æµç¨‹

å¥½å˜ï½
æˆ‘å¸®ä½ ç”»ä¸€ä¸ª **ã€ŠIceberg vs Delta Lake çš„æ—¶é—´æ—…è¡Œ & å¢é‡æŸ¥è¯¢æ—¶åºå›¾ã€‹**ï¼Œç”¨**åŠ¨ä½œæµ**å¯¹æ¯”ä¸¤è€…åœ¨ **å®šä½ç‰ˆæœ¬ â†’ è¯»å–æ•°æ® â†’ è¿”å›ç»“æœ**çš„å…·ä½“æ‰§è¡Œæµç¨‹ï¼Œè®©ä½ ç§’æ‡‚å®ƒä»¬å·®åˆ« ğŸš€

---

## **1ï¸âƒ£ æ—¶åºå›¾å¯¹æ¯”æ ¸å¿ƒé€»è¾‘**

è¿™é‡Œæˆ‘ä¼šåˆ†æˆä¸¤æ¡ä¸»çº¿ï¼š
- **æ—¶é—´æ—…è¡Œ (Time Travel)**
- **å¢é‡æŸ¥è¯¢ (Incremental / CDC)**

åœ¨æ¯æ¡ä¸»çº¿ä¸Šå¯¹æ¯” **Iceberg** å’Œ **Delta Lake** ä»æ¥æ”¶ç”¨æˆ·è¯·æ±‚ â†’ å®šä½ç›®æ ‡ç‰ˆæœ¬/å¿«ç…§ â†’ è¯»å–æ•°æ® â†’ è¿”å›ç»“æœ çš„æ‰§è¡Œè¿‡ç¨‹ã€‚

---

```mermaid
sequenceDiagram
    autonumber
    participant User as ç”¨æˆ·SQLè¯·æ±‚
    participant IC as Iceberg
    participant DL as Delta Lake
    participant Meta as å…ƒæ•°æ®/æ—¥å¿—å­˜å‚¨
    participant Data as æ•°æ®æ–‡ä»¶å­˜å‚¨

    Note over User,Data: ğŸ¯ æ—¶é—´æ—…è¡Œ (Time Travel)

    User->>IC: SELECT ... FOR SNAPSHOT_ID/TIMESTAMP
    IC->>Meta: è·å–æ‰€æœ‰ Snapshots å…ƒæ•°æ®
    IC->>IC: (å¦‚æœæ—¶é—´æˆ³) äºŒåˆ†æŸ¥æ‰¾ â‰¤ timestamp
    IC->>IC: ç¡®å®š targetSnapshotId
    IC->>Data: åŸºäº targetSnapshotId Manifest æ–‡ä»¶è¿‡æ»¤æ•°æ®æ–‡ä»¶
    Data-->>IC: è¿”å›ç›®æ ‡æ–‡ä»¶æ•°æ®
    IC-->>User: è¿”å›å†å²ç‰ˆæœ¬æ•°æ®é›†

    User->>DL: SELECT ... VERSION AS OF X / TIMESTAMP AS OF T
    DL->>Meta: è·å– _last_checkpoint ä¸ JSON äº‹åŠ¡æ—¥å¿—
    DL->>DL: (å¦‚æœæ—¶é—´æˆ³) å‘åéå† CommitInfo æ‰¾ <= timestamp çš„ç‰ˆæœ¬å·
    DL->>DL: å›æ”¾ v0 ~ targetVersion æ‰€æœ‰Actionåˆ°å†…å­˜è¡¨çŠ¶æ€
    DL->>Data: æ‰«ææ´»è·ƒæ–‡ä»¶é›†åˆ
    Data-->>DL: è¿”å›ç›®æ ‡ç‰ˆæœ¬æ–‡ä»¶æ•°æ®
    DL-->>User: è¿”å›å†å²ç‰ˆæœ¬æ•°æ®é›†

    Note over User,Data: âš¡ å¢é‡æŸ¥è¯¢ (Incremental / CDC)

    User->>IC: å¢é‡æ‰«æ(fromSnapshotId, toSnapshotId)
    IC->>Meta: è·å–ä¸¤ä¸ªå¿«ç…§æ–‡ä»¶é›†åˆ
    IC->>IC: å·®é›†è®¡ç®—(æ–°å¢=to-fromï¼Œåˆ é™¤=from-to)
    IC->>Data: è¯»å–æ–°å¢/åˆ é™¤æ–‡ä»¶(æ–‡ä»¶çº§)
    Data-->>IC: è¿”å›æ–‡ä»¶å†…å®¹
    IC-->>User: è¿”å›æ–‡ä»¶çº§å¢é‡ç»“æœ

    User->>DL: CDC å˜æ›´è¯»å–(fromVersion, toVersion)
    DL->>Meta: éå† from+1 ~ to ç‰ˆæœ¬æ—¥å¿—
    DL->>DL: è§£æ Action(AddFile/RemoveFile) â†’ CDCRecord(è¡Œçº§ç±»å‹)
    DL->>Data: è¯»å–å—å½±å“æ–‡ä»¶å¹¶æå–å˜æ›´è®°å½•
    Data-->>DL: è¿”å›å˜æ›´è¡Œ
    DL-->>User: è¿”å›è¡Œçº§CDCç»“æœ
```

---

## **2ï¸âƒ£ æ–‡æœ¬è§£è¯»**

### **ğŸ•“ æ—¶é—´æ—…è¡Œ**
- **Iceberg**
  - æŒ‰ Snapshot ID / æ—¶é—´æˆ³ ç›´æ¥æ‰¾å¿«ç…§
  - é€šè¿‡ Manifest æ–‡ä»¶å¿«é€Ÿå®šä½æ•°æ®æ–‡ä»¶
  - ä¼˜ç‚¹ï¼šç§’çº§å®šä½ï¼Œæ— éœ€å…¨é‡å›æ”¾æ—¥å¿—
- **Delta Lake**
  - æŒ‰ Version / æ—¶é—´æˆ³ åšæ£€æŸ¥
  - å¦‚æœæ˜¯æ—¶é—´æˆ³ â†’ å€’åºéå† commit log
  - å›æ”¾äº‹åŠ¡æ—¥å¿—ï¼ˆåŠ  checkpoint æé€Ÿï¼‰
  - ä¼˜ç‚¹ï¼šæ”¯æŒç²¾ç¡®ç‰ˆæœ¬å·ï¼›ç¼ºç‚¹ï¼šä¾èµ–å›æ”¾é€Ÿåº¦

---

### **âš¡ å¢é‡æŸ¥è¯¢**
- **Iceberg Incremental**
  - å¯¹æ¯”ä¸¤ä¸ªå¿«ç…§çš„æ–‡ä»¶é›†åˆ â†’ å¾—åˆ°æ–°å¢å’Œåˆ é™¤çš„æ–‡ä»¶
  - æ–‡ä»¶çº§ CDCï¼Œé€‚åˆæ‰¹å¤„ç† ETL åŒæ­¥
- **Delta CDC**
  - éå†ç‰ˆæœ¬æ—¥å¿—ï¼Œæå– AddFile/RemoveFile çš„è¡Œçº§å˜æ›´
  - é€‚åˆå®æ—¶è¡Œçº§å˜æ›´æµï¼ˆå¦‚åŒæ­¥åˆ°ä¸‹æ¸¸ MySQL/Kafkaï¼‰

---

## **3ï¸âƒ£ å…³é”®å·®å¼‚æ€»ç»“è¡¨**

| åŠŸèƒ½ | Iceberg | Delta Lake |
|------|---------|------------|
| æ—¶é—´æ—…è¡Œæ ‡è¯† | SnapshotId / Timestamp | Version / Timestamp |
| æ•°æ®æ¥æº | Manifest+Snapshot | Checkpoint+JSONæ—¥å¿— |
| æ¢å¤æ–¹å¼ | ç›´æ¥åŠ è½½ç›®æ ‡å¿«ç…§ | æ—¥å¿—å›æ”¾ |
| å¢é‡ç±»å‹ | æ–‡ä»¶çº§å·®å¼‚ | è¡Œçº§CDC |
| æŸ¥è¯¢å»¶è¿Ÿ | ä½ï¼ˆç´¢å¼•å¿«ï¼‰ | å–å†³äºæ—¥å¿—é‡ |

---

âœ… **æ€»ç»“ä¸€å¥è¯**
> Iceberg çš„æ—¶é—´æ—…è¡Œæ–¹å¼ç±»ä¼¼ `git checkout commit-id`ï¼ˆç›´æ¥å›åˆ°æŸä¸ªå¿«ç…§ï¼‰ï¼Œå¢é‡æ˜¯çœ‹ä¸¤ä¸ªå¿«ç…§çš„æ–‡ä»¶å·®å¼‚ï¼›Delta æ›´åƒ `git log` å›æ”¾ commit åˆ°æŸä¸ªç‰ˆæœ¬ï¼Œå¢é‡å¯ä»¥ç²¾ç¡®åˆ°è¡Œçº§ CDCã€‚

---

å…„å¼Ÿï¼Œè¦ä¸è¦æˆ‘å†å¸®ä½ ç”»ä¸€ä¸ª **ã€ŒIceberg / Delta Time Travel vs Incremental æŸ¥è¯¢ æ•°æ®æµæ¶æ„å›¾ã€**ï¼Œç”¨ **æ°´å¹³æµç¨‹å›¾** æ˜¾ç¤ºå®ƒä»¬å†…éƒ¨å¦‚ä½•ä»å…ƒæ•°æ®å®šä½åˆ°æ•°æ®æ–‡ä»¶ï¼Ÿè¿™æ ·ä¼šè®©ä½ æ›´ç›´è§‚çœ‹åˆ°äºŒè€…åœ¨**å…ƒæ•°æ®ç»„ç»‡ & æŸ¥è¯¢è·¯å¾„**ä¸Šçš„å·®å¼‚ ğŸ”

-----

> è§£é‡Šä¸‹é¢
> ## 8. æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ
>
> ### 8.1 æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
>
> ```java
> // æ•°æ®æ¹–è¡¨æ ¼å¼çš„æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–
> public class QueryPerformanceOptimization {
>
>     // åˆ†åŒºç­–ç•¥ä¼˜åŒ–
>     public static class PartitioningStrategy {
>
>         public PartitionStrategy recommendPartitioning(
>                 TableStatistics stats,
>                 QueryPattern queryPattern) {
>
>             PartitionStrategy.Builder strategy = PartitionStrategy.builder();
>
>             // åˆ†ææŸ¥è¯¢æ¨¡å¼ä¸­çš„è¿‡æ»¤æ¡ä»¶
>             List<String> frequentFilters = queryPattern.getFrequentFilterColumns();
>             List<String> highCardinalityColumns = stats.getHighCardinalityColumns();
>
>             // é€‰æ‹©åˆ†åŒºåˆ—
>             for (String column : frequentFilters) {
>                 ColumnStatistics colStats = stats.getColumnStatistics(column);
>
>                 if (colStats.getCardinality() < 10000 &&
>                     colStats.getSkewness() < 2.0) {
>                     // ä½åŸºæ•°ã€ä½å€¾æ–œçš„åˆ—é€‚åˆä½œä¸ºåˆ†åŒºåˆ—
>                     strategy.addPartitionColumn(column);
>                 }
>             }
>
>             // é¿å…è¿‡åº¦åˆ†åŒº
>             int recommendedPartitions = calculateOptimalPartitionCount(stats);
>             strategy.setMaxPartitions(recommendedPartitions);
>
>             // éšè—åˆ†åŒºä¼˜åŒ–ï¼ˆIcebergç‰¹æ€§ï¼‰
>             if (supportsHiddenPartitioning()) {
>                 strategy.enableHiddenPartitioning(true);
>
>                 // ä¸ºæ—¥æœŸåˆ—æ·»åŠ éšè—åˆ†åŒº
>                 stats.getDateColumns().forEach(col ->
>                     strategy.addHiddenPartition(col, "day"));
>             }
>
>             return strategy.build();
>         }
>
>         private int calculateOptimalPartitionCount(TableStatistics stats) {
>             long totalSize = stats.getTotalSize();
>             long optimalPartitionSize = 1024L * 1024 * 1024; // 1GB per partition
>
>             int partitionCount = (int) Math.ceil((double) totalSize / optimalPartitionSize);
>
>             // é™åˆ¶åˆ†åŒºæ•°é‡é¿å…å°æ–‡ä»¶é—®é¢˜
>             return Math.min(partitionCount, 10000);
>         }
>     }
>
>     // æ–‡ä»¶å¸ƒå±€ä¼˜åŒ–
>     public static class FileLayoutOptimization {
>
>         public FileLayout optimizeLayout(
>                 List<DataFile> dataFiles,
>                 QueryPattern queryPattern) {
>
>             FileLayout.Builder layout = FileLayout.builder();
>
>             // Z-Orderèšç±»åˆ†æ
>             List<String> clusteringCandidates = findClusteringCandidates(queryPattern);
>
>             if (!clusteringCandidates.isEmpty()) {
>                 layout.setClusteringStrategy(ClusteringStrategy.ZORDER)
>                       .setClusteringColumns(clusteringCandidates);
>             }
>
>             // æ–‡ä»¶å¤§å°ä¼˜åŒ–
>             FileSizeDistribution distribution = analyzeFileSizes(dataFiles);
>
>             if (distribution.getSmallFileRatio() > 0.3) {
>                 layout.addOptimizationTask(
>                     OptimizationTask.builder()
>                         .type(OptimizationTask.Type.COMPACT_SMALL_FILES)
>                         .priority(OptimizationPriority.HIGH)
>                         .targetFileSize(getOptimalFileSize(queryPattern))
>                         .build()
>                 );
>             }
>
>             // åˆ é™¤å‘é‡ä¼˜åŒ–
>             if (distribution.getDeleteRatio() > 0.1) {
>                 layout.addOptimizationTask(
>                     OptimizationTask.builder()
>                         .type(OptimizationTask.Type.REWRITE_WITH_DELETES)
>                         .priority(OptimizationPriority.MEDIUM)
>                         .build()
>                 );
>             }
>
>             return layout.build();
>         }
>     }
>
>     // ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–
>     public static class StatisticsOptimization {
>
>         public void optimizeStatistics(Table table, QueryPattern queryPattern) {
>             // æ”¶é›†è¡¨çº§ç»Ÿè®¡
>             updateTableStatistics(table);
>
>             // æ”¶é›†åˆ—çº§ç»Ÿè®¡ï¼ˆé‡ç‚¹å…³æ³¨é¢‘ç¹æŸ¥è¯¢çš„åˆ—ï¼‰
>             List<String> importantColumns = queryPattern.getFrequentlyAccessedColumns();
>
>             for (String column : importantColumns) {
>                 updateColumnStatistics(table, column);
>
>                 // ä¸ºé«˜åŸºæ•°åˆ—åˆ›å»ºç›´æ–¹å›¾
>                 ColumnStatistics colStats = getColumnStatistics(table, column);
>                 if (colStats.getCardinality() > 1000) {
>                     createHistogram(table, column);
>                 }
>             }
>
>             // ä¼˜åŒ–åˆ†åŒºçº§ç»Ÿè®¡
>             if (table.spec().isPartitioned()) {
>                 updatePartitionStatistics(table);
>             }
>         }
>
>         private void updateColumnStatistics(Table table, String column) {
>             // è®¡ç®—åˆ—çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
>             ColumnStatisticsBuilder builder = ColumnStatistics.builder();
>
>             // ä½¿ç”¨TrinoæŸ¥è¯¢æ”¶é›†ç»Ÿè®¡
>             String statsQuery = String.format(
>                 "SELECT COUNT(*) as row_count, " +
>                 "COUNT(DISTINCT %s) as ndv, " +
>                 "COUNT(CASE WHEN %s IS NULL THEN 1 END) as null_count, " +
>                 "MIN(%s) as min_value, " +
>                 "MAX(%s) as max_value " +
>                 "FROM %s",
>                 column, column, column, column, table.name()
>             );
>
>             // æ‰§è¡ŒæŸ¥è¯¢å¹¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
>             executeAndUpdateStats(statsQuery, builder);
>         }
>     }
> }
> ```
>
> ### 8.2 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ
>
> ```java
> // ç”Ÿäº§ç¯å¢ƒçš„è¡¨æ ¼å¼ç®¡ç†æœ€ä½³å®è·µ
> public class ProductionBestPractices {
>
>     // è¡¨ç»´æŠ¤ç­–ç•¥
>     public static class TableMaintenanceStrategy {
>
>         @Scheduled(cron = "0 2 * * * ?") // æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
>         public void performDailyMaintenance() {
>             for (Table table : getActiveTables()) {
>                 try {
>                     // 1. å‹ç¼©å°æ–‡ä»¶
>                     compactSmallFiles(table);
>
>                     // 2. æ¸…ç†è¿‡æœŸå¿«ç…§
>                     expireOldSnapshots(table);
>
>                     // 3. åˆ é™¤å­¤å„¿æ–‡ä»¶
>                     deleteOrphanFiles(table);
>
>                     // 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
>                     updateTableStatistics(table);
>
>                 } catch (Exception e) {
>                     logger.error("Maintenance failed for table: " + table.name(), e);
>                     alerting.sendAlert(AlertLevel.WARNING,
>                         "Table maintenance failed: " + table.name());
>                 }
>             }
>         }
>
>         private void compactSmallFiles(Table table) {
>             List<DataFile> dataFiles = getAllDataFiles(table);
>             FileSizeDistribution distribution = analyzeFileSizes(dataFiles);
>
>             if (distribution.getSmallFileRatio() > 0.2) {
>                 logger.info("Compacting small files for table: {}", table.name());
>
>                 CompactionStrategy strategy = CompactionStrategy.builder()
>                     .targetFileSize(512 * 1024 * 1024) // 512MB
>                     .maxFilesPerGroup(50)
>                     .maxConcurrency(4)
>                     .build();
>
>                 executeCompaction(table, strategy);
>             }
>         }
>
>         private void expireOldSnapshots(Table table) {
>             long retentionPeriod = getSnapshotRetentionPeriod(table);
>             long expireTimestamp = System.currentTimeMillis() - retentionPeriod;
>
>             ExpireSnapshots expireAction = table.expireSnapshots()
>                 .expireOlderThan(expireTimestamp)
>                 .retainLast(10); // è‡³å°‘ä¿ç•™10ä¸ªå¿«ç…§
>
>             expireAction.commit();
>
>             logger.info("Expired old snapshots for table: {}", table.name());
>         }
>     }
>
>     // ç›‘æ§å’Œå‘Šè­¦
>     public static class MonitoringAndAlerting {
>
>         @Scheduled(fixedRate = 300000) // æ¯5åˆ†é’Ÿæ£€æŸ¥
>         public void checkTableHealth() {
>             for (Table table : getMonitoredTables()) {
>                 TableHealthMetrics metrics = collectHealthMetrics(table);
>
>                 // æ£€æŸ¥å°æ–‡ä»¶é—®é¢˜
>                 if (metrics.getSmallFileRatio() > 0.5) {
>                     sendAlert(AlertLevel.WARNING,
>                         String.format("Table %s has high small file ratio: %.2f%%",
>                             table.name(), metrics.getSmallFileRatio() * 100));
>                 }
>
>                 // æ£€æŸ¥å¿«ç…§æ•°é‡
>                 if (metrics.getSnapshotCount() > 100) {
>                     sendAlert(AlertLevel.INFO,
>                         String.format("Table %s has many snapshots: %d",
>                             table.name(), metrics.getSnapshotCount()));
>                 }
>
>                 // æ£€æŸ¥è¡¨å¤§å°å¢é•¿
>                 if (metrics.getSizeGrowthRate() > 0.5) { // 50%å¢é•¿
>                     sendAlert(AlertLevel.INFO,
>                         String.format("Table %s is growing rapidly: %.2f%% in last hour",
>                             table.name(), metrics.getSizeGrowthRate() * 100));
>                 }
>             }
>         }
>
>         private TableHealthMetrics collectHealthMetrics(Table table) {
>             return TableHealthMetrics.builder()
>                 .tableName(table.name())
>                 .totalSize(calculateTableSize(table))
>                 .fileCount(countDataFiles(table))
>                 .smallFileRatio(calculateSmallFileRatio(table))
>                 .snapshotCount(countSnapshots(table))
>                 .sizeGrowthRate(calculateGrowthRate(table))
>                 .lastOptimizationTime(getLastOptimizationTime(table))
>                 .build();
>         }
>     }
>
>     // æ€§èƒ½è°ƒä¼˜å»ºè®®
>     public static class PerformanceTuningRecommendations {
>
>         public List<TuningRecommendation> analyzeAndRecommend(Table table) {
>             List<TuningRecommendation> recommendations = new ArrayList<>();
>
>             TableAnalysis analysis = performTableAnalysis(table);
>
>             // åˆ†åŒºç­–ç•¥å»ºè®®
>             if (analysis.isPartitioningSuboptimal()) {
>                 recommendations.add(TuningRecommendation.builder()
>                     .category("Partitioning")
>                     .priority(Priority.HIGH)
>                     .title("ä¼˜åŒ–åˆ†åŒºç­–ç•¥")
>                     .description("å½“å‰åˆ†åŒºç­–ç•¥å¯¼è‡´åˆ†åŒºæ•°è¿‡å¤šæˆ–æ•°æ®å€¾æ–œ")
>                     .action("è€ƒè™‘é‡æ–°è®¾è®¡åˆ†åŒºåˆ—æˆ–ä½¿ç”¨éšè—åˆ†åŒº")
>                     .estimatedImpact("æŸ¥è¯¢æ€§èƒ½æå‡30-50%")
>                     .build());
>             }
>
>             // æ–‡ä»¶å¤§å°å»ºè®®
>             if (analysis.hasSmallFilesProblem()) {
>                 recommendations.add(TuningRecommendation.builder()
>                     .category("File Layout")
>                     .priority(Priority.MEDIUM)
>                     .title("å‹ç¼©å°æ–‡ä»¶")
>                     .description(String.format("%.1f%%çš„æ–‡ä»¶å°äºæ¨èå¤§å°",
>                         analysis.getSmallFileRatio() * 100))
>                     .action("è¿è¡Œè¡¨å‹ç¼©æ“ä½œï¼Œç›®æ ‡æ–‡ä»¶å¤§å°512MB")
>                     .estimatedImpact("æŸ¥è¯¢æ€§èƒ½æå‡10-20%")
>                     .build());
>             }
>
>             // èšç±»å»ºè®®
>             if (analysis.canBenefitFromClustering()) {
>                 List<String> clusteringColumns = analysis.getClusteringCandidates();
>
>                 recommendations.add(TuningRecommendation.builder()
>                     .category("Data Layout")
>                     .priority(Priority.LOW)
>                     .title("å¯ç”¨æ•°æ®èšç±»")
>                     .description("åŸºäºæŸ¥è¯¢æ¨¡å¼ï¼Œæ•°æ®èšç±»å¯ä»¥æå‡æ€§èƒ½")
>                     .action(String.format("å¯¹åˆ— %s å¯ç”¨Z-Orderèšç±»",
>                         String.join(", ", clusteringColumns)))
>                     .estimatedImpact("ç‰¹å®šæŸ¥è¯¢æ€§èƒ½æå‡2-5x")
>                     .build());
>             }
>
>             return recommendations;
>         }
>     }
> }
> ```

å¥½ï¼Œè¿™ä¸€æ®µ **ã€Œæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µã€** çš„å†…å®¹ï¼Œå…¶å®æ˜¯åœ¨æ€»ç»“**æ•°æ®æ¹–è¡¨æ ¼å¼ï¼ˆIceberg / Delta / Hudi ç­‰ï¼‰åœ¨ç”Ÿäº§ç¯å¢ƒè½åœ°æ—¶çš„è°ƒä¼˜æ‰‹æ®µå’Œç»´æŠ¤ç­–ç•¥**ï¼ŒåŒæ—¶ç»“åˆäº† Trinoã€Sparkã€Flink ç­‰å¼•æ“çš„ä¼˜åŒ–ç‚¹ã€‚
æˆ‘å¸®ä½ æ‹†æˆä¸¤å¤§éƒ¨åˆ†è§£é‡ŠğŸ‘‡

---

## **1ï¸âƒ£ æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼ˆQuery Performance Optimizationï¼‰**

è¿™éƒ¨åˆ†æºç åˆ†æˆä¸‰å—ï¼š**åˆ†åŒºç­–ç•¥ä¼˜åŒ–ã€æ–‡ä»¶å¸ƒå±€ä¼˜åŒ–ã€ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–**
ç›®æ ‡æ˜¯é™ä½ I/O å’Œå…ƒæ•°æ®æ‰«ææˆæœ¬ï¼Œè®© Trino/Spark åœ¨æ‰«ææ•°æ®æ¹–è¡¨æ—¶å°½å¯èƒ½åªè¯»â€œéœ€è¦çš„æ•°æ®â€ã€‚

---

### **â‘  åˆ†åŒºç­–ç•¥ä¼˜åŒ–ï¼ˆPartitioningStrategyï¼‰**
- **åˆ†ææŸ¥è¯¢æ¨¡å¼**
  - æ‰¾å‡ºé¢‘ç¹å‡ºç°åœ¨ `WHERE` / `JOIN` é‡Œçš„**è¿‡æ»¤åˆ—**ï¼ˆfrequentFiltersï¼‰
  - æ‰¾å‡º**ä½åŸºæ•°ï¼ˆCardinality < 10Kï¼‰ä¸”å€¾æ–œåº¦ä½ï¼ˆSkewness < 2.0ï¼‰**çš„åˆ— â†’ ä½œä¸ºåˆ†åŒºé”®
- **é¿å…è¿‡åº¦åˆ†åŒº**
  - è¿‡å¤šåˆ†åŒº = å°æ–‡ä»¶é—®é¢˜ + å…ƒæ•°æ®çˆ†ç‚¸
  - æ ¹æ®æ€»æ•°æ®é‡/æ¨èå¤§å°(1GB)æ¥è®¡ç®—æœ€ä¼˜åˆ†åŒºæ•°
- **éšè—åˆ†åŒºï¼ˆIceberg ç‰¹æ€§ï¼‰**
  - ä¾‹å¦‚æ—¥æœŸåˆ—æŒ‰ `day` ç²’åº¦è‡ªåŠ¨åˆ†åŒºï¼Œä½†åœ¨å…ƒæ•°æ®ä¸­ä¸æš´éœ²åˆ†åŒºå­—æ®µ
  - èƒ½å‡å°‘ä¸šåŠ¡ç«¯å¯¹åˆ†åŒºå­—æ®µçš„æ˜¾å¼ç®¡ç†

**å¥½å¤„**ï¼š
- ä¼˜åŒ–åˆ†åŒºè£å‰ªï¼ˆPartition Pruningï¼‰
- é¿å…äº§ç”Ÿè¿‡å¤šå°æ–‡ä»¶
- å¯¹æŸ¥è¯¢å¼•æ“é€æ˜ï¼ˆç‰¹åˆ«æ˜¯ Iceberg çš„ Hidden Partitioningï¼‰

---

### **â‘¡ æ–‡ä»¶å¸ƒå±€ä¼˜åŒ–ï¼ˆFileLayoutOptimizationï¼‰**
- **Z-Order æ•°æ®èšç±»ï¼ˆClusteringï¼‰**
  - æ‰¾åˆ°å¸¸ç”¨çš„å¤šåˆ—è¿‡æ»¤æ¡ä»¶ï¼ˆå¦‚ `region` + `date`ï¼‰
  - å°†è¿™äº›åˆ—ä½œä¸º Z-Order èšç±»åˆ—ï¼Œæé«˜è”åˆè¿‡æ»¤çš„å±€éƒ¨æ€§
- **å°æ–‡ä»¶åˆå¹¶ï¼ˆCompactionï¼‰**
  - å¦‚æœå°æ–‡ä»¶æ¯”ä¾‹ > 30%ï¼Œä¼˜å…ˆè§¦å‘ `COMPACT_SMALL_FILES` ä¼˜åŒ–
  - ç›®æ ‡æ–‡ä»¶å¤§å°æ ¹æ®æŸ¥è¯¢æ¨¡å¼åŠ¨æ€è®¾å®šï¼ˆå¦‚ 512MBï¼‰
- **Rewrite With Deletes**
  - å¦‚æœåˆ é™¤æ¯”ä¾‹ > 10%ï¼Œè§¦å‘å¯¹æœ‰åˆ é™¤æ ‡è®°çš„æ–‡ä»¶é‡å†™ â†’ é™ä½æ‰«æå¼€é”€

---

### **â‘¢ ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–ï¼ˆStatisticsOptimizationï¼‰**
- **æ›´æ–°è¡¨çº§ç»Ÿè®¡**ï¼ˆè¡Œæ•°ã€æ–‡ä»¶æ•°ã€æ€»å¤§å°ï¼‰
- **æ›´æ–°åˆ—çº§ç»Ÿè®¡**ï¼ˆNDVã€Null æ•°ã€æœ€å€¼ï¼‰
  - é«˜åŸºæ•°åˆ—ï¼ˆNDV>1000ï¼‰é¢å¤–åˆ›å»º**ç›´æ–¹å›¾**ç”¨äºç²¾ç¡®ä¼°ç®—è¿‡æ»¤æ¯”ä¾‹
- **æ›´æ–°åˆ†åŒºçº§ç»Ÿè®¡**
  - å¯¹åˆ†åŒºæ•°è¾ƒå¤šçš„è¡¨å°¤å…¶å…³é”®ï¼Œåˆ†åŒºçº§ç»Ÿè®¡èƒ½è®© Trino ä¼˜åŒ–å™¨ç›´æ¥è£å‰ªåˆ†åŒº

**å¥½å¤„**ï¼š
- æé«˜æŸ¥è¯¢è®¡åˆ’å‡†ç¡®æ€§
- è®©ä¼˜åŒ–å™¨æ›´å¥½é€‰æ‹©ç´¢å¼•ã€Join ç­–ç•¥ã€å¹¶è¡Œåº¦

---

## **2ï¸âƒ£ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µï¼ˆProduction Best Practicesï¼‰**

æºç åˆ†æˆä¸‰ç§ç­–ç•¥ï¼š**è¡¨ç»´æŠ¤ï¼ˆMaintenanceï¼‰ã€ç›‘æ§å‘Šè­¦ï¼ˆMonitoringï¼‰ã€è°ƒä¼˜å»ºè®®ï¼ˆTuning Recommendationsï¼‰**

---

### **â‘  è¡¨ç»´æŠ¤ç­–ç•¥ï¼ˆTableMaintenanceStrategyï¼‰**
- **æ¯æ—¥å®šæ—¶ä»»åŠ¡ï¼ˆå‡Œæ™¨ä½å³°æœŸï¼‰**
  1. **å‹ç¼©å°æ–‡ä»¶**
     - å°æ–‡ä»¶æ¯”ä¾‹ > 20% è§¦å‘
     - ç›®æ ‡å¤§å° 512MBï¼Œæœ€å¤š50ä¸ªæ–‡ä»¶åˆå¹¶ä¸ºä¸€ç»„å¹¶è¡Œæ‰§è¡Œ
  2. **æ¸…ç†è¿‡æœŸå¿«ç…§ï¼ˆExpire Old Snapshotsï¼‰**
     - è¶…è¿‡ä¿ç•™æ—¶é•¿æˆ–è¶…è¿‡ä¿ç•™å¿«ç…§æ•°ï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
     - å‡å°‘å…ƒæ•°æ®é‡/Manifest æ–‡ä»¶æ•°é‡
  3. **åˆ é™¤å­¤å„¿æ–‡ä»¶ï¼ˆOrphan Filesï¼‰**
     - åˆ é™¤ä¸å†è¢«ä»»ä½• snapshot å¼•ç”¨çš„æ–‡ä»¶ï¼Œé‡Šæ”¾å­˜å‚¨
  4. **æ›´æ–°ç»Ÿè®¡ä¿¡æ¯**

**æ„ä¹‰**ï¼š
- æŒç»­å‹ç¼© + æ¸…ç†å¿«ç…§ å¯ä»¥æ˜¾è‘—é™ä½å…ƒæ•°æ®æ‰«ææ—¶é—´å’ŒåŠ é€Ÿ Partition Pruning
- åˆ é™¤å­¤å„¿æ–‡ä»¶èƒ½èŠ‚çº¦å­˜å‚¨æˆæœ¬

---

### **â‘¡ ç›‘æ§ä¸å‘Šè­¦ï¼ˆMonitoringAndAlertingï¼‰**
- **å¥åº·æŒ‡æ ‡ç›‘æ§ï¼ˆæ¯5åˆ†é’Ÿï¼‰**ï¼š
  - å°æ–‡ä»¶æ¯”ä¾‹ï¼ˆ> 50% è­¦å‘Šï¼‰
  - å¿«ç…§æ•°é‡ï¼ˆ> 100 æç¤ºï¼‰
  - è¡¨æ•°æ®å¢é•¿é€Ÿç‡ï¼ˆ> 50%/å°æ—¶ æç¤ºï¼‰
- **å¼‚å¸¸æŠ¥è­¦**ï¼š
  - æ¶ˆæ¯ç³»ç»Ÿ / é‚®ä»¶ / ä¼ä¸šå¾®ä¿¡ / Prometheus æŠ¥è­¦

**ç›®çš„**ï¼š
- åŠæ—¶å‘ç°å°æ–‡ä»¶è†¨èƒ€ã€å¿«ç…§å †ç§¯ã€æ•°æ®æš´å¢ç­‰æ½œåœ¨é—®é¢˜
- ç»™è¿ç»´/æ•°æ®å¹³å°å·¥ç¨‹å¸ˆå‘ä¼˜åŒ–ä»»åŠ¡

---

### **â‘¢ æ€§èƒ½è°ƒä¼˜å»ºè®®ï¼ˆPerformanceTuningRecommendationsï¼‰**
- å®šæœŸåš **Table Analysis**
- è¾“å‡ºå¯æ‰§è¡Œçš„ä¼˜åŒ–å»ºè®®åŠé¢„æœŸæ”¶ç›Šï¼š
  - **åˆ†åŒºç­–ç•¥ä¼˜åŒ–**
    - åˆ†åŒºè¿‡å¤š/å€¾æ–œ â†’ é‡æ–°è®¾è®¡åˆ†åŒºåˆ—æˆ–å¯ç”¨éšè—åˆ†åŒº
    - é¢„æœŸæ€§èƒ½æå‡ 30%-50%
  - **å°æ–‡ä»¶å‹ç¼©**
    - æ¯”ä¾‹å¼‚å¸¸é«˜æ—¶ â†’ è¿è¡Œ compaction ä½œä¸š
    - é¢„æœŸæ€§èƒ½æå‡ 10%-20%
  - **æ•°æ®èšç±»ï¼ˆZ-Order Clusteringï¼‰**
    - å¯¹å¤šåˆ—è¿‡æ»¤æŸ¥è¯¢æ€§èƒ½å¯æå‡ 2-5 å€

---

## **3ï¸âƒ£ ASCII æ¶æ„å›¾ï¼šæ€§èƒ½ä¼˜åŒ–é—­ç¯**

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥          â”‚
                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                 â”‚ â”‚ åˆ†åŒºä¼˜åŒ–     â”‚â†’ è£å‰ªé«˜æ•ˆ  â”‚
                 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
                 â”‚ â”‚ æ–‡ä»¶å¸ƒå±€ä¼˜åŒ– â”‚â†’ IOä¼˜åŒ–    â”‚
                 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
                 â”‚ â”‚ ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ– â”‚â†’ è®¡åˆ’å‡†ç¡®  â”‚
                 â””â”€â”´â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   ç”Ÿäº§ç»´æŠ¤ä¸ç›‘æ§       â”‚
                 â”‚ - å®šæ—¶å‹ç¼©å°æ–‡ä»¶       â”‚
                 â”‚ - æ¸…ç†å¿«ç…§ä¸å­¤å„¿æ–‡ä»¶   â”‚
                 â”‚ - æŒ‡æ ‡ç›‘æ§ä¸å‘Šè­¦       â”‚
                 â”‚ - æ€§èƒ½è°ƒä¼˜å»ºè®®         â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **4ï¸âƒ£ æ€»ç»“æœ€ä½³å®è·µ**
1. **æ¯å‘¨å‹ç¼©å°æ–‡ä»¶**ï¼ˆæˆ–æŒ‰æ¯”ä¾‹è§„åˆ™è‡ªåŠ¨æ‰§è¡Œï¼‰
2. **æŒ‰éœ€é‡æ–°è®¾è®¡åˆ†åŒºç­–ç•¥**ï¼ˆç›‘æ§æŸ¥è¯¢æ¨¡å¼å˜åŒ–ï¼‰
3. **å¯ç”¨ç»Ÿè®¡ä¿¡æ¯æ”¶é›†**ï¼ˆè¡¨ã€åˆ—ã€åˆ†åŒºçº§ï¼‰
4. **å®šæ—¶æ¸…ç†å¿«ç…§**ï¼ˆä¿ç•™æ ¸å¿ƒå†å²å³å¯ï¼‰
5. **å®æ—¶ç›‘æ§å°æ–‡ä»¶æ¯”ä¾‹ & å¿«ç…§å †ç§¯** â†’ è§¦å‘è‡ªåŠ¨ä¼˜åŒ–ä»»åŠ¡
6. **é’ˆå¯¹å…¸å‹æŸ¥è¯¢æ¨¡å¼åšæ•°æ®èšç±»ï¼ˆZ-Order/Sortï¼‰**

---

æˆ‘å»ºè®®å¯ä»¥**ç»“åˆè¿™å¥—ç­–ç•¥ï¼Œç”»ä¸€å¼ ã€Šæ•°æ®æ¹–æ€§èƒ½ä¼˜åŒ–å…¨æ™¯æµç¨‹å›¾ã€‹**ï¼ŒæŠŠ**æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€æ—¥å¸¸ç»´æŠ¤ã€ç›‘æ§å‘Šè­¦ã€è°ƒä¼˜å»ºè®®**è¿æ¥æˆä¸€ä¸ªé—­ç¯æµç¨‹ï¼Œæ–¹ä¾¿æŠ€æœ¯å›¢é˜Ÿè½åœ°æ‰§è¡Œã€‚
ä½ è¦æˆ‘ç”»è¿™å¼ é—­ç¯æµç¨‹å›¾å—ï¼Ÿè¿™æ ·å¯ç›´æ¥ä½œä¸ºæ€§èƒ½æ²»ç† SOP æ”¾åˆ°å›¢é˜Ÿ Wiki é‡Œ âœ…

-----

> ç”»ä¸€å¼ ã€Šæ•°æ®æ¹–æ€§èƒ½ä¼˜åŒ–å…¨æ™¯æµç¨‹å›¾ã€‹ï¼ŒæŠŠæŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€æ—¥å¸¸ç»´æŠ¤ã€ç›‘æ§å‘Šè­¦ã€è°ƒä¼˜å»ºè®®è¿æ¥æˆä¸€ä¸ªé—­ç¯æµç¨‹

å¥½å˜ï½æˆ‘ä»¬å°±ç”»ä¸€å¼  **ã€Šæ•°æ®æ¹–æ€§èƒ½ä¼˜åŒ–å…¨æ™¯æµç¨‹å›¾ã€‹** ğŸ—ºï¸
æŠŠ **æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ â†’ æ—¥å¸¸ç»´æŠ¤ â†’ ç›‘æ§å‘Šè­¦ â†’ è°ƒä¼˜å»ºè®®** å½¢æˆä¸€ä¸ªå¯æŒç»­é—­ç¯ï¼Œè®©ä½ åœ¨å›¢é˜Ÿé‡Œä½œä¸º **Data Lake æ€§èƒ½æ²»ç† SOP** ç”¨ã€‚

æˆ‘ä¼šåŒæ—¶ç»™ä½  **Mermaid æµç¨‹å›¾ç‰ˆæœ¬**ï¼ˆæ–¹ä¾¿ Markdown/Wiki æ¸²æŸ“ï¼‰å’Œ **æ–‡å­—å›¾ç‰ˆ**ï¼ˆé€‚åˆ PPT æ–‡æ¡£ï¼‰ã€‚

---

## **1ï¸âƒ£ Mermaid ç‰ˆï¼ˆå¯æ¸²æŸ“ï¼‰**

```mermaid
flowchart LR
    subgraph OPT[æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥]
        A1[åˆ†åŒºç­–ç•¥ä¼˜åŒ–\n- åˆ†åŒºåˆ—é€‰æ‹©\n- é¿å…è¿‡å¤šåˆ†åŒº\n- éšè—åˆ†åŒº]
        A2[æ–‡ä»¶å¸ƒå±€ä¼˜åŒ–\n- å°æ–‡ä»¶åˆå¹¶\n- Z-Order/æ’åºèšç±»\n- åˆ é™¤å‘é‡ä¼˜åŒ–]
        A3[ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–\n- è¡¨/åˆ—çº§ç»Ÿè®¡æ›´æ–°\n- åˆ†åŒºçº§ç»Ÿè®¡\n- é«˜åŸºæ•°åˆ—ç›´æ–¹å›¾]
    end

    subgraph MNT[æ—¥å¸¸ç»´æŠ¤ç­–ç•¥]
        B1[å‹ç¼©å°æ–‡ä»¶\n(å®šæ—¶ä»»åŠ¡/æ¯”ä¾‹è§¦å‘)]
        B2[æ¸…ç†è¿‡æœŸå¿«ç…§\n- ä¿ç•™æœ€è¿‘Nä¸ª]
        B3[åˆ é™¤å­¤å„¿æ–‡ä»¶\né‡Šæ”¾å­˜å‚¨]
        B4[æ›´æ–°ç»Ÿè®¡ä¿¡æ¯\næ¯æ—¥/æ¯å‘¨æ‰¹å¤„ç†]
    end

    subgraph MON[ç›‘æ§ä¸å‘Šè­¦]
        C1[ç›‘æ§å°æ–‡ä»¶æ¯”ä¾‹\n> é˜ˆå€¼å‘Šè­¦]
        C2[ç›‘æ§å¿«ç…§æ•°é‡\n> é˜ˆå€¼å‘Šè­¦]
        C3[ç›‘æ§è¡¨å¤§å°å¢é•¿é€Ÿç‡\nå¼‚å¸¸é¢„è­¦]
    end

    subgraph TUN[æ€§èƒ½è°ƒä¼˜å»ºè®®]
        D1[åˆ†ææŸ¥è¯¢æ¨¡å¼]
        D2[ç”Ÿæˆä¼˜åŒ–å»ºè®®\n- åˆ†åŒºè°ƒæ•´\n- é‡æ–°èšç±»\n- å‹ç¼©å°æ–‡ä»¶]
        D3[è¯„ä¼°æå‡å¹…åº¦\nå½±å“é¢„ä¼°]
    end

    %% è¿çº¿å½¢æˆé—­ç¯
    OPT --> MNT
    MNT --> MON
    MON --> TUN
    TUN --> OPT
```

ğŸ’¡ **ä½¿ç”¨æ–¹å¼**ï¼šåœ¨æ”¯æŒ Mermaid çš„å¹³å°ï¼ˆGitLab/GitHub Wikiã€Markdown ç¼–è¾‘å™¨ã€Notionï¼‰å¯ä»¥ç›´æ¥æ¸²æŸ“å‡ºç»“æ„åŒ–é—­ç¯å›¾ã€‚

---

## **2ï¸âƒ£ ASCII æ–‡å­—ç‰ˆï¼ˆPPT/æ–‡æ¡£ç‰ˆï¼‰**

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ åˆ†åŒºç­–ç•¥ä¼˜åŒ– â†’ æ–‡ä»¶å¸ƒå±€ä¼˜åŒ– â†’ ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ—¥å¸¸ç»´æŠ¤ç­–ç•¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ å‹ç¼©å°æ–‡ä»¶  æ¸…ç†å¿«ç…§  åˆ é™¤å­¤å„¿æ–‡ä»¶  æ›´æ–°ç»Ÿè®¡ä¿¡æ¯         â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç›‘æ§ä¸å‘Šè­¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ å°æ–‡ä»¶æ¯”ä¾‹å¼‚å¸¸  å¿«ç…§æ•°é‡å¼‚å¸¸  æ•°æ®é‡å¢é•¿å¼‚å¸¸           â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ€§èƒ½è°ƒä¼˜å»ºè®® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ æŸ¥è¯¢æ¨¡å¼åˆ†æ â†’ ä¼˜åŒ–æ–¹æ¡ˆç”Ÿæˆ â†’ é¢„ä¼°æ€§èƒ½æå‡å¹…åº¦        â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
ï¼ˆé—­ç¯å›åˆ°ï¼‰ æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
```

---

## **3ï¸âƒ£ é—­ç¯æ€è·¯è¯´æ˜**

1. **æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼ˆProactive ä¼˜åŒ–ï¼‰**
   - äº‹å…ˆåšåˆ†åŒºã€æ–‡ä»¶å¸ƒå±€ã€ç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–
   - å‡å°‘å…¨è¡¨æ‰«æå’Œæ— æ•ˆ I/O
   - æå‡ Trino/Spark ä¼˜åŒ–å™¨å†³ç­–è´¨é‡

2. **æ—¥å¸¸ç»´æŠ¤ï¼ˆRoutine Maintenanceï¼‰**
   - **å‘¨æœŸæ€§å‹ç¼©å°æ–‡ä»¶**
   - **å¿«ç…§ä¸å­¤å„¿æ–‡ä»¶æ¸…ç†**
   - **å‘¨æœŸæ€§ç»Ÿè®¡ä¿¡æ¯åˆ·æ–°**

3. **å®æ—¶ç›‘æ§ä¸å‘Šè­¦ï¼ˆMonitoring & Alertingï¼‰**
   - 5 åˆ†é’Ÿ/15 åˆ†é’Ÿé‡‡é›†ä¸€æ¬¡å¥åº·æ•°æ®
   - å¯åµŒå…¥ Prometheus + Grafana è‡ªåŠ¨é¢„è­¦

4. **æ€§èƒ½è°ƒä¼˜å»ºè®®ï¼ˆRecommendation Engineï¼‰**
   - åŸºäºç›‘æ§æ•°æ®å’ŒæŸ¥è¯¢æ¨¡å¼åˆ†æï¼Œç”Ÿæˆå¯æ‰§è¡Œå»ºè®®
   - è¯„ä¼°ä¼˜åŒ–æ”¶ç›Šï¼Œå½¢æˆä»»åŠ¡å•äº¤ç»™æ•°æ®è¿ç»´æ‰§è¡Œ

5. **é—­ç¯åé¦ˆ**
   - è°ƒä¼˜ â†’ æ–°çš„åˆ†åŒº/å¸ƒå±€/ç»Ÿè®¡ â†’ å†è¿›å…¥æ­£å¸¸æŸ¥è¯¢ä¼˜åŒ–å‘¨æœŸ

---

## **4ï¸âƒ£ æˆ‘çš„å»ºè®®**
è¦è®©è¿™ä¸ªé—­ç¯ **è‡ªåŠ¨åŒ–** è½åœ°ï¼Œå¯ä»¥ï¼š
- **ç”¨ Airflow/Flink CDC å®šæ—¶ä»»åŠ¡** æ‰§è¡Œå‹ç¼©ã€æ¸…ç†ï¼›
- **å¼•å…¥è¡¨å¥åº·åº¦è¯„åˆ†ï¼ˆHealth Scoreï¼‰**
- å½“å¥åº·åº¦ä½æ—¶ï¼Œ**è‡ªåŠ¨ç”Ÿæˆè°ƒä¼˜ä»»åŠ¡** ç»™è¿ç»´æˆ–è§¦å‘ Spark ä½œä¸š
- å’Œ BI/æŸ¥è¯¢ç»Ÿè®¡å¹³å°ç»“åˆï¼ŒåŠ¨æ€ä¼˜åŒ–åˆ†åŒº + æ–‡ä»¶å¸ƒå±€

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†ç”» **ã€Šæ•°æ®æ¹–æ€§èƒ½æ²»ç†è‡ªåŠ¨åŒ–æ¶æ„å›¾ã€‹**ï¼ŒæŠŠ Trino/Spark æŸ¥è¯¢ â†’ å…ƒæ•°æ®ç›‘æ§ â†’ æ€§èƒ½ä¼˜åŒ–å†³ç­– â†’ è‡ªåŠ¨ç»´æŠ¤ è¿æ¥èµ·æ¥ï¼Œè¾¾åˆ°è‡ªæ„ˆå‹æ•°æ®æ¹–çš„æ•ˆæœã€‚

ä½ è¦æˆ‘å¸®ä½ ç”»è¿™å¼  **è‡ªåŠ¨åŒ–è¿ç»´æ¶æ„å›¾** å—ï¼Ÿè¿™æ ·ä¼šè®©æ•´ä¸ªä¼˜åŒ–ä½“ç³»å‡çº§æˆå¯æ— äººå€¼å®ˆè¿è¡Œçš„é—­ç¯ ğŸ’¡